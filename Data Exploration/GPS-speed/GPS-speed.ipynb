{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import radians, degrees, cos, sin, asin, sqrt\n",
    "\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm as tqdm_t\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import feather\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras import layers, Input, Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, LSTM, Dropout\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utm\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from pipeline.utils.stats import Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv(\"../../Trapeze_Data/first dump/VehicleMessages.csv\", dtype={\"isValid\":float, \"workCode\":float,\"tripCode\":float}, parse_dates=[1], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = feather.read_dataframe(\"../../data_files/B/once/75days/stop_events_with_geo_train_test_averages_prev_next_dwell.feather\",\n",
    "                            columns=[\"index\",\n",
    "                                     \"segment_duration\",\n",
    "                                     \"mean_durations_by_segment_code\",\n",
    "                                     \"mean_durations_by_segment_code_and_hour\",\n",
    "                                     \"mean_durations_by_segment_code_and_hour_and_day\",\n",
    "                                     \"diff_segment_and_mean_by_segment_code\",\n",
    "                                     \"diff_segment_and_mean_by_segment_code_and_hour_and_day\",\n",
    "                                     'line_distance',\n",
    "                                     'to_centre_dist',\n",
    "                                     'direction_degrees',\n",
    "                                     'rain',\n",
    "                                     'median_durations_by_segment_code_and_hour_and_day',\n",
    "                                     'arrival_hour','arrival_day',\n",
    "                                     \"diff_percent_segment_and_mean_by_segment_code_and_hour_and_day\",\n",
    "                                     'date','workid',\n",
    "                                     'actualArrival',\n",
    "                                     'publicName',\n",
    "                                     'segment_name',\n",
    "                                     'prev_segment_code_1',\n",
    "                                     'next_segment_code_1',\n",
    "                                     'test','train',\n",
    "                                     'timetable_segment_duration',\n",
    "                                     'clock_direction_degrees', 'dry', 'weekend',\n",
    "                                     'segment_code'\n",
    "                                    ])\n",
    "se = se.set_index(se.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.03960549855144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se['segment_duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = Stats(se[se['test']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = pd.read_csv(\"../../Bournemouth GTFS/routes.csv\")\n",
    "shapes = pd.read_csv(\"../../Bournemouth GTFS/shapes.csv\")\n",
    "stops = pd.read_csv(\"../../Bournemouth GTFS/stops.txt\").set_index('stop_id')\n",
    "trips = pd.read_csv(\"../../Bournemouth GTFS/trips.txt\")\n",
    "performed_work = pd.read_csv(\"../../Trapeze_Data/first dump/PerformedWork.csv\", parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se['speed_mph'] = se['line_distance']*1000/se['segment_duration'] * 2.237\n",
    "\n",
    "# se['speed_mph_baseline'] = se['line_distance']*1000/se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237\n",
    "\n",
    "# And now for just segments:\n",
    "se[\"diff_segment_and_mean_by_segment_code\"] = (\n",
    "    se[\"segment_duration\"]\n",
    "    - se[\"mean_durations_by_segment_code\"]\n",
    ")\n",
    "se[\"diff_segment_and_mean_by_segment_code_and_hour_and_day\"] = (\n",
    "    se[\"segment_duration\"]\n",
    "    - se[\"mean_durations_by_segment_code_and_hour_and_day\"]\n",
    ")\n",
    "\n",
    "se[\"diff_percent_segment_and_mean_by_segment_code\"] = (\n",
    "    se[\"diff_segment_and_mean_by_segment_code\"]\n",
    "    * 100\n",
    "    / se[\"mean_durations_by_segment_code\"]\n",
    ")\n",
    "\n",
    "se[\"diff_percent_segment_and_mean_by_segment_code_and_hour_and_day\"] = (\n",
    "    se[\"diff_segment_and_mean_by_segment_code_and_hour_and_day\"]\n",
    "    * 100\n",
    "    / se[\"mean_durations_by_segment_code_and_hour_and_day\"]\n",
    ")\n",
    "\n",
    "segment_code_and_hour_and_day_groups = se[se[\"train\"]].groupby(\n",
    "        [\"segment_code\", \"arrival_hour\", \"arrival_day\"]\n",
    "    )\n",
    "\n",
    "std_diff_percent_segment_mean_by_segment_code_and_hour_and_day = (\n",
    "    segment_code_and_hour_and_day_groups[\n",
    "        \"diff_percent_segment_and_mean_by_segment_code_and_hour_and_day\"\n",
    "    ]\n",
    "    .std()\n",
    "    .rename(\"std_diff_percent_segment_mean_by_segment_code_and_hour_and_day\")\n",
    ")\n",
    "se = se.merge(\n",
    "    std_diff_percent_segment_mean_by_segment_code_and_hour_and_day.to_frame(),\n",
    "    \"left\",\n",
    "    left_on=[\"segment_code\", \"arrival_hour\", \"arrival_day\"],\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "se['prev_segment_name'] = se['prev_segment_code_1'].str[:-2]\n",
    "se['next_segment_name'] = se['next_segment_code_1'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_to_shapes_dict = {}\n",
    "\n",
    "for route_id, route_group in trips.groupby('route_id'):\n",
    "    matching_shapes = route_group.groupby('shape_id').first().index.values\n",
    "    \n",
    "    trips_to_shapes_dict[route_id] = matching_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd04f6d7b64c4984a289ccdfff31ffe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=172), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapes_dict = {}\n",
    "\n",
    "for shape_name, shape in tqdm(shapes.groupby('shape_id')):\n",
    "    \n",
    "    coords = np.empty((len(shape)+1, 2))\n",
    "    \n",
    "    for i, row in enumerate(shape[['latitude','longitude']].itertuples()):\n",
    "\n",
    "        coords[i, :] = utm.from_latlon(row[1], row[2])[:2]\n",
    "                        \n",
    "    shapes_dict[shape_name] = LineString(coords)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cache = {}\n",
    "\n",
    "def find_length_by_name_route(segment_name, route_id, line_dist):\n",
    "    \n",
    "    line_dist = line_dist * 1000\n",
    "    \n",
    "    if segment_name in segment_cache:\n",
    "        return segment_cache[segment_name]\n",
    "    \n",
    "    if type(route_id) == float:\n",
    "        if np.isnan(route_id):\n",
    "            \n",
    "            segment_cache[segment_name] = line_dist\n",
    "            \n",
    "            return line_dist\n",
    "    \n",
    "    best_dist = np.inf\n",
    "    lengths = []\n",
    "    distances = []\n",
    "    \n",
    "    stop_codes = segment_name.split('_')\n",
    "\n",
    "    try:\n",
    "        stop_1_point = Point(utm.from_latlon(*stops.loc[stop_codes[0]][['stop_lat', 'stop_lon']].values)[:2])\n",
    "\n",
    "        stop_2_point = Point(utm.from_latlon(*stops.loc[stop_codes[1]][['stop_lat', 'stop_lon']].values)[:2])\n",
    "    except KeyError:\n",
    "        \n",
    "        segment_cache[segment_name] = line_dist\n",
    "        \n",
    "        return line_dist\n",
    "\n",
    "    for shape_name in trips_to_shapes_dict[route_id]:\n",
    "\n",
    "        shape = shapes_dict[shape_name]\n",
    "        \n",
    "        nearest_1 = nearest_points(shape, stop_1_point)[0]\n",
    "        nearest_2 = nearest_points(shape, stop_2_point)[0]\n",
    "\n",
    "        combined_dist = stop_1_point.distance(nearest_1) + stop_2_point.distance(nearest_2)\n",
    "            \n",
    "#         distances.append(combined_dist)\n",
    "#         lengths.append(np.abs(shape.project(nearest_1) - shape.project(nearest_2)))\n",
    "\n",
    "        # Find the cases where the points are close to the shape\n",
    "        if (combined_dist) <= best_dist:\n",
    "            best_dist = combined_dist\n",
    "            \n",
    "            distances.append(combined_dist)\n",
    "            lengths.append(np.abs(shape.project(nearest_1) - shape.project(nearest_2)))\n",
    "                \n",
    "    if(best_dist >= 15):\n",
    "        \n",
    "        segment_cache[segment_name] = line_dist\n",
    "        \n",
    "        return line_dist\n",
    "\n",
    "    # Take the mean of only those shapes where the points is very close to the shape\n",
    "    new_length = np.mean(np.asarray(lengths)[np.asarray(distances) == best_dist])\n",
    "    \n",
    "    if (new_length == 0) | (new_length > 4000):\n",
    "        \n",
    "        segment_cache[segment_name] = line_dist\n",
    "        \n",
    "        return line_dist\n",
    "\n",
    "    segment_cache[segment_name] = new_length\n",
    "\n",
    "    return segment_cache[segment_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length_by_geo_route(lat1, lon1, lat2, lon2, route_id, line_dist):\n",
    "    \n",
    "    # Try if line_dist < 20 just return line_dist...\n",
    "    \n",
    "    if line_dist == 0:\n",
    "        return line_dist\n",
    "    \n",
    "    if type(route_id) == float:\n",
    "        if np.isnan(route_id):\n",
    "            \n",
    "            return line_dist\n",
    "    \n",
    "    best_dist = np.inf\n",
    "    lengths = []\n",
    "    distances = []\n",
    "\n",
    "    try: \n",
    "        stop_1_point = Point(utm.from_latlon(lat1, lon1)[:2])\n",
    "\n",
    "        stop_2_point = Point(utm.from_latlon(lat2, lon2)[:2])\n",
    "        \n",
    "        shape_names = trips_to_shapes_dict[route_id]\n",
    "        \n",
    "        lengths = np.empty(len(shape_names))\n",
    "        distances = np.empty(len(shape_names))\n",
    "    \n",
    "        for idx, shape_name in enumerate(shape_names):\n",
    "\n",
    "            shape = shapes_dict[shape_name]\n",
    "\n",
    "            nearest_1 = nearest_points(shape, stop_1_point)[0]\n",
    "            nearest_2 = nearest_points(shape, stop_2_point)[0]\n",
    "            \n",
    "            distances[idx] = stop_1_point.distance(nearest_1) + stop_2_point.distance(nearest_2)\n",
    "            lengths[idx] = np.abs(shape.project(nearest_1) - shape.project(nearest_2))\n",
    "            \n",
    "#             # Find the cases where the points are close to the shape\n",
    "#             if (combined_dist) <= best_dist:\n",
    "#                 best_dist = combined_dist\n",
    "                \n",
    "#                 distances.append(combined_dist)\n",
    "#                 lengths.append(np.abs(shape.project(nearest_1) - shape.project(nearest_2)))\n",
    "\n",
    "        best_dist = np.min(distances)\n",
    "   \n",
    "        # If the combined distance between the points and the best shape is over 10 meters\n",
    "        # Or if the distance is more than a quater of the strieght line distance between the \n",
    "        # points just use the line distance.\n",
    "        if (best_dist >= 10) or ((best_dist * 4) > line_dist):\n",
    "            return line_dist\n",
    "\n",
    "        # Take the mean of only those shapes where the points is very close to the shape\n",
    "        new_length = np.mean(lengths[distances == best_dist])\n",
    "\n",
    "    except: \n",
    "        return line_dist\n",
    "    \n",
    "    if (new_length == 0) | (new_length > line_dist*5) | (new_length < line_dist):\n",
    "        \n",
    "        return line_dist\n",
    "\n",
    "    return new_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "se['route_id'] = routes.set_index('route_short_name').loc[se['publicName']]['route_id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(\"My Bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a2e4d3fbdb4582850085d08519396d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3920087), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se['real_length'] = se.progress_apply(lambda row: find_length_by_name_route(row['segment_name'], row['route_id'], row['line_distance']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "se['speed_mph'] = se['real_length'] / se['segment_duration'] * 2.237\n",
    "\n",
    "se['speed_mph_baseline'] = se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['timeReported'] = pd.to_datetime(messages['timeReported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['delta_time'] = messages['timeReported'] - messages.shift(1)['timeReported']\n",
    "messages['time_seconds'] = messages['delta_time'] / np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['workCode'] = messages['workCode'].fillna(method=\"ffill\")\n",
    "messages['tripCode'] = messages['tripCode'].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['dateReported'] = messages['timeReported'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['dateReported'] = pd.to_datetime(messages['dateReported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "performed_work['tripCode'] = performed_work['tripCode'].replace([np.nan, np.inf], -1)\n",
    "\n",
    "performed_work['tripCode'] = performed_work['tripCode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.reset_index().merge(performed_work[['workCode', 'tripCode', 'date', 'publicName']],\n",
    "                            left_on=['workCode', 'tripCode', 'dateReported'], \n",
    "                            right_on=['workCode', 'tripCode', 'date'],\n",
    "                           how=\"left\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = messages.drop(columns=['date_x', 'publicName_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.reset_index().merge(routes[['route_short_name', 'route_id']], \n",
    "                                        left_on=['publicName'], \n",
    "                                        right_on=['route_short_name'], \n",
    "                                        how=\"left\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((messages['delta_time'] / np.timedelta64(1, 's')).values, bins=100, range=(-10, 300));\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction under 31 seconds: 0.9922313547349763\n",
      "Between 20 and 31 seconds: 0.4873540276156894\n",
      "Between 10 and 31 seconds: 0.6685176447865044\n",
      "Between 5 and 31 seconds: 0.7989372016388877\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fraction under 31 seconds: {np.count_nonzero(messages['time_seconds'] < 31)/messages.shape[0]}\")\n",
    "      \n",
    "print(f\"Between 20 and 31 seconds: {np.count_nonzero((messages['time_seconds'] < 31) & (messages['time_seconds'] > 20))/messages.shape[0]}\")\n",
    "      \n",
    "print(f\"Between 10 and 31 seconds: {np.count_nonzero((messages['time_seconds'] < 31) & (messages['time_seconds'] > 10))/messages.shape[0]}\")\n",
    "      \n",
    "print(f\"Between 5 and 31 seconds: {np.count_nonzero((messages['time_seconds'] < 31) & (messages['time_seconds'] > 5))/messages.shape[0]}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['delta_lon'] = messages['lon'] - messages.shift(1)['lon']\n",
    "messages['delta_lat'] = messages['lat'] - messages.shift(1)['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['inPosition', 'InTripEnd', 'InTripStart', 'InPointArrive',\n",
       "       'InPointDepart'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['msg'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['delta_distance'] = haversine_np(messages['lon'], messages['lat'], messages['lon'].shift(1), messages['lat'].shift(1)) * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.dropna(subset=['lon', 'lat'])\n",
    "\n",
    "messages = messages[(messages['time_seconds'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['lon_next'] = messages['lon'].shift(1)\n",
    "messages['lat_next'] = messages['lat'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 20\n",
    "num_cores = 5\n",
    "\n",
    "def parallelize_dataframe(df, func, args):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    \n",
    "    # This line is fidly, we make a list where each item is a tuple of \n",
    "    # a bit of the dataframe and whatever is passed in as args. \n",
    "    # Then starmap unpacks that tuple so each copy of func gets it's \n",
    "    # little bit of the dataframe and the right args to do it's job. \n",
    "    # All this to avoid globals! \n",
    "    all_args = [(split,) + args for split in df_split]\n",
    "    \n",
    "    df = pd.concat(pool.starmap(func, all_args))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.iloc[1510485]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dist(messages):\n",
    "\n",
    "    messages['true_distance'] = messages[['lon', 'lat', \n",
    "                                          'lon_next', 'lat_next', \n",
    "                                          'route_id', 'delta_distance'\n",
    "                                         ]].apply(lambda row: find_length_by_geo_route(*row[['lat', 'lon',\n",
    "                                                                                          'lat_next', \n",
    "                                                                                           'lon_next',\n",
    "                                                                                           'route_id',\n",
    "                                                                                           'delta_distance'\n",
    "                                                                                          ]]), axis=1)\n",
    "\n",
    "    return messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = parallelize_dataframe(messages, find_dist, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['delta_speed'] = messages['delta_distance']/messages['time_seconds']\n",
    "# messages['delta_speed'] = messages['true_distance']/messages['time_seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['speed_mph'] = messages['delta_speed'] * 2.237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# messages.to_csv(\"messages_with_true_dist.csv\")\n",
    "\n",
    "messages = pd.read_csv(\"messages_with_true_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages.to_csv(\"messages_with_true_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 21434532\n",
      "changed: 5660938\n",
      "is close: 15777464\n"
     ]
    }
   ],
   "source": [
    "print(f\"total: {len(messages)}\")\n",
    "\n",
    "print(f\"changed: {np.count_nonzero(messages['true_distance'] != messages['delta_distance'])}\")\n",
    "      \n",
    "print(f\"is close: {np.count_nonzero(np.isclose(messages['true_distance'], messages['delta_distance']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1de93ac940>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(messages['delta_distance'], messages['true_distance'], bins=[50,50], range=[[0,800],[0,800]], norm=LogNorm())\n",
    "plt.axis('equal')\n",
    "plt.xlabel(\"straight line distance\")\n",
    "plt.ylabel(\"real distance\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.58963564028363"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.count_nonzero(messages['delta_distance'] == messages['true_distance'])/len(messages))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 3920087\n",
      "changed: 2785921\n",
      "is close: 1134166\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"total: {len(se)}\")\n",
    "\n",
    "print(f\"changed: {np.count_nonzero(se['real_length'] != se['line_distance']*1000)}\")\n",
    "      \n",
    "print(f\"is close: {np.count_nonzero(np.isclose(se['real_length'], se['line_distance']*1000))}\")\n",
    "\n",
    "just_segs = se.groupby('segment_name').first()\n",
    "      \n",
    "plt.hist2d(just_segs['line_distance']*1000, just_segs['real_length'], bins=[50,50], range=[[0,800],[0,800]], cmin=1)\n",
    "# plt.hist2d(just_segs['line_distance']*1000, just_segs['real_length'], bins=[50,50], range=[[0,800],[0,800]], norm=LogNorm())\n",
    "plt.axis('equal')\n",
    "plt.xlabel(\"Straight Line Distance (meters)\")\n",
    "plt.ylabel(\"Calculated Distance (meters)\")\n",
    "plt.title(\"Changes In Segment Distance After Map Matching\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"GPS:distances hist.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 20)]['speed_mph'], bins=100, range=(-10,400));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 5)]['speed_mph'], bins=100, range=(-10,400));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a9eaff780>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 5)]['speed_mph'], bins=100, range=(-10,400), label=\"5\");\n",
    "plt.hist(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 10)]['speed_mph'], bins=100, range=(-10,400), label=\"10\", alpha=0.5);\n",
    "plt.hist(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 20)]['speed_mph'], bins=100, range=(-10,400), label=\"20\", alpha=0.5);\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431833852.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(messages[(messages['msg'].isin(['inPosition', 'InPointArrive']))]['time_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226814593.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['speed_mph'] < 3)]['time_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.40194601510768"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "226289342.0/431833852.0*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['prev_speed_mph'] = messages.shift(1)['speed_mph']\n",
    "messages['next_speed_mph'] = messages.shift(-1)['speed_mph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['jitter'] = [False]*messages.shape[0]\n",
    "\n",
    "messages['jitter'] = (messages['speed_mph'] > 75) & \\\n",
    "    (((messages['prev_speed_mph'] > 75) & (messages['next_speed_mph'] < 50)) | \\\n",
    "     ((messages['next_speed_mph'] > 75) & (messages['prev_speed_mph'] < 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['inout'] = \"\"\n",
    "messages.loc[messages['msg'] == \"InPointArrive\", \"inout\"] = \"in\"\n",
    "messages.loc[messages['msg'] == \"InPointDepart\", \"inout\"] = \"out\"\n",
    "messages['inout'] = messages['inout'].replace(\"\", np.nan)\n",
    "messages['inout'] = messages['inout'].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in     9429412\n",
       "out    7870405\n",
       "Name: inout, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[messages['msg'].isin(['inPosition', 'InPointArrive']), 'inout'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    21426427\n",
       "True         8105\n",
       "Name: jitter, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['jitter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['segment_name'] = messages['stopCode'].fillna(method=\"ffill\").shift(1) + \"_\" + messages['stopCode'].fillna(method=\"bfill\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = messages[(messages['msg'].isin(['inPosition', 'InPointArrive'])) & (messages['time_seconds'] < 31) & (messages['time_seconds'] > 5) & (messages['jitter'] == False) & (messages['speed_mph'] != np.inf) & (messages['inout'] == \"out\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7098429, 32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(filtered['speed_mph'], bins=100, range=(0,75));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(filtered['speed_mph'], bins=100, range=(3,75));\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se['speed_mph'], bins=100, range=(3,75));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se['speed_mph'], range=(0, 60), bins=61);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "se['mean_speed_mph_by_segment_code'] = se['real_length']/se['mean_durations_by_segment_code'] * 2.237\n",
    "\n",
    "se['mean_speed_mph_by_segment_code_hour'] = se['real_length']/se['mean_durations_by_segment_code_and_hour'] * 2.237\n",
    "\n",
    "se['speed_mph_diff_mean_to_hour'] = se['mean_speed_mph_by_segment_code_hour'] - se['mean_speed_mph_by_segment_code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one = se[se['arrival_day'] < 5].groupby([\"segment_name\", \"arrival_hour\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one = just_one.reset_index().merge(all_stats_df, left_on=['segment_name','arrival_hour'], right_on=['seg_name','hours']) # .set_index(['segment_name','arrival_hour'])\n",
    "\n",
    "just_one = just_one.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_fit = just_one[['slow_fraction', 'fast_mean', 'total_mean',\n",
    "                        'clipped_hmean','clipped_mean','freq',\n",
    "                        'fast_hmean', 'real_length', ]].values\n",
    "#                         'direction_degrees', 'to_centre_dist']].values\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "expanded_data = poly.fit_transform(data_to_fit)\n",
    "\n",
    "names = poly.get_feature_names(['slow_fraction', 'fast_mean', 'total_mean',\n",
    "                                'clipped_hmean','clipped_mean','freq',\n",
    "                                'fast_hmean','real_length', ])\n",
    "                                #'direction_degrees', 'to_centre_dist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_training_data(data, target, cut_point):\n",
    "\n",
    "#     cut_point = int(len(data)*test_fraction)\n",
    "    \n",
    "    train_data = data[:cut_point,:]\n",
    "    test_data = data[cut_point:,:]\n",
    "    \n",
    "    test_mask = np.zeros(data.shape[0]).astype(bool)\n",
    "    test_mask[cut_point:] = True\n",
    "\n",
    "    train_target = target[:cut_point]\n",
    "    test_target = target[cut_point:]\n",
    "    \n",
    "    scaler_target = preprocessing.StandardScaler().fit(train_target[:, None])\n",
    "\n",
    "#     scaler_target = preprocessing.MinMaxScaler().fit(train_target[:, None])\n",
    "\n",
    "\n",
    "    train_target_scaled = scaler_target.transform(train_target[:, None]).astype(np.float32)\n",
    "    test_target_scaled = scaler_target.transform(test_target[:, None]).astype(np.float32)\n",
    "    \n",
    "    data_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    train_data_scaled = data_scaler.fit_transform(train_data).squeeze()\n",
    "    test_data_scaled = data_scaler.transform(test_data).squeeze()\n",
    "\n",
    "    return train_data_scaled, test_data_scaled, train_target_scaled, test_target_scaled, scaler_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_training_data_days(data, target, days, valid_mask):\n",
    "\n",
    "    first_day_test = se.loc[se[\"test\"], \"date\"].min()\n",
    "    \n",
    "    train_days = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Use the stop events to work out how to make a mask that has exactly the right number of days in it.\n",
    "    while train_days != days and count != 10:\n",
    "\n",
    "        train = se.loc[\n",
    "            se[\"date\"].isin(\n",
    "                pd.date_range(\n",
    "                    start=(first_day_test - pd.Timedelta(f\"{days + 1 + count} days\")),\n",
    "                    periods=(days + 1 + count),\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        train_days = len(train.groupby(\"date\").first())\n",
    "        count += 1\n",
    "\n",
    "    \n",
    "    train_days_mask = se[\"date\"].isin(\n",
    "                pd.date_range(\n",
    "                    start=(first_day_test - pd.Timedelta(f\"{days + 1 + count} days\")),\n",
    "                    periods=(days + 1 + count),\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    train_data = data[valid_mask & train_days_mask,:]\n",
    "    test_data = data[valid_mask & se['test'],:]\n",
    "    \n",
    "    train_target = target[valid_mask & train_days_mask]\n",
    "    test_target = target[valid_mask & se['test']]\n",
    "    \n",
    "    scaler_target = preprocessing.StandardScaler().fit(train_target[:, None])\n",
    "\n",
    "    train_target_scaled = scaler_target.transform(train_target[:, None]).astype(np.float32)\n",
    "    test_target_scaled = scaler_target.transform(test_target[:, None]).astype(np.float32)\n",
    "    \n",
    "    data_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    train_data_scaled = data_scaler.fit_transform(train_data).squeeze()\n",
    "    test_data_scaled = data_scaler.transform(test_data).squeeze()\n",
    "\n",
    "    return train_data_scaled, test_data_scaled, train_target_scaled, test_target_scaled, scaler_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_scaled, test_data_scaled, \n",
    " train_target_scaled, test_target_scaled, \n",
    " scaler_target) = prep_training_data(expanded_data, just_one['mean_speed_mph_by_segment_code_hour'].values, int(len(expanded_data)*test_fraction))\n",
    "\n",
    "test_target_truth = scaler_target.inverse_transform(test_target_scaled).squeeze()\n",
    "\n",
    "lr = LinearRegression()\n",
    "# lr = Lasso()\n",
    "\n",
    "lr.fit(train_data_scaled, train_target_scaled)\n",
    "\n",
    "test_y_scaled = lr.predict(test_data_scaled)\n",
    "\n",
    "test_y = scaler_target.inverse_transform(test_y_scaled)\n",
    "\n",
    "test_target_truth = scaler_target.inverse_transform(test_target_scaled)\n",
    "\n",
    "plt.scatter(test_target_truth, test_y, marker=\".\", alpha=0.3)\n",
    "plt.xlabel(\"true target (mph)\")\n",
    "plt.ylabel(\"prediction target (mph)\")\n",
    "plt.ylim(-5,35)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_target_truth, test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names = np.array(names).squeeze()[np.argsort(np.abs(lr.coef_))].squeeze()\n",
    "\n",
    "ordered_coef = np.array(lr.coef_).squeeze()[np.argsort(np.abs(lr.coef_))].squeeze()\n",
    "\n",
    "display(list(zip(ordered_names, ordered_coef))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_scaled, test_data_scaled, \n",
    " train_target_scaled, test_target_scaled, \n",
    " scaler_target) = prep_training_data(expanded_data, just_one['mean_speed_mph_by_segment_code_hour'].values, int(len(expanded_data)*test_fraction))\n",
    "\n",
    "ar = ARDRegression()\n",
    "# lr = Lasso()\n",
    "\n",
    "ar.fit(train_data_scaled, train_target_scaled)\n",
    "\n",
    "test_y_scaled = ar.predict(test_data_scaled)\n",
    "\n",
    "test_y = scaler_target.inverse_transform(test_y_scaled)\n",
    "\n",
    "test_target_truth = scaler_target.inverse_transform(test_target_scaled)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_target_truth, test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_scaled = ar.predict(test_data_scaled)\n",
    "\n",
    "test_y = scaler_target.inverse_transform(test_y_scaled)\n",
    "\n",
    "test_target_truth = scaler_target.inverse_transform(test_target_scaled)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_target_truth, test_y)))\n",
    "\n",
    "plt.scatter(test_target_truth, test_y, marker=\".\", alpha=0.3)\n",
    "plt.xlabel(\"true target (mph)\")\n",
    "plt.ylabel(\"prediction target (mph)\")\n",
    "plt.ylim(-5,35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names = np.array(names).squeeze()[np.argsort(np.abs(ar.coef_))].squeeze()\n",
    "\n",
    "ordered_coef = np.array(ar.coef_).squeeze()[np.argsort(np.abs(ar.coef_))].squeeze()\n",
    "\n",
    "display(list(zip(ordered_names, ordered_coef))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(input_shape, dropout, NN, use_linear):\n",
    "\n",
    "    # with help from: https://keras.io/getting-started/functional-api-guide/\n",
    "\n",
    "    # Headline input: meant to receive road time series.\n",
    "    main_input = Input(shape=[input_shape], dtype=\"float32\", name=\"input\")\n",
    "\n",
    "    for index, layer in enumerate(NN):\n",
    "        if(index == 0):\n",
    "            x = Dense(layer, activation=\"relu\")(main_input)\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        if index == len(NN)-1:\n",
    "            x = Dense(layer, activation=\"relu\")(x)\n",
    "        else:\n",
    "            x = Dense(layer, activation=\"relu\")(x)\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "\n",
    "#     # We stack a deep densely-connected network on top\n",
    "#     x = Dense(128, activation=\"relu\")(main_input)\n",
    "#     x = Dropout(rate=dropout)(x)\n",
    "#     x = Dense(64, activation=\"relu\")(x)\n",
    "#     x = Dropout(rate=dropout)(x)\n",
    "#     x = Dense(32, activation=\"relu\")(x)\n",
    "#     x = Dropout(rate=dropout)(x)\n",
    "#     x = Dense(32, activation=\"relu\")(x)\n",
    "#     x = Dropout(rate=dropout)(x)\n",
    "#     x = Dense(12, activation=\"relu\")(x)\n",
    "#     x = Dropout(rate=dropout)(x)\n",
    "\n",
    "    # And finally we add the main output layer\n",
    "    if use_linear:\n",
    "        main_output = Dense(1, activation=\"linear\", name=\"main_output\")(x)\n",
    "    else: \n",
    "        main_output = Dense(1, activation=\"tanh\", name=\"main_output\")(x)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[main_input], outputs=[main_output]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_scaled, test_data_scaled, \n",
    " train_target_scaled, test_target_scaled, \n",
    " scaler_target) = prep_training_data(data_to_fit, just_one['mean_speed_mph_by_segment_code_hour'], int(len(data_to_fit)*test_fraction))\n",
    "\n",
    "model = create_simple_model(\n",
    "        (train_data_scaled.shape[1]),\n",
    "        0.1)\n",
    "\n",
    "Path(f\"GPS_models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"GPS_models/simple.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# model.compile(optimizer=\"rmsprop\", loss=\"mean_absolute_error\")\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "model.fit(\n",
    "    train_data_scaled,\n",
    "    train_target_scaled,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks_list,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_data_scaled, test_target_scaled),\n",
    ")\n",
    "\n",
    "test_y_scaled = model.predict(test_data_scaled)\n",
    "\n",
    "test_y = scaler_target.inverse_transform(test_y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_truth = scaler_target.inverse_transform(test_target_scaled).squeeze()\n",
    "\n",
    "print(np.sqrt(mean_squared_error(test_target_truth, test_y)))\n",
    "\n",
    "plt.scatter(test_target_truth, test_y, marker=\".\", alpha=0.3)\n",
    "plt.xlabel(\"true target (mph)\")\n",
    "plt.ylabel(\"prediction target (mph)\")\n",
    "plt.ylim(-5,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.030280221158794"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered['time_seconds'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "- Calc the stats for all the segments\n",
    "- Load up the means by hour of the day and daytype for each of these segment names\n",
    "- Try to find a way to predict the spead of the segment by hour using the stats\n",
    "- Get the stats for each indivual event, not just the bulk averages, \n",
    "    - Do the same for the last hour on that segment and think about fast ways to do prev/next as well\n",
    "- Try to find the stats with the highest and lowest variance (forcus on those with lower variance)\n",
    "- Is there enough data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_dict = {}\n",
    "\n",
    "segments = filtered.groupby('segment_name')\n",
    "\n",
    "for seg_name, segment in segments:\n",
    "    \n",
    "     df = segment.set_index(\"timeReported\")[['speed_mph', 'time_seconds']]\n",
    "        \n",
    "     df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "     segments_dict[seg_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_width = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_gps_data_hour = np.zeros((se.shape[0], matrix_width)).astype(np.float32)\n",
    "se_gps_data_20mins = np.zeros((se.shape[0], matrix_width)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_gps_data_hour_prev_next = np.zeros((se.shape[0], matrix_width)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d579ab79fe843cfabfb9c01c03f7a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/scipy/stats/stats.py:377: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return size / np.sum(1.0 / a, axis=axis, dtype=dtype)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/core/_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in enumerate(tqdm(se[['actualArrival', 'segment_name']].itertuples())):\n",
    "    \n",
    "    gps_tracks = segments_dict[row[2]]\n",
    "    \n",
    "    relevant = gps_tracks[(gps_tracks.index > row[1] - pd.Timedelta(f\"80 min\")) & (gps_tracks.index < row[1] - pd.Timedelta(f\"20 min\"))]\n",
    "    \n",
    "    if(len(relevant) == 0):\n",
    "        se_gps_data_hour[idx,0] = row[0]\n",
    "        continue\n",
    "    \n",
    "    slow_time = np.sum(relevant[relevant['speed_mph'] <= 3]['time_seconds'])\n",
    "    total_time = np.sum(relevant['time_seconds'])\n",
    "    fast = relevant[relevant['speed_mph'] > 3]\n",
    "    fast_speeds = fast['speed_mph'].values\n",
    "    fast_times = fast['time_seconds'].values\n",
    "    fast_time = total_time - slow_time\n",
    "    relevant_speeds = relevant['speed_mph'].values\n",
    "    relvant_times = relevant['time_seconds'].values\n",
    "    \n",
    "    row_data = np.empty(matrix_width).astype(np.float32)\n",
    "    \n",
    "    row_data[0] = row[0]\n",
    "    row_data[1] = slow_time/total_time\n",
    "    row_data[2] = hmean(fast_speeds)\n",
    "    row_data[3] = np.sum(fast_speeds * fast_times)/fast_time\n",
    "    row_data[4] = np.sum(relevant_speeds * relvant_times)/total_time\n",
    "    row_data[5] = len(relevant)\n",
    "    row_data[6] = len(fast_times)\n",
    "\n",
    "    if len(fast_times) > 0:\n",
    "        row_data[7], row_data[8] = np.quantile(fast_speeds, [0.5, 0.75])\n",
    "    else:\n",
    "        row_data[7] = np.nan\n",
    "        row_data[8] = np.nan\n",
    "    \n",
    "    row_data[9], row_data[10] = np.quantile(relevant_speeds, [0.5, 0.75])\n",
    "    row_data[11] = np.max(relevant_speeds)\n",
    "    row_data[12] = np.std(fast_speeds)\n",
    "    \n",
    "    se_gps_data_hour[idx, :] = row_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0878c6b327e41ad86a48e7ee612609f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-d38928c92801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mslow_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speed_mph'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_seconds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_seconds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speed_mph'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "for idx, row in enumerate(tqdm(se[['actualArrival', 'segment_name']].itertuples())):\n",
    "    \n",
    "    gps_tracks = segments_dict[row[2]]\n",
    "    \n",
    "    relevant = gps_tracks[(gps_tracks.index > row[1] - pd.Timedelta(f\"40 min\")) & (gps_tracks.index < row[1] - pd.Timedelta(f\"20 min\"))].values\n",
    "    \n",
    "    if(len(relevant) == 0):\n",
    "        se_gps_data_20mins[idx,0] = row[0]\n",
    "        continue\n",
    "        \n",
    "    slow_time = np.sum(relevant[relevant['speed_mph'] <= 3]['time_seconds'])\n",
    "    total_time = np.sum(relevant['time_seconds'])\n",
    "    fast = relevant[relevant['speed_mph'] > 3]\n",
    "    fast_speeds = fast['speed_mph'].values\n",
    "    fast_times = fast['time_seconds'].values\n",
    "    fast_time = total_time - slow_time\n",
    "    relevant_speeds = relevant['speed_mph'].values\n",
    "    relvant_times = relevant['time_seconds'].values\n",
    "    \n",
    "    row_data = np.empty(matrix_width).astype(np.float32)\n",
    "    \n",
    "    row_data[0] = row[0]\n",
    "    row_data[1] = slow_time/total_time\n",
    "    row_data[2] = hmean(fast_speeds)\n",
    "    row_data[3] = np.sum(fast_speeds * fast_times)/fast_time\n",
    "    row_data[4] = np.sum(relevant_speeds * relvant_times)/total_time\n",
    "    row_data[5] = len(relevant)\n",
    "    row_data[6] = len(fast_times)\n",
    "\n",
    "    if len(fast_times) > 0:\n",
    "        row_data[7], row_data[8] = np.quantile(fast_speeds, [0.5, 0.75])\n",
    "    else:\n",
    "        row_data[7] = np.nan\n",
    "        row_data[8] = np.nan\n",
    "    \n",
    "    row_data[9], row_data[10] = np.quantile(relevant_speeds, [0.5, 0.75])\n",
    "    row_data[11] = np.max(relevant_speeds)\n",
    "    row_data[12] = np.std(fast_speeds)\n",
    "    \n",
    "    se_gps_data_20mins[idx, :] = row_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943c55f1f98b468d9406f8a0cd6ed49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "for idx, row in enumerate(tqdm(se[['actualArrival', 'segment_name', 'prev_segment_name', 'next_segment_name']].itertuples())):\n",
    "    \n",
    "    gps_tracks = segments_dict[row[2]]\n",
    "    \n",
    "    relevant_current = gps_tracks[(gps_tracks.index > row[1] - pd.Timedelta(f\"80 min\")) & (gps_tracks.index < row[1] - pd.Timedelta(f\"20 min\"))]\n",
    "    \n",
    "    if (row[3] != '') & (row[3] in segments_dict):\n",
    "        gps_tracks_prev = segments_dict[row[3]]\n",
    "        \n",
    "        relevant_prev = gps_tracks_prev[(gps_tracks_prev.index > row[1] - pd.Timedelta(f\"80 min\")) & (gps_tracks_prev.index < row[1] - pd.Timedelta(f\"20 min\"))]\n",
    "    else:\n",
    "        relevant_prev = [] \n",
    "        \n",
    "    if (row[4] != '') & (row[4] in segments_dict):\n",
    "        gps_tracks_next = segments_dict[row[4]]\n",
    "    \n",
    "        relevant_next = gps_tracks_next[(gps_tracks_next.index > row[1] - pd.Timedelta(f\"80 min\")) & (gps_tracks_next.index < row[1] - pd.Timedelta(f\"20 min\"))]\n",
    "    else: \n",
    "        relevant_next = []\n",
    "        \n",
    "    to_concat = []\n",
    "    \n",
    "    for chunk in [relevant_current, relevant_prev, relevant_next]:\n",
    "        if len(chunk) > 0:\n",
    "            to_concat.append(chunk)\n",
    "            \n",
    "    if len(to_concat) == 0:\n",
    "        se_gps_data_hour_prev_next[idx,0] = row[0]\n",
    "        continue\n",
    "        \n",
    "    relevant = pd.concat(to_concat)\n",
    "    \n",
    "#     if(len(relevant) == 0):\n",
    "#         se_gps_data_hour_prev_next[idx,0] = row[0]\n",
    "#         continue\n",
    "        \n",
    "    slow_time = np.sum(relevant[relevant['speed_mph'] <= 3]['time_seconds'])\n",
    "    total_time = np.sum(relevant['time_seconds'])\n",
    "    fast = relevant[relevant['speed_mph'] > 3]\n",
    "    fast_speeds = fast['speed_mph'].values\n",
    "    fast_times = fast['time_seconds'].values\n",
    "    fast_time = total_time - slow_time\n",
    "    relevant_speeds = relevant['speed_mph'].values\n",
    "    relvant_times = relevant['time_seconds'].values\n",
    "    \n",
    "    row_data = np.empty(matrix_width).astype(np.float32)\n",
    "    \n",
    "    row_data[0] = row[0]\n",
    "    row_data[1] = slow_time/total_time\n",
    "    row_data[2] = hmean(fast_speeds)\n",
    "    row_data[3] = np.sum(fast_speeds * fast_times)/fast_time\n",
    "    row_data[4] = np.sum(relevant_speeds * relvant_times)/total_time\n",
    "    row_data[5] = len(relevant)\n",
    "    row_data[6] = len(fast_times)\n",
    "\n",
    "    if len(fast_times) > 0:\n",
    "        row_data[7], row_data[8] = np.quantile(fast_speeds, [0.5, 0.75])\n",
    "    else:\n",
    "        row_data[7] = np.nan\n",
    "        row_data[8] = np.nan\n",
    "    \n",
    "    row_data[9], row_data[10] = np.quantile(relevant_speeds, [0.5, 0.75])\n",
    "    row_data[11] = np.max(relevant_speeds)\n",
    "    row_data[12] = np.std(fast_speeds)\n",
    "    \n",
    "    se_gps_data_hour_prev_next[idx, :] = row_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"se_gps_features_20min_80min_inout_fixed_true_speed\", se_gps_data_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(\"se_gps_features_20min_40min_inout_fixed\", se_gps_data_20mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"se_gps_features_20min_80min_prev_next_inout_fixed_true_speed\", se_gps_data_hour_prev_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se_gps_data_hour = np.load(\"se_gps_features_20min_80min_inout_fixed_true_speed.npy\")\n",
    "# se_gps_data_20mins = np.load(\"se_gps_features_20min_40min_inout_fixed.npy\", )\n",
    "# se_gps_data_hour_prev_next = np.load(\"se_gps_features_20min_80min_prev_next_inout_fixed_true_speed.npy\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Key to columns\n",
    " \n",
    "-  0 -> Index\n",
    "-  1 -> slow_fraction (time)\n",
    "-  2 -> harmonic mean speed (fast, not weighted)\n",
    "-  3 -> mean speed (fasted weighted dby time)\n",
    "-  4 -> mean speed (all weighted dby time)\n",
    "-  5 -> number of relevant readings\n",
    "-  6 -> number of fast readings\n",
    "-  7 -> median fast\n",
    "-  8 -> 75th percentile (fast)\n",
    "-  9 -> median all\n",
    "-  10 -> 75th percentile (all)\n",
    "-  11 -> Max speed\n",
    "-  12 -> standard deviation fast speeds\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((se_gps_data_hour_prev_next[:,1:], se[['real_length', \n",
    "                                                            'direction_degrees', \n",
    "                                                            \"to_centre_dist\",\n",
    "                                                           'rain',\n",
    "                                                           'arrival_hour',\n",
    "                                                           'arrival_day']].values))\n",
    "\n",
    "df_cors = pd.DataFrame(data=np.hstack((data, se[['speed_mph']].values)),\n",
    "                    columns=['slow_fraction', 'fast_hmean', 'fast_mean', 'total_mean',\n",
    "                                'freq_total',\n",
    "                                'freq_fast',\n",
    "                               'fast_median', 'fast_75th percential',\n",
    "                              'total_median', 'total_75th percential', 'max', 'std',\n",
    "                             'real_length', 'direction_degrees', \"to_centre_dist\",\n",
    "                                                           'rain',\n",
    "                                                           'arrival_hour',\n",
    "                                                           'arrival_day','speed_mph'])\n",
    "\n",
    "cors = df_cors[df_cors['freq_fast'] >= 10].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slow_fraction</th>\n",
       "      <th>fast_hmean</th>\n",
       "      <th>fast_mean</th>\n",
       "      <th>total_mean</th>\n",
       "      <th>freq_total</th>\n",
       "      <th>freq_fast</th>\n",
       "      <th>fast_median</th>\n",
       "      <th>fast_75th percential</th>\n",
       "      <th>total_median</th>\n",
       "      <th>total_75th percential</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>real_length</th>\n",
       "      <th>direction_degrees</th>\n",
       "      <th>to_centre_dist</th>\n",
       "      <th>rain</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>speed_mph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slow_fraction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.442384</td>\n",
       "      <td>-0.016944</td>\n",
       "      <td>-0.101059</td>\n",
       "      <td>0.303115</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>-0.382185</td>\n",
       "      <td>-0.277706</td>\n",
       "      <td>-0.726955</td>\n",
       "      <td>-0.549655</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>-0.073490</td>\n",
       "      <td>0.056266</td>\n",
       "      <td>-0.009064</td>\n",
       "      <td>-0.022689</td>\n",
       "      <td>-0.015588</td>\n",
       "      <td>-0.118985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_hmean</th>\n",
       "      <td>-0.442384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.120259</td>\n",
       "      <td>-0.352249</td>\n",
       "      <td>-0.256651</td>\n",
       "      <td>0.868918</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.835032</td>\n",
       "      <td>0.768264</td>\n",
       "      <td>-0.010895</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>-0.039705</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>-0.066586</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.218893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_mean</th>\n",
       "      <td>-0.016944</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969980</td>\n",
       "      <td>-0.026257</td>\n",
       "      <td>-0.024816</td>\n",
       "      <td>0.074618</td>\n",
       "      <td>0.070954</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>0.066144</td>\n",
       "      <td>0.727367</td>\n",
       "      <td>0.824269</td>\n",
       "      <td>-0.002517</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.014896</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_mean</th>\n",
       "      <td>-0.101059</td>\n",
       "      <td>0.120259</td>\n",
       "      <td>0.969980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053959</td>\n",
       "      <td>-0.030653</td>\n",
       "      <td>0.112633</td>\n",
       "      <td>0.099916</td>\n",
       "      <td>0.126229</td>\n",
       "      <td>0.117126</td>\n",
       "      <td>0.669403</td>\n",
       "      <td>0.767772</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.028061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_total</th>\n",
       "      <td>0.303115</td>\n",
       "      <td>-0.352249</td>\n",
       "      <td>-0.026257</td>\n",
       "      <td>-0.053959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928832</td>\n",
       "      <td>-0.359567</td>\n",
       "      <td>-0.327228</td>\n",
       "      <td>-0.387995</td>\n",
       "      <td>-0.387281</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.135797</td>\n",
       "      <td>-0.155788</td>\n",
       "      <td>-0.192583</td>\n",
       "      <td>-0.022869</td>\n",
       "      <td>-0.017694</td>\n",
       "      <td>-0.032736</td>\n",
       "      <td>-0.141950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_fast</th>\n",
       "      <td>0.032602</td>\n",
       "      <td>-0.256651</td>\n",
       "      <td>-0.024816</td>\n",
       "      <td>-0.030653</td>\n",
       "      <td>0.928832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.265226</td>\n",
       "      <td>-0.255504</td>\n",
       "      <td>-0.191257</td>\n",
       "      <td>-0.223257</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.137177</td>\n",
       "      <td>-0.151528</td>\n",
       "      <td>-0.254368</td>\n",
       "      <td>-0.026618</td>\n",
       "      <td>-0.020346</td>\n",
       "      <td>-0.037814</td>\n",
       "      <td>-0.114343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_median</th>\n",
       "      <td>-0.382185</td>\n",
       "      <td>0.868918</td>\n",
       "      <td>0.074618</td>\n",
       "      <td>0.112633</td>\n",
       "      <td>-0.359567</td>\n",
       "      <td>-0.265226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840192</td>\n",
       "      <td>0.848304</td>\n",
       "      <td>0.876314</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>-0.009789</td>\n",
       "      <td>-0.043736</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.222838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_75th percential</th>\n",
       "      <td>-0.277706</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.070954</td>\n",
       "      <td>0.099916</td>\n",
       "      <td>-0.327228</td>\n",
       "      <td>-0.255504</td>\n",
       "      <td>0.840192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669848</td>\n",
       "      <td>0.907133</td>\n",
       "      <td>-0.007572</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>0.089241</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>0.219115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_median</th>\n",
       "      <td>-0.726955</td>\n",
       "      <td>0.835032</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>0.126229</td>\n",
       "      <td>-0.387995</td>\n",
       "      <td>-0.191257</td>\n",
       "      <td>0.848304</td>\n",
       "      <td>0.669848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>-0.019671</td>\n",
       "      <td>-0.048896</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>-0.012460</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>-0.034402</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.207256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_75th percential</th>\n",
       "      <td>-0.549655</td>\n",
       "      <td>0.768264</td>\n",
       "      <td>0.066144</td>\n",
       "      <td>0.117126</td>\n",
       "      <td>-0.387281</td>\n",
       "      <td>-0.223257</td>\n",
       "      <td>0.876314</td>\n",
       "      <td>0.907133</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.034806</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>-0.044306</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.222241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.023791</td>\n",
       "      <td>-0.010895</td>\n",
       "      <td>0.727367</td>\n",
       "      <td>0.669403</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>-0.007572</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978168</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.004882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025007</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>0.824269</td>\n",
       "      <td>0.767772</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>-0.009789</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>-0.019671</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>0.978168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003379</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.008834</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.004790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_length</th>\n",
       "      <td>0.007807</td>\n",
       "      <td>-0.039705</td>\n",
       "      <td>-0.002517</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>0.135797</td>\n",
       "      <td>0.137177</td>\n",
       "      <td>-0.043736</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>-0.048896</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>-0.003379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029062</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>-0.092871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_degrees</th>\n",
       "      <td>-0.073490</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>-0.155788</td>\n",
       "      <td>-0.151528</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>-0.029062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005734</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>0.031385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_centre_dist</th>\n",
       "      <td>0.056266</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>-0.192583</td>\n",
       "      <td>-0.254368</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.089241</td>\n",
       "      <td>-0.012460</td>\n",
       "      <td>0.034806</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>-0.005734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017674</td>\n",
       "      <td>-0.019916</td>\n",
       "      <td>-0.022087</td>\n",
       "      <td>0.014546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>-0.009064</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.022869</td>\n",
       "      <td>-0.026618</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-0.017674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.002794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_hour</th>\n",
       "      <td>-0.022689</td>\n",
       "      <td>-0.066586</td>\n",
       "      <td>-0.014896</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.017694</td>\n",
       "      <td>-0.020346</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>-0.034402</td>\n",
       "      <td>-0.044306</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>-0.008834</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>-0.019916</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_day</th>\n",
       "      <td>-0.015588</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>-0.032736</td>\n",
       "      <td>-0.037814</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>-0.022087</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_mph</th>\n",
       "      <td>-0.118985</td>\n",
       "      <td>0.218893</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>-0.141950</td>\n",
       "      <td>-0.114343</td>\n",
       "      <td>0.222838</td>\n",
       "      <td>0.219115</td>\n",
       "      <td>0.207256</td>\n",
       "      <td>0.222241</td>\n",
       "      <td>-0.004882</td>\n",
       "      <td>-0.004790</td>\n",
       "      <td>-0.092871</td>\n",
       "      <td>0.031385</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       slow_fraction  fast_hmean  fast_mean  total_mean  \\\n",
       "slow_fraction               1.000000   -0.442384  -0.016944   -0.101059   \n",
       "fast_hmean                 -0.442384    1.000000   0.075459    0.120259   \n",
       "fast_mean                  -0.016944    0.075459   1.000000    0.969980   \n",
       "total_mean                 -0.101059    0.120259   0.969980    1.000000   \n",
       "freq_total                  0.303115   -0.352249  -0.026257   -0.053959   \n",
       "freq_fast                   0.032602   -0.256651  -0.024816   -0.030653   \n",
       "fast_median                -0.382185    0.868918   0.074618    0.112633   \n",
       "fast_75th percential       -0.277706    0.714348   0.070954    0.099916   \n",
       "total_median               -0.726955    0.835032   0.059134    0.126229   \n",
       "total_75th percential      -0.549655    0.768264   0.066144    0.117126   \n",
       "max                         0.023791   -0.010895   0.727367    0.669403   \n",
       "std                         0.025007   -0.012660   0.824269    0.767772   \n",
       "real_length                 0.007807   -0.039705  -0.002517   -0.003253   \n",
       "direction_degrees          -0.073490    0.011115   0.010177    0.015392   \n",
       "to_centre_dist              0.056266    0.015355   0.023939    0.019120   \n",
       "rain                       -0.009064    0.013833   0.000372    0.000123   \n",
       "arrival_hour               -0.022689   -0.066586  -0.014896   -0.012433   \n",
       "arrival_day                -0.015588    0.014993   0.000449    0.001836   \n",
       "speed_mph                  -0.118985    0.218893   0.015747    0.028061   \n",
       "\n",
       "                       freq_total  freq_fast  fast_median  \\\n",
       "slow_fraction            0.303115   0.032602    -0.382185   \n",
       "fast_hmean              -0.352249  -0.256651     0.868918   \n",
       "fast_mean               -0.026257  -0.024816     0.074618   \n",
       "total_mean              -0.053959  -0.030653     0.112633   \n",
       "freq_total               1.000000   0.928832    -0.359567   \n",
       "freq_fast                0.928832   1.000000    -0.265226   \n",
       "fast_median             -0.359567  -0.265226     1.000000   \n",
       "fast_75th percential    -0.327228  -0.255504     0.840192   \n",
       "total_median            -0.387995  -0.191257     0.848304   \n",
       "total_75th percential   -0.387281  -0.223257     0.876314   \n",
       "max                      0.017147   0.007964    -0.010144   \n",
       "std                      0.012263   0.003234    -0.009789   \n",
       "real_length              0.135797   0.137177    -0.043736   \n",
       "direction_degrees       -0.155788  -0.151528     0.013491   \n",
       "to_centre_dist          -0.192583  -0.254368     0.030019   \n",
       "rain                    -0.022869  -0.026618     0.011212   \n",
       "arrival_hour            -0.017694  -0.020346    -0.064000   \n",
       "arrival_day             -0.032736  -0.037814     0.008228   \n",
       "speed_mph               -0.141950  -0.114343     0.222838   \n",
       "\n",
       "                       fast_75th percential  total_median  \\\n",
       "slow_fraction                     -0.277706     -0.726955   \n",
       "fast_hmean                         0.714348      0.835032   \n",
       "fast_mean                          0.070954      0.059134   \n",
       "total_mean                         0.099916      0.126229   \n",
       "freq_total                        -0.327228     -0.387995   \n",
       "freq_fast                         -0.255504     -0.191257   \n",
       "fast_median                        0.840192      0.848304   \n",
       "fast_75th percential               1.000000      0.669848   \n",
       "total_median                       0.669848      1.000000   \n",
       "total_75th percential              0.907133      0.842482   \n",
       "max                               -0.007572     -0.018709   \n",
       "std                               -0.004569     -0.019671   \n",
       "real_length                        0.030820     -0.048896   \n",
       "direction_degrees                 -0.027995      0.037344   \n",
       "to_centre_dist                     0.089241     -0.012460   \n",
       "rain                               0.007358      0.012136   \n",
       "arrival_hour                      -0.057837     -0.034402   \n",
       "arrival_day                       -0.002462      0.016045   \n",
       "speed_mph                          0.219115      0.207256   \n",
       "\n",
       "                       total_75th percential       max       std  real_length  \\\n",
       "slow_fraction                      -0.549655  0.023791  0.025007     0.007807   \n",
       "fast_hmean                          0.768264 -0.010895 -0.012660    -0.039705   \n",
       "fast_mean                           0.066144  0.727367  0.824269    -0.002517   \n",
       "total_mean                          0.117126  0.669403  0.767772    -0.003253   \n",
       "freq_total                         -0.387281  0.017147  0.012263     0.135797   \n",
       "freq_fast                          -0.223257  0.007964  0.003234     0.137177   \n",
       "fast_median                         0.876314 -0.010144 -0.009789    -0.043736   \n",
       "fast_75th percential                0.907133 -0.007572 -0.004569     0.030820   \n",
       "total_median                        0.842482 -0.018709 -0.019671    -0.048896   \n",
       "total_75th percential               1.000000 -0.014069 -0.012305    -0.003346   \n",
       "max                                -0.014069  1.000000  0.978168    -0.003603   \n",
       "std                                -0.012305  0.978168  1.000000    -0.003379   \n",
       "real_length                        -0.003346 -0.003603 -0.003379     1.000000   \n",
       "direction_degrees                   0.004169  0.007603  0.008455    -0.029062   \n",
       "to_centre_dist                      0.034806  0.021268  0.021431     0.101195   \n",
       "rain                                0.009007 -0.002251 -0.001798     0.002340   \n",
       "arrival_hour                       -0.044306 -0.008796 -0.008834    -0.008285   \n",
       "arrival_day                         0.005869 -0.000781 -0.000676     0.002121   \n",
       "speed_mph                           0.222241 -0.004882 -0.004790    -0.092871   \n",
       "\n",
       "                       direction_degrees  to_centre_dist      rain  \\\n",
       "slow_fraction                  -0.073490        0.056266 -0.009064   \n",
       "fast_hmean                      0.011115        0.015355  0.013833   \n",
       "fast_mean                       0.010177        0.023939  0.000372   \n",
       "total_mean                      0.015392        0.019120  0.000123   \n",
       "freq_total                     -0.155788       -0.192583 -0.022869   \n",
       "freq_fast                      -0.151528       -0.254368 -0.026618   \n",
       "fast_median                     0.013491        0.030019  0.011212   \n",
       "fast_75th percential           -0.027995        0.089241  0.007358   \n",
       "total_median                    0.037344       -0.012460  0.012136   \n",
       "total_75th percential           0.004169        0.034806  0.009007   \n",
       "max                             0.007603        0.021268 -0.002251   \n",
       "std                             0.008455        0.021431 -0.001798   \n",
       "real_length                    -0.029062        0.101195  0.002340   \n",
       "direction_degrees               1.000000       -0.005734 -0.001712   \n",
       "to_centre_dist                 -0.005734        1.000000 -0.017674   \n",
       "rain                           -0.001712       -0.017674  1.000000   \n",
       "arrival_hour                    0.018543       -0.019916  0.011006   \n",
       "arrival_day                    -0.005179       -0.022087  0.173254   \n",
       "speed_mph                       0.031385        0.014546  0.002794   \n",
       "\n",
       "                       arrival_hour  arrival_day  speed_mph  \n",
       "slow_fraction             -0.022689    -0.015588  -0.118985  \n",
       "fast_hmean                -0.066586     0.014993   0.218893  \n",
       "fast_mean                 -0.014896     0.000449   0.015747  \n",
       "total_mean                -0.012433     0.001836   0.028061  \n",
       "freq_total                -0.017694    -0.032736  -0.141950  \n",
       "freq_fast                 -0.020346    -0.037814  -0.114343  \n",
       "fast_median               -0.064000     0.008228   0.222838  \n",
       "fast_75th percential      -0.057837    -0.002462   0.219115  \n",
       "total_median              -0.034402     0.016045   0.207256  \n",
       "total_75th percential     -0.044306     0.005869   0.222241  \n",
       "max                       -0.008796    -0.000781  -0.004882  \n",
       "std                       -0.008834    -0.000676  -0.004790  \n",
       "real_length               -0.008285     0.002121  -0.092871  \n",
       "direction_degrees          0.018543    -0.005179   0.031385  \n",
       "to_centre_dist            -0.019916    -0.022087   0.014546  \n",
       "rain                       0.011006     0.173254   0.002794  \n",
       "arrival_hour               1.000000     0.017845   0.006743  \n",
       "arrival_day                0.017845     1.000000   0.003314  \n",
       "speed_mph                  0.006743     0.003314   1.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['speed_mph', 'fast_median', 'total_75th percential',\n",
       "       'fast_75th percential', 'fast_hmean', 'total_median', 'freq_total',\n",
       "       'slow_fraction', 'freq_fast', 'real_length', 'direction_degrees',\n",
       "       'total_mean', 'fast_mean', 'to_centre_dist', 'arrival_hour', 'max',\n",
       "       'std', 'arrival_day', 'rain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For version 3\n",
    "\n",
    "cors['speed_mph'].abs().sort_values().index[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se_gps_data_hour_prev_next[:,1], bins=50, range=(0,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/tommelamed/.local/lib/python3.7/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se_gps_data_hour_prev_next[:,4], bins=50, range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se_gps_data_hour_prev_next[:,7], bins=50, range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(se['speed_mph'], bins=50, range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHkCAYAAADFHq1WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvXuYZGV57v17qvo0R4aZaWBARhA16GcUPidEQz6jSLKJW6MmJJGoQaMZ/bZJNObLTtR8iafsxEQl5mQyKhvMNgrxSIwmeqGEqFsQZAQUDR5QgZGZgTn09Pnw7D/Wauyu9+nud7pqVVcV9++6+uqqp9fhXdV1r1Vrrbvux9wdIYQQQnQntbUegBBCCCFWjw7kQgghRBejA7kQQgjRxehALoQQQnQxOpALIYQQXYwO5EIIIUQXU/mB3MzqZnaLmX28fH6mmd1gZnea2VVmNlD1GIQQzSMtC9GZtOOM/JXAHQuevwW4zN0fBRwCXtKGMQghmkdaFqIDqfRAbmYPA/4r8O7yuQEXAB8sJ7kSeE6VYxBCNI+0LETnUvUZ+V8A/x2YK59vAw67+0z5/G7gtIrHIIRoHmlZiA6lr6oFm9kzgf3ufrOZPXW+HEwaZsSa2W5gN8CGDRueePbZZ3Pn3u+mM8/OtmbAHUZxwrPamVs3jiUJ/mvhP1IRwG3h0U98BAA333zzQXcfbuWyq9AywJ233JUuYG4uqa0Jmfprh9RyyVKa9NjxrEbLlR3IgfOBnzOzZwBDwGaKT/VbzKyv/CT/MODeaGZ33wPsAdi1a5ffdNNNXLT115PpZg8frmj4K2B5FzOstjqpW72++nGscp3HxVy6Qwg/VHm6Y/Zg3pBgXhHz6Zv+CQAzSz/tNk/LtQxw0Qm/lkw7OzJSwfAXEOgl1Gir9Z25vPA9H827Wl1lakoaXTtWo+XKLq27+2vc/WHufgbwPOAz7v584LPAxeVklwIfq2oMQojmkZaF6GzW4nvkvwe82sy+SXGf7T1rMAYhRPNIy0J0AFVeWn8Qd78OuK58/G3gvHasVwjRWqRlITqPthzIW0Y77v1GNHO/rGHe3Ptx1h/8a3Lvm+cSGYsyzTBOej/cSMfnwW1zizYjvOeXd29QdCm1ii8INnE/PNJf6FvJNaUGuoqNusE6ovvV4batrI1QUwE5yyoINB+NV7qtFEW0CiGEEF2MDuRCCCFEF6MDuRBCCNHF6EAuhBBCdDFdZXazwcG1WXF2iEL0uajB0OKpOSYyf/n0TFoMzDHZBpzIvNOX+e8PDEJhrFc05qmpdLqp6bz1ip7GBvqrXUGmgTI0dgVaC01c9Wh5mYayXPNqX6ahLlpv43ZEBtfZyPSarjMy52UHx4hK0Rm5EEII0cXoQC6EEEJ0MTqQCyGEEF2MDuRCCCFEF9NVZjfWDa3NelvYCSk2p60+2S00DPVHtWB5wevp9cDYNplnYrO+YLrIKBeYcjxYXmIUJDArKTGqe6laz5nJbqEmAyNoOF0zCXBRimI0XW56XI7ZbSYy0eaZ/cJaZHBVSmPb0Rm5EEII0cXoQC6EEEJ0MTqQCyGEEF2MDuRCCCFEF9NdZrdc00dT61h9KlNodmuYLtdYE5rEoumGgrS7gYGk5IN5/2qbDQw4URpUM4lOmYY/LFpHg+Emmk8mGrEEoW4DvRCYSC0ykeYa26JakAoXGuAiM1qkycDIlqSxZRrbPFp+QPR6Rq2LI+OqtNs6KjsjN7MhM7vRzL5iZl81szeU9SvM7Dtmtrf8OaeqMQghWoP0LETnUuUZ+SRwgbsfM7N+4HNm9snyb7/r7h+scN1CiNYiPQvRoVR2IHd3B46VT/vLHyXsC9GFSM9CdC6Vmt3MrG5me4H9wKfd/YbyT39sZrea2WVmtkYtzYQQx4P0LERnUqnZzd1ngXPMbAvwETN7HPAa4AfAALAH+D3gjY3zmtluYDfAzp07y9Fmtv3rJBpNYUFLwtAAt2ljUvINwT4ySnOaSQ0jkYnN+9P1zvUFyxsMjD+BGcbGJrOm86mxdB2ZJpdGQ6HaKLaP1eo51DLEJs+KCd8v0Xs5mjka76YN6ToCY5vNZCal5b6fI6NcZNBrXG+U7BYZ24LEtjB9MXa2peMIzLvSbutoy9fP3P0wcB1wkbvv84JJ4H8C5y0xzx533+Xuu4aHh9sxTCFEBserZ2lZiGqp0rU+XH5yx8zWARcCXzezHWXNgOcAt1c1BiFEa5Cehehcqry2tQO40szqFB8Yrnb3j5vZZ8xsmOLq1V7g5RWOQQjRGqRnITqUKl3rtwLnBvULqlqnEKIapGchOpeuSnabPmlTUrNvtHYdYTpbZjvEsPVhYxpUpkklMqXYTDrd3MY0lWpmW1qbHchMrAv8J32j6VhqE9PpvFGr1MF0LBalV0VEhpvEW5NnthGdx+zWVM98u3XLD1uWBu/R2rp16cxRYmLU9jcwtvlAug5fH6THhSluac0CU5xNZxrl+hqMbNOROTZYfjpVTGS2DUxxYRtTpb21DGWtCyGEEF2MDuRCCCFEF6MDuRBCCNHF6EAuhBBCdDFdZXabHUyTyNqxAbkGuHjmxfOGrUgHU2NNlOI2tzE128xsTA1wU5vTdcwOptswV09rtZnUMNO3Lt3WgcPpvH2BUac2EaRBRa0UxUMOH6g4qTFsjRtoOdJ3YGyb3ZKmuM2tC4xtga6ixMRakMAYGdYiTdYmAzNsYICzyQZTaqQ9y9RjYM5L2qQuOW+Qnqe0t5ahM3IhhBCii9GBXAghhOhidCAXQgghuhgdyIUQQogupqvMblObW2x2yzWsRQQJbTYQpJg1prYFJpq5E1MTzcSpaRvTYzvSrZ1JFxems9UngukCY0lk1JkNTEkzkQFuQzq+ocjkkw4lTJLyqL1kg2km7KKodKiuYHpTatQMMg7zyNRy2DI40uSmtDa5Pa1NbIuMpekq6mmHX+pTqf4GjqZvaJ9K37tzUTtkT1+92tTimk0FJrmoFpnpxoOdyGhgWAuS3UJ95xrlxIrojFwIIYToYnQgF0IIIboYHciFEEKILmbFW8xmVgOeAJwKjANfdff7qh6YEKL1SM9C9B5LHsjN7Czg94ALgTuBA8AQ8GgzGwP+HrjSvX0uopn1bbiAEKZBBca2wDQTGmka25gGhrgobarvWGo22bgvnXVyczq2qY1pbWZ9Ou9cf2BUCTY/MsoNHklrUUBU2G4xaNEaGl+iJKkGg57SofLoSD0HhslVm93C5LBg9xZpNEhbDFuRBgazKHXNPDCihe1J01r0mkSdj2szwVim09fAG2a2qO1olHYXGE2ZTlsXE+k2SI+TJqtluTPyNwPvBF7mvniPamYnAb8CvBC4MprZzIaA64HBcj0fdPc/MrMzgQ8AW4EvAy909yDHUwjRQqRnIXqUJU9x3f0Sd7++UfTl3/a7+1+4eyj6kkngAnd/AnAOcJGZPQl4C3CZuz8KOAS8pLlNEEKshPQsRO+S9TVsM/sJ4IyF07v7e5ebp9xhHCuf9pc/DlxA8ekfik//r6c4UxBCtAHpWYjeIsfs9g/AWcBeYP6GiAPLCr+ctw7cDDwS+BvgW8Bhd5+/SXo3cNoS8+4GdgPs3LlzpVUJITJYCz1Ly0JUS84Z+S7gsdEluZVw91ngHDPbAnwEeEw02RLz7gH2AOzatcsBjp2amjI2H++gFhAZpcKWpZHbpD946YaCSKeG1KgoMWr6hCBF6sR0+aM7UqPOaPAxaOqk1JRSX5cazHKZG0ktSIP3peObC0xDNpum1g1G7RZzjTQNphmPWkGK5Wi7niMtA4yekr6f1x3voOaJTKqRIbUxaRGY25Q6QSeGU02OnZQub/KEIAkx2A1EiYmRObQWuAtsNl1vPZBLLagNHFv874iS4/qPpjP2Bwa4KAnSct9GwXZFqYxWi4xySmpciRwb+O3AKc2sxN0PA9cBTwK2mNn8Hv9hwL3NLFsIcVxIz0L0GMt9/eyfKT5dbwK+ZmY3UhheAHD3n1tuwWY2DEy7+2EzW0fxtZe3AJ8FLqZwul4KfKzZjRBCLI/0LETvstyl9bc2uewdwJXlfbUacLW7f9zMvgZ8wMzeDNwCvKfJ9QghVkZ6FqJHWfJA7u7/Pv/YzE4BzqP4RP8ld//BSgt291uBc4P6t8tlCSHahPQsRO+S41p/KfCHwGcoutH9lZm90d0vr3pwyVja4W+IUtyCNCQLE+CClLEGU9zs+tRsM35SWjtyZrr8sZ2pO6Rvaxq7dsK61FkyOZ3+qyePBSlz4+l09dF0LH1j6ayhAWcqMrYFxrsoSSoy0sjk0hQPOT0nKw3MrEGr3ekgHfHYaem8EycHbUeHgpS5iSCxbTytDR4KUh5HkxL9o0EL1JG0Vp9cPJa+0XS8USJcqL25YFsDQ6oHyY2hboNamAAnza9Ijmv9d4Fz3f1+ADPbBnwBaLvwhRBNIz0L0WPkuNbvBkYWPB8Bvl/NcIQQFSM9C9Fj5JyR3wPcYGYfo7in9mzgRjN7NYC7v73C8QkhWov0LESPkXMg/1b5M8/810s2tX44QoiKkZ6F6DFWPJC7+xvaMZAcpk5ow0rCZLeg9WFuAlyQ6JQsajo1eAweTqebG0zHMVFLY6Sm+1MDyqlb0r6jZ5z+QLreWmpU+fKB05PagW9uS2p9Y+n2rzsQvMX6gtczMgpGBjjRFJ2k5+mNFa8gNLZF7UnT960H+g6kQT0wsc3NBfNOpbX6ZF4q3GzgSZ3cmreOgaOLxzf0QKq99fuDZU2mG2vR6xmRO51oGTmu9V3A64CHs7jJwuMrHJcQogKkZyF6j5xL6++jcLreBugUSYjuRnoWosfIOZAfcPdrKh+JEKIdSM9C9Bg5B/I/MrN3A9eyOJv5w5WNSghRFdKzED1GzoH8xcDZQD8/vBTnQNuF7znfem+WKFkoMm8MpA4U35y27JzeurhF4sT2dL7x7emGjQ+nq5wYTk1sWx+Wmtj+r21p4ubJQyNJrRZcWX1gOt2GkfHUgZOb9tY3FjiEomS32dVd5Q2ToMRyPLT03EhgtJzcmr6/j+1INT92avAe3RTEGZLOOzMTGNsy094iU1zUstSCtqCN09VmglakQY3ZqJap0ePvkCuaJOdA/gR3/9HKRyKEaAfSsxA9Rs5n4i+a2WMrH4kQoh1Iz0L0GDln5D8JXGpm36G4p2aA6+sqQnQl0rMQPUbOgfyiykchhGgX0rMQPcaSB3Iz2+jux9z9uytNs8TfTgfeC5xCYarZ4+7vMLPXA78OHCgnfa27fyJnsLPr2mCiiBLbcs0bQRJZY0LUzFC6/MjYNn56agjbfloa93b21v1J7awNB5Laxnra7nRrPe2PeHd9a1L75ubtSe2769NYrjAhKyPZbkmC1z3L3Ka2hwnN6LkKLUOcYlY5UfvhgNmhtNY3PJ7UTt9+KKlNzaa71ftHUhPpxEj6AgR+tVBXtYlUV0GgI3MN3trZgXS+uf4opTKoRfvGiDClUQa4KlnujPxjZraXIov5ZncfBTCzRwBPA34JeBfwwSXmnwF+x92/bGabgJvN7NPl3y5z97e2ZAuEEDk0o2dpWYgOZskDubs/3cyeAbwMON/MTqQQ9DeAfwEudff0e04/nH8fsK98PGJmdwCntXLwQog8mtGztCxEZ7PsPfLyMln2pbKlMLMzgHOBG4Dzgd8ws18FbqL4pJ9enxJCtJRW6FlaFqLzqDySwcw2Ah8CXuXuR4F3AmcB51B8yn/bEvPtNrObzOymAwfSe75CiPYiLQvRmeS41leNmfVTCP998xGQ7n7fgr+/C/h4NK+77wH2AOzatcsBrBkPU6bJJTvZLZPazOJBW7D8+njQ4nA0TaAaGQ0cOKk3jbMG70tqJ/UdTWpDlhrqpj1d71yQVFWbjtoopttWmwgcOJNTSclnI6dO8L+QkW1NaLWWAWwt/E+hmTUtRWObmUh3l0cnA01Gq62l71urp7W5gcAwGqSsNZrYAOaCNqaz/Q3rDOQT1qaC9MWZQKNNpDSGBjjpe1VUdkZuRfPa9wB3uPvbF9R3LJjsucDtVY1BCNE80rIQnc1yXz8LzvV+iLs/sMKyzwdeCNxWumUBXgtcYmbnUHwOvovCfCOEqJAm9SwtC9HBLHdp/WYKgRqwEzhUPt4CfA84c7kFu/vniLoHtMA8J4Q4blatZ2lZiM5mua+fnQlgZn8HXDMf9GBmPwtc2J7hLcaC+7LZhPde0vvB4XrrwXRBF6W5dWnAQ2O3s/FtQaezk4N7RcNpgMupJ6adztbV0zZI+6ZPTGpDQbukw0H7qTsnTklq9xwIlrc//V+seyC9h1YfSUM0mA5aN80E99p0v6xldKaeK15+LbhzGNSmNwYd0bakmty6Pc2+OnVj6j0Zm+lPalPT6a7W59Kx2GQQ/hLc+w49KsHrOdAwvIFjqab6jqUz2kSwsFxvS6RbablScu6R/9jCtCZ3/yTwU9UNSQhRIdKzED1Gjmv9oJn9AfC/KC7NvQC4v9JRCSGqQnoWosfIOSO/BBgGPlL+DJc1IUT3IT0L0WOseEZeullfuVyDFCFEdyA9C9F7rHggN7OfAN4NbAR2mtkTgJe5+3+renCN1KLWQE0QBRJEdrrI0GFBEEJtMjWI9I0tNnnUZgPjXHBdpG8gXedgX9ARbSDdFz95/Z1J7fyhdCVzpAaU0bl7kto1fY9LBxiFaATBFcEq4i5xQU20nk7Sc1MBTxlE7ykLQk36JoLp5tJdY18Q6rKxfzKpre/Lc/HNzgWdEGtBR7T+dCxzgSnOZqPug43TBPu8meAfEbxOnmlYU6ez9pNzaf0y4L9Q3kdz968AT6lyUEKIypCehegxspLd3P37DaUWnxsLIdqF9CxEb5HjWv9+eTnOzWwA+C3gjmqHJYSoCOlZiB4j54z85cArKPoP303R6egVVQ5KCFEZ0rMQPUaOa/0g8Pw2jGVlWmyOsagTUlSLiJLdBtNEp8bUqJnUy8LsYNARLRjG6HTa8mgyMOUcnluf1L4+nX5V+MDshqT2xaNnJbWpA+uS2sY0ZI7+o0FC1HhqBorToNLXIDLNJDUlRh0XnaTnqs1uIfX03GUmMIJ6X/reGwjMphON7cWAY4FO7x9LtTY5kU43F3RYqwXGtvpEuoPoG0tK9E0s3o56YOyrTaSJbWH6YtTVLLPTmaiWFc/IzezRZnatmd1ePn98GSghhOgypGcheo+cS+vvAl4DTAO4+63A86oclBCiMqRnIXqMnAP5ene/saEWdLgQQnQB0rMQPUbOgfygmZ1FGQFiZhcD+yodlRCiKqRnIXqMnK+fvQLYA5xtZvcA32GNzDJtSXaLUokCI9ZqTR6zqW8MNqYnRKedeDipnbU5NaydMXQwqW2rp2lvD++LTHHper92+OSkNvBAauwbOhS0QxzNbE8avXbh6y4jTQV0jJ4rN7tl6jbS/FzqYePk9amuzt74g6R2/3RqbNs8kJo+vz5zUlI7Npbq1GYiY1ta6x9NSgwcXby9/SOpsc3G0rHFZrfVtywN096k75aR41r/NnChmW0Aau4+krNgMzsdeC9wCoXffI+7v8PMtgJXAWcAdwG/5O6HVjd8IcTxID0L0XvkuNa3mdlfAv8BXGdm7zCzbRnLngF+x90fAzwJeIWZPRb4feBad38UcG35XAjRBqRnIXqPnHvkHwAOAL8AXFw+vmqlmdx9n7t/uXw8QpEedRrwbODKcrIrgecc/7CFEKtEehaix8i5R77V3d+04Pmbzey4xGpmZwDnAjcAJ7v7Pih2DmaW3igSQlSF9CxEj5FzIP+smT0PuLp8fjHwL7krMLONwIeAV7n7UbO85DQz2w3sBti5cycAntXiJZ/sZLdozEGyWxTH1miamUvDnOhfnxpLtgxOJLWTB46mqwzi7g7Mbk5qX55MjTqfGvnRpLb/yKZ0HelQqE9FLUuj5KfAIBNNJ+NLu2i7niMtF3/IHvPqiMYWJLt5oPko2W2onteeNEpbPDCeGuCmpgJj23TQnjSSRiC/WjC8+vTiCW060GOk0cAU2PJWwxbs0LUfWBU5h8aXAf8ITJU/HwBebWYjZpYeWRZgZv0Uon+fu3+4LN9nZjvKv+8A9kfzuvsed9/l7ruGh4fztkYIsRJt17O0LES1rHggd/dN7l5z977yp1bWNrl7eupXYsVH9fcAd7j72xf86Rrg0vLxpcDHmtkAIUQ+0rMQvceSl9bN7OHAYXc/Uj5/GoWR5S7gb9w9SNpfxPnAC4HbzGxvWXst8KfA1Wb2EuB7wC82tQVCiBWRnoXoXZa7R3418FzgiJmdA/wT8CcUbQ//Fnjpcgt298+x9F2wpx//UIUQTSA9C9GjLHcgX+fu95aPXwBc7u5vM7MasHeZ+XqP0ACXaZppqEWJUVs2pv0HH7f53qT2yKH7ktr6WprKNGTpydUDcxuT2oGptDYdtFEcChKjalNBQtZME0aVyPhCRpSfDDO5POT0bLXgvREY4DzaCwZmtzPWpcmK5238dlL7Wt+pSW3/eGoi/UEtMoympbBlaaDJ/mNBO+SGtqWh2S1qISwNdRXL3SNf+O65gCLsAdd/WIhuRHoWokdZ7oz8M2Z2NUVDhROBz8CDztSV7qcJIToL6VmIHmW5A/mrgF8GdgA/6e7z31I8BXhd1QMTQrQU6VmIHmXJA7m7O8V3TBvrt1Q6IiFEy5GehehdcpLdOgYLOmI2Q9jGNH/mrMlmG8xtM+vTdW5dn5rdImPblno63f0zqWFtInDUPTCbTnfP2Jak5qPpW6IWXHitTQevXWSkCVPcWtjSULd4uxZrcVvivJUG6YtBIiND6eBOCpIVh+tpbVNta1KbmE11NTudpkPWplLbUpisGKW4BWmLjabUONktt61wUBMdQYtDT4UQQgjRTnLamL4ypyaE6HykZyF6j5wz8kuD2otaPA4hRHuQnoXoMZaLaL0E+BXgTDO7ZsGfNgFpMoIQomORnoXoXZYzu32B4jun24G3LaiPALdWOail6Btv7fLCNqbRdPWoZWlam+tPL3DM9TUkuw2kZpNT1x9Japtq6cZGtVpfalQZmVuX1A7NpG0Uv3ckNbvVj6bb1TcRmGimc01sQWpUq9shihw6Ts+RiaulRG1MA81HaYt9g6mz9hEDaaPG04Od0rcCU+pAPdV95NMMjaVBrS9dBX3j6QJrkw3rnQnMbjOBizhqbRoQGYazkVG1ZSz39bPvAt8Fnty+4QghqkB6FqJ3yTG7/byZ3WlmR8zsaE7fYiFEZyI9C9F75HyP/M+AZ7n7HVUPRghROdKzED1Gjmv9PoleiJ5Behaix8g5I7/JzK4CPgo82DPT3T9c2aiWoHJzDEsY2yLTTDRd1Ma04RX2odTgMTxwLKltq6d9CvuDaLv7PU1s+87kcFK77ehpSW1sfDCp9Y2n21CbCVLcIpNLM8YX0S46Rs99kxW/X4I2ph7UGg2pAIOB2W1LLXWYnVRLjaWTnrrnxqfT2txoWuuPWpYG+73QgBomuzVsR27SYhM0ZYATqyLnjHwzMAb8DPCs8ueZK81kZpeb2X4zu31B7fVmdo+Z7S1/nrHagQshVoX0LESPseIZubu/eJXLvgL4a+C9DfXL3P2tq1ymEKIJpGcheo8c1/qjzeza+U/iZvZ4M/uDleZz9+uBB1owRiFEi5Ceheg9ci6tvwt4DTAN4O63As9rYp2/YWa3lpfqTlxqIjPbbWY3mdlNBw4caGJ1QogFtF3P0rIQ1ZJjdlvv7jfaYsPXahuKvhN4E+Dl77cBvxZN6O57gD0Au3btcoD+0TUyUWSaQeb6InPN4ufWly7rxP7U2LY+iHMamUvNafdOp/vOeybTxLYHJlJTzvSxgaS2IR0KfWNRy9Ko9WFa8yg1Kkx7y6spDapp2q7nSMvQBj1Hxq6gZamHvtV0bNvqaYpbv6WJif1Bf9ax6VRrNpHuL8LEtrCWblvfRLpeazS7TQX9T6M2ptE+LzPtLUS6rZScM/KDZnYWhVgxs4spoh6PG3e/z91n3X2O4szgvNUsRwixaqRnIXqMnDPyV1B8mj7bzO4BvgO8YDUrM7Md7j6/03gucPty0wshWo70LESPkeNa/zZwoZltAGruPpKzYDN7P/BUYLuZ3Q38EfBUMzuH4mzgLuBlqxy3EGIVSM9C9B4rHsjNbAvwq8AZQN/8vTV3/63l5nP3S4Lye45/iEKIViE9C9F75Fxa/wTwReA2YE0dC1GaUauJWmxamOwW2AuCyeYaXmGrp8ufbpwI+H5gYptujIkDpgOnzvhsmhh1dHIoqdmxdN76ZFKiNhsluwVvhcg0IzqNjtFzfWoNVh9oeS4wu52wPjW2DVmgXU99giOzqdbGp1JN2kw6lkh//eOp/vpHM1qWAjbTMF1kNA1MbNmthnNNbBbsL2WAaxk5B/Ihd3915SMRQrQD6VmIHiPHtf4PZvbrZrbDzLbO/1Q+MiFEFUjPQvQYOWfkU8CfA6+j/MpK+fsRVQ1KCFEZ0rMQPUbOgfzVwCPd/WDVgxFCVI70LESPkXMg/ypFt6Q1pz9IGGs1FrQ5jAwyHiRERe0QG31stXq6DZOB2S1Kh/ruVNqe9OujO5LaXSPpldJDh4IEqiPptg6MBMaaY+lYahNBGFiU4hYZ4JpJbGs0zcgwc7x0jJ7r4xX/76I2pkH64lzqQ8M9cK4GHPXUnbZvKk1WHJ9IVzJwNF1Hf/BlwCjFrR6kuNVH0zTIJMltOkh2i1LcMtMXs5FOKyXnQD4L7DWzz7K4f/GyX1cRQnQk0rMQPUbOgfyj5Y8QovuRnoXoMXKS3a5sx0CEENUjPQvRe+Qku93GD92t8xwBbgLe7O73VzEwIUTrkZ6F6D1yLq1/kuK+2j+Wz59HkWF2BLgCeFYlIwuoTa6RYaIeRD8FtbmBlY009b7UpNJfS2sHZjYntdkgOm5kOk2ROnhsYzqOkbSNYv+xpBQaCuvjqYktaY8IcZvDqNaM8UWmmWbpHD1PNdEWM4fQpBroNtgLru9PjWObIiNswKGZ9Ult+mjagngoaBkcpbj1jQXGtvHAtDYdvJ6NZrfIfNpEe9KmDHCiZeQcyM939/MXPL/NzD7v7ueb2aq6Jgkh1gzpWYjM8IeDAAAgAElEQVQeI+cj5kYz+/H5J2Z2HjB/yheclgkhOhjpWYgeI+eM/KXA5WY2L/YR4KVlG8Q/qWxkQogqkJ6F6DFyXOtfAn7UzE4AzN0PL/jz1ZWNTAjRcqRnIXqPHNf6ycD/AE519581s8cCT3b3ZXsRm9nlwDOB/e7+uLK2FbiKohfyXcAvufuh3MH2j7b4yl/UWi9qWRolREXJboEnbq7RYxYs/v6p1JwWJruNb0tq+8fTxLbRY6mxpjaWbkPUMrEvMNuEpqSZTGOb6Cg6Sc/1sVTPlVunIt2mcmFjYHY7HBi7DicCh33jJ6SrjVoGT6TrzU1xi5IVrdHYBkmSW3bLUpnYuoqce+RXAP8GnFo+/0/gVZnzXdRQ+33gWnd/FHBt+VwI0T6uQHoWoqfIOZBvd/ergTkAd5+h+PrKsrj79cADDeVnA/OBFFcCz8kfqhCiBUjPQvQYOQfyUTPbRnnVy8yeRPGd09VwsrvvAyh/n7TK5QghVof0LESPkdvG9BrgLDP7PDAMXFzpqAAz2w3sBti5c2fVqxPioULb9SwtC1EtOa71L5vZTwE/QmHV+oa7B66KLO4zsx3uvs/MdgD7l1nvHmAPwK5duxygNtlic0xuSlgtLyEqTJLK6IZ4dCZNZxsPeiveM5aaaL5/8MR0nfen7p11B9OBDB6OUtzSq6w2GSVGBS0Tg9So2FwjI81asRZ6jrQMUAvSAVtpl7RAox5oOUp2q1n6Hj0wm+r0tonTk9o379+e1PqDlqVDh/JaBveNpv+eMFkxalHaaGQLkxaDlqWtTmQUlbLkpXUz+zEzOwUevI/2ROCPgbeVbtXVcA1wafn4UuBjq1yOEOI4kJ6F6F2Wu0f+98AUgJk9BfhT4L0U99P2rLRgM3s/8L+BHzGzu83sJeUyftrM7gR+unwuhKge6VmIHmW5S+t1d593qf4ysMfdPwR8yMz2rrRgd79kiT89/TjHKIRoHulZiB5luTPyupnNH+ifDnxmwd9yTHJCiM5BehaiR1lOwO8H/t3MDgLjwH8AmNkjWf3XVZqiFrTua8ocEyW7Ra0Ko7S3gNk05Cn5qDQzmRpwfjC+KanNzKXj+P4DqbFt5nBqbBs4ms47cDQdWv9o0DIxMLvVJgMTTZDsFhpkMgkNcDLXtJKO07NF76vVLiswsUV4X9BqODK7BTbaO6dOSWpfGjkzqR09mKYtbj6clOgfTd/ffUHaXfg6RSluk6kBtVGToUYzdZttUpVu286SB3J3/2MzuxbYAXzK/UFrYw34zXYMTgjRGqRnIXqXZS+pufsXg9p/VjccIURVSM9C9CY5yW5CCCGE6FB0IBdCCCG6mO5yq86skYkiMMVZkIZUC/wntYZWoXOjaWLbdw6m7UlnZ9J1zgaJbQOHUvPc4P3pOAaOpuMdGElNLvXRILFtOkiRyjXNyMQmliJqhbtKco1YUdJipNv7xtPWwp8/8qikduO+NHJ28N5U47kpbrWJIMUtqDER9CCO2pE2ajfYb4UEGo0Mhc0YXEXr0Bm5EEII0cXoQC6EEEJ0MTqQCyGEEF1MV90jtyDwoKnlRSESUfhLdE83uB9lwX26vvGG54fTe9pTs+uSWm0q6laWfu4aDIImBo5E98PT8dYngk5n08E9r5ngHnkL72+Khygt1HOo5aBWmwk6/gXD+MHhzUnt2GTqUTm6Lw1z2vxAUmLocF74S20s8qgE98ijroI5tWAfle0viKaLQrXkgWk7OiMXQgghuhgdyIUQQoguRgdyIYQQoovRgVwIIYToYrrK7BaartpBFKIQ+Dn6xtLi4JHFn5VmB1IDTv9IaoCLQir6xtLaYKaxLQqfqAfd5MLwiaDTUpaxBmR8EUvTyjCRyHQVGlejYJZ0srF965PaA/2pKXVwf6rddQeDdRxN9131Y0GoS9TVLApkisyms4HWGre31XqUvjuCNTmQm9ldwAhFF9IZd9+1FuMQQjSP9CzE2rKWZ+RPc/eDa7h+IUTrkJ6FWCN0j1wIIYToYtbqQO7Ap8zsZjPbvUZjEEK0BulZiDVkrS6tn+/u95rZScCnzezr7n79wgnKHcJugJ07yw5D7UgTixKigkSj2mRqShk4mtbmBhd/VqpNB13NBoJhBJvaNxYkx00EiVHjUVezIEUqMLuFHZSiWkRuZyXRayyr51DL0FqzWya1yVQHg4fT9+2G76U69eC0ZyhKcTuUblffSJrYZlOBiS0yuwUm39BYmtt9MIPctDfRGazJGbm731v+3g98BDgvmGaPu+9y913Dw8PtHqIQIpOV9CwtC1EtbT+Qm9kGM9s0/xj4GeD2do9DCNE80rMQa89aXFo/GfiIFd/x7AP+0d3/dQ3GIYRoHulZiDWm7Qdyd/828IR2r1cI0XqkZyHWnu5KdmuHOSYyeUwFrQXHUlNcPUiSGmpYXv/R9CWf60/ns6hjYNSCcSI1wliQ8FSLpovMNlHLxMjslmmsyTbNKCHqoUfV5shIB6NpmtqGH6T6rk/2JzUP9pb9x9J1DDyQrqM2HqS4jU+ktdDElpHYBniGKTXUo7TX9eh75EIIIUQXowO5EEII0cXoQC6EEEJ0MTqQCyGEEF1MV5ndfCIwjDSzvMD4YVGKUmTKCaazIHmur6FWX5fGuHl/2goxZCY1pVhgcLHpwDATtUIMzDY+ERhwgnm9mdamQtBiPQeGLQ9MqjYymtQG7k3PZ+pjactS70uni5LiIkOdHUnXGxpLg32IR+2bM01xif6aMbbJFNex6IxcCCGE6GJ0IBdCCCG6GB3IhRBCiC5GB3IhhBCii+kus1uUsNbUAvMMMqEpLmh36oF5zEaOLS70py95rS+KjEqTpcJ2hoFhxqMkqMAUF7dCDKabCUw5AUqNEsdDZJhc9bKiVMHIkHnocFKz0bGk1nd/0Fs40mmUsDaZmt1yzaFhsmS0n1ql1qTR3kRn5EIIIUQXowO5EEII0cXoQC6EEEJ0MTqQCyGEEF1MV5nd5lqd7NZEElnYgNGiz0WTDZOkJrlovnC6aBzRNuS2Dg0XKOOLaA9zrTSvBu/buckgpTDSaLBfydVp7ljUzldUyZqckZvZRWb2DTP7ppn9/lqMQQjRGqRnIdaWth/IzawO/A3ws8BjgUvM7LHtHocQonmkZyHWnrU4Iz8P+Ka7f9vdp4APAM9eg3EIIZpHehZijVmLA/lpwPcXPL+7rAkhug/pWYg1Zi3MbpGLK3GCmNluYHf59JiZfaN8vB04WNHYmiPHz1J4WTp3G/LphW2A3tiO7WY2vw0Pb/O6V9RzR2k51wea7znrhfcP9MZ29MI2YGbz25Gt5bU4kN8NnL7g+cOAexsncvc9wJ7Gupnd5O67qhte9WgbOode2I413oYV9Swtdz69sB29sA2wuu1Yi0vrXwIeZWZnmtkA8DzgmjUYhxCieaRnIdaYtp+Ru/uMmf0G8G9AHbjc3b/a7nEIIZpHehZi7VmTQBh3/wTwiVXOnlyi60K0DZ1DL2zHmm5DE3rWa9859MJ29MI2wCq2wzxowyeEEEKI7kBZ60IIIUQX0zUH8m6NgTSzy81sv5ndvqC21cw+bWZ3lr9PXMsxroSZnW5mnzWzO8zsq2b2yrLeNdthZkNmdqOZfaXchjeU9TPN7IZyG64qDVsdjZnVzewWM/t4+bwbt6Hr9Cwtdw7S82K64kDe5TGQVwAXNdR+H7jW3R8FXFs+72RmgN9x98cATwJeUb7+3bQdk8AF7v4E4BzgIjN7EvAW4LJyGw4BL1nDMebySuCOBc+7ahu6WM9XIC13CtLzArriQE4Xx0C6+/XAAw3lZwNXlo+vBJ7T1kEdJ+6+z92/XD4eoXjTnUYXbYcXHCuf9pc/DlwAfLCsd/Q2AJjZw4D/Cry7fG502TbQpXqWljsH6Xkx3XIg77UYyJPdfR8UwgJOWuPxZGNmZwDnAjfQZdtRXsLaC+wHPg18Czjs7jPlJN3wvvoL4L/zw+yxbXTfNvSSnrtKAwvpZi2D9LyQbjmQZ8W6imoxs43Ah4BXufvRtR7P8eLus+5+DkX62HnAY6LJ2juqfMzsmcB+d795YTmYtGO3oaQbx9xTdLuWQXpeyJp8j3wVZMW6dhH3mdkOd99nZjsoPlF2NGbWTyH897n7h8ty120HgLsfNrPrKO4RbjGzvvITcKe/r84Hfs7MngEMAZspPtF30zZAb+m56zTQS1oG6Rm654y812IgrwEuLR9fCnxsDceyIuV9m/cAd7j72xf8qWu2w8yGzWxL+XgdcCHF/cHPAheXk3X0Nrj7a9z9Ye5+BoUGPuPuz6eLtqGkl/TcNRqA3tAySM/RwrriB3gG8J8U90Fet9bjOY5xvx/YB0xTnIm8hOI+yLXAneXvrWs9zhW24ScpLu/cCuwtf57RTdsBPB64pdyG24E/LOuPAG4Evgn8EzC41mPN3J6nAh/v1m3oRj1Ly53zIz0v/lGymxBCCNHFdMuldSGEEEIE6EAuhBBCdDE6kAshhBBdjA7kQgghRBejA7kQQgjRxehA3gGYmZvZPyx43mdmB+a74RzHcq4zs13l40/Mf8+yybG9qBzL3vLnvatYxjll6MFSfz/XzN7d3EgfXNYVZnZxUB82s39txTpEb2Bmswve13vLyNLjXcZrl/nbXWa2fcHzpx6vpqvCzE41sw+uPOWD019hZmNmtmlB7R3lvmv7cvM2i/YPK6MDeWcwCjyuDDYA+GngnmYW6O7PcPfDTY+s4Cp3P6f8+dVVzH8OxXdVl+K1wF+tbmh5uPsBYJ+ZnV/lekRXMb7gfX2Ou9+1imUseSBvFjOrLHnT3e919+SAtgLfpGxuY2Y14Gk0uZ/KRPuHFdCBvHP4JEUXHIBLKMInADCzDVb0Qv5S2bd2XkzrzOwDZnarmV0FrFswz4NnA2b2UTO72Yq+vbsXTHPMzP7Yip6+XzSzk3MHa2a/Xo7nK2b2ITNbX9Z/0cxuL+vXl8ldbwR+uTzr+eWG5WwCHu/uXymfv97MrjSzT5Xb8PNm9mdmdpuZ/WsZLzm/fW+xoifxjWb2yAWLfYqZfcHMvt3w6fujwPNzt1E89DCzM8zsP8zsy+XPT5T1HeX7eW/5/v5/zOxPgXVl7X3HuZ7zyvfoLeXvHynrLzKzfzKzfwY+VZ7F/7uZXW1m/2lmf2pmzy/f87eZ2VnlfA83s2vLfcG1ZrazrF9hZn/ZqIdyO28vH9fN7K3l8m41s99cYtjvB+b1+1Tg8xRtUee36QXluPaa2d9b0a4WM3unmd1kC/qGl/W7zOwN5et8m5mdHbxO2j/ksNaJNvpxgGMUSUUfpMjc3cvipJ//AbygfLyFIhFrA/Bq4PKy/ngKUe0qn98FbC8fby1/r6NIQdpWPnfgWeXjPwP+IBjbi4AD/DAF6sVlfduCad4M/Gb5+DbgtPmxLljGXy+x7U8DPrTg+euBz1G0JXwCMAb8bPm3jwDPWbB9rysf/+qC1+oKijSkGkWv628uWPZpwG1r/f/WT2f8ALML3tcfKWvrgaHy8aOAm8rHv7Pg/VYHNpWPjy2z/LtKPcyv45sL3qebgb7y8YXzGii1cvcCzT4VOAzsAAYpzoDfUP7tlcBflI//Gbi0fPxrwEfLx6EegDOA28vH/y9F9vr8eJJUt3I5FwNfBE4E3gX8VLmN2ykalvwz0F9O/7fAry5cXvm6XUdxYJ5/feb3G/8NeHewXu0fMn66pWlKz+Put1pxj+4S4BMNf/4ZinD9/698PgTsBJ4C/OWC+W9dYvG/ZWbPLR+fTrGDuh+YAubv2d1McUk/4ip3/42G2uPM7M0UHyw2Av9W1j8PXGFmVwMfZmV2UHxQWMgn3X3azG6jEP/8vavbKHZA87x/we/LFtQ/6u5zwNcarjLsB07NGJN4aDDuRfeshfQDf21m51Ac6B9d1r8EXF6e8X3U3fdmruNp7n4QinvkwLyGTwCuNLNHUXyg7l8wz6fdfWHf8y952WLUzL4FfKqs30ZxoAN4MvDz5eN/oPhgPs9SepjnQuDvvGyd2bDuRj5MkQv+48DLFtSfDjwR+JKZQXHSMN945ZesuBLYR6H3x1JEq84vD4r9z8+Tov1DBjqQdxbXAG+l+BS+bUHdgF9w928snLgUzLIZu+XO40Lgye4+ZkWXoKHyz9NefhSl2Gkdz/vhCopPv18xsxeVY8bdX25mP05xm2BvuUNcjvEF45lnslzWnJktHONcwxh9iceTCx4vbAs4VK5PiKX4beA+irO9GjAB4O7Xm9lTKN7X/2Bmf+7ux238XMCbgM+6+3PLD/DXLfjbaMO0C9/PcwueN+phITl6WFjLzer+APBl4MpSnwuXcaW7v2bRgs3OpPjw8mPufsjMrmCx3ufHttT+R/uHDHSPvLO4HHiju9/WUP834DetVI2ZnVvWr6e8p2Nmj6O4vN7ICcCh8iB+NkWrv1awicIc0s+C+0pmdpa73+DufwgcpLgCMFJOH3EH8Mgl/rYSv7zg9//OmP7RFLcWhFiKE4B95RnbCynO+DCzh1P0jn4XRfew/7ucfnr+vuwq1jNvFHtRUyMu+ALFmTIUevzcccz7KeDlVprrzGzrUhO6+/eA11FcOl/ItcDFZnbS/DLK12wzxQeTI+XZ788ex7hA+4csdCDvINz9bnd/R/CnN1Fceru1NKi8qay/E9hYXlL/7xQdcxr5V6CvnOZNFPe4WsH/D9wAfBr4+oL6n5fGk9spPmh8haIt32MtMLu5+9eBE2zB11qOg0Ezu4HiXuFvZ0z/NOBfVrEe8dDhb4FLzeyLFDv2+bPjp1JcYboF+AVgXqd7KHR5XGY3ikvff2Jmn6f8sNAkvwW8uNT5Cyk0kcu7ge9RbMdXgF9ZbmJ3/3t3/1ZD7WvAH1AY9G6l2C/s8MKkdgvwVYoTlc8fx7i0f8hE3c/EmmNmvw2MuHv2d0XN7C4KY9/B45jneuDZ7n7o+EcphFgLtH9YGZ2Ri07gnSy+b9VyzGwYeHs3ilSIhzjaP6yAzsiFEEKILkZn5EIIIUQXowO5EEII0cXoQC6EEEJ0MZUfyMsc31us7PpjZmea2Q1mdqeZXWVFFrcQosORloXoTNpxRv5Kii/1z/MW4DJ3fxRwCHhJG8YghGgeaVmIDqTSA7mZPYwi0vDd5XMDLqBoDgJwJfCcKscghGgeaVmIzqXqM/K/oEgcmyufbwMOz4fzU3T5Oa3iMQghmkdaFqJDqaxpipk9kyKb+OaycQfEgf3hF9nLbjm7ATZs2PDEs88+mztvuSudeW4uqT3ksehlDiZr+XqDWmZMQTiZMg6yefQTHwHAzTfffNDdh1u57Cq0DEjPuVSt59wZc7Us3TbFarRcZfez8ylabz6DoqvMZopP9VvMrK/8JP8w4N5oZnffQ5FjzK5du/ymm27ios0vTqabPXasouG3Ecu7MGK1TMWt0fKIljcXiNrTnbUH0/ns7MrrDJb1UOTTN/0TAGb23QoW33ItA1x0wq8l086OjFQw/BaRq4Psxa2BnqNl5Y4jV8uBbiN9S7sxq9FyZZfW3f017v4wdz+DoivPZ9z9+RQNNC4uJ7sU+FhVYxBCNI+0LERnsxbfI/894NVm9k2K+2zvWYMxCCGaR1oWogOo8tL6g7j7dcB15eNvA+e1Y71CiNYiLQvReSjZTQghhOhi2nJG3jIy3ZsdTYuNaFavp8WgFk4XLjDzNQ6cqbHjePUO1ug1CE0zojvJfU+uBW0wjIbzRuutR/MG0612/9hqLYfbGhlcg22QAW5V6IxcCCGE6GJ0IBdCCCG6GB3IhRBCiC5GB3IhhBCii+kqs5sN9ECXxEwzR2QEyTV/GUGyUrSSwBxj/f1Z4wvnzZszZnIyKfn0TFJrNM3IMNO92EDme20taEKnMVFKYWBKDUxh0ayRnnONrwnBfiVby7PBeKemklKOlkF6Xi06IxdCCCG6GB3IhRBCiC5GB3IhhBCii+mqe+QMDa71CKqhxV2VwuVF97SD19OGhtJ51wW1KHxiJriZN5PeGyOnq9kS6/Cp6caF5S1LdB6drOe16nQWEQXCBF4WGww8RI2v8WDmax5pdDK9900UHJMZTBPdN5eeV4fOyIUQQoguRgdyIYQQoovRgVwIIYToYnQgF0IIIbqY7jK7PcS7nzXT6cwik0tfsLwodCeaLvpfNNE5LQqliEheF49CchQq0RWshZ47qatZMxqPwnT6gt15gynOIy0HhFsfzTud2xFtlfoGXP63FansjNzMhszsRjP7ipl91czeUNavMLPvmNne8uecqsYghGgN0rMQnUuVZ+STwAXufszM+oHPmdkny7/9rrt/sMJ1CyFai/QsRIdS2YHc3R04Vj7tL38yr8MIIToJ6VmIzqVSs5uZ1c1sL7Af+LS731D+6Y/N7FYzu8zMOjgVQggxj/QsRGdSqdnN3WeBc8xsC/ARM3sc8BrgB8AAsAf4PeCNjfOa2W5gN8DOnTuLYpBw1Atkm2MyTWy2fl06b4s7x3l/YHyJagPBmMcDk890Y2IbUEtrOgVcO1ar51DLEJuzOoSwq2Ck09BEmWkoi/S8YX064bpAz5mmtcRYGu1Cg3GE+g7WaeNp18JQy1HCY66xLdoXyry6iLYcGd39MHAdcJG77/OCSeB/AuctMc8ed9/l7ruGh4fbMUwhRAbHq2dpWYhqqdK1Plx+csfM1gEXAl83sx1lzYDnALdXNQYhRGuQnoXoXKq8trUDuNLM6hQfGK5294+b2WfMbJjiq4p7gZdXOAYhRGuQnoXoUKp0rd8KnBvUL6hqnUKIapCehehcOtdtEjC3dVNa/G77x3FcNBg1co1tYcJTlI4UpaRFLQgDc4hvTE0009s3JrW5gWB8M+l6a9PpeuujaetDmw3GHJnxclqg5rZEFR3H7PZAz99q4QpanOIWa7K1iW1hW9BIB4HxbG5zqufJ7YtrXk/HVp9K11kfT3VVi7QcjXc60HLUsjTSrvS8KnrTBi6EEEI8RNCBXAghhOhidCAXQgghuhgdyIUQQogupqvMbj7Q4cPNNNesfvFR2lteAhxDaQLc3Ia0NjuUzju9IV3HXH9kmkn/P33r09rg/RNJrTaVpkHZZJA41WD4C01EpIYZtTbtPOai1L81GEdIrpaj95AF+6ncVqT9QS3S7qahpDazKZhucPF2RFrG07FFWh44nE43cH+QgDeeZ95t1HIxYdQWNjDqSs+L0Bm5EEII0cXoQC6EEEJ0MTqQCyGEEF2MDuRCCCFEF9Ph7rHFzGxMjSCZzfxaz2pTo3JT3AITW9SylK1bktLUjs1JbfqE9LWbGUrXMb0+aC2Y+SJHBri5vsi+lBp1BmdSo0pogJtY3DbRo9SriIewEaZTmd4YGKpyZmxxYltssMptLZynZ4tatq5LdTA3nOp5fEfa2jQyrc0OpGOeGVr5NagFSYuRbj0w8Xl9Q1IbDNImbSY1oNpUmhRHLdVz2NpUel6EzsiFEEKILkYHciGEEKKL0YFcCCGE6GJWvEduZjXgCcCpwDjwVXe/r+qBCSFaj/QsRO+x5IHczM4Cfg+4ELgTOEDhUnq0mY0Bfw9c6d4+10GUOrZmZrdVkt0yMUp4iuadnExKA/uPpbPOpKYU355ai6bXR8lugYkt8uel3jQGRoLa0aDNY9SONao1ptuFxqfAHRNN9xAyzHSinmeC91qW2a0ZmjG25bYn7Q92q1GKWy2dt3YsTT0c2h+kKG5Oja+TJ6brnVm3eN7pdDcQtjbtH02nMw9euyOB2TRqbRoRJVXm8hDXcyPLnZG/GXgn8DL3xXtUMzsJ+BXghcCV0cxmNgRcDwyW6/mgu/+RmZ0JfADYCnwZeKG7B/ZFIUQLkZ6F6FGW/Ejk7pe4+/WNoi//tt/d/8LdQ9GXTAIXuPsTgHOAi8zsScBbgMvc/VHAIeAlzW2CEGIlpGchepes75Gb2U8AZyyc3t3fu9w85Q5j/hpvf/njwAUUn/6h+PT/eoozBSFEG5Cehegtcsxu/wCcBezlhzcfHVhW+OW8deBm4JHA3wDfAg67+/yNlbuB045/2EKI1SA9C9F75JyR7wIeG12SWwl3nwXOMbMtwEeAx0STRfOa2W5gN8DOnTsBGD1pDcwx0FSSVGKGyUx9ClscDgRbG6RDTQ9vTGqjp6XmmJHT0u0a3RkYRk5MDXVRv0kfScc8dF+6vXP1dHvrE+uS2sBYut4k2a0W3I7NNcA9NGm7niMtA4yekv6fkgyzZlLccluRNpPYFmky1G7UnjSdd/aEVAfjp6S10ZPTsYyemq5icudifQxsTPUyMx1o9HA6tvX3RFpOpzthPE2i65sInLATqbEvbME8F71VpeeF5LzTbwdOaWYl7n4YuA54ErDF7MGsv4cB9y4xzx533+Xuu4aHh5tZvRDih7Rdz9KyENWy3NfP/pni0/Um4GtmdiOF4QUAd/+55RZsZsPAtLsfNrN1FF97eQvwWeBiCqfrpcDHmt0IIcTySM9C9C7LXVp/a5PL3gFcWd5XqwFXu/vHzexrwAfM7M3ALcB7mlyPEGJlpGchepQlD+Tu/u/zj83sFOA8ik/0X3L3H6y0YHe/FTg3qH+7XJYQok1Iz0L0Ljmu9ZcCfwh8hsLi9Fdm9kZ3v7zqwSVjOW57ztrjDUYNizYi8h1FBo/B1FgydfKmpHb0zNQAN7ojNQNNnBS0G9wWGMzq6XSz4+lbpzaeWi7qY0mJvsA7V5vOS2VKgsei1+khnPC0Ep2k59jmWi3ZrU0jcpPIoumCpMbI2DZyRmoUO3ZqurzxU9IXb2ZLagBbv2V88TSzqZlsdizVcv/RdLq+IO2tfzTVmk0FRrTZQJORdqXnVZHjWv9d4Fx3vx/AzLYBXwDaL3whRLNIz0L0GDkfMe8GFiZmjwDfr2Y4QoiKkZ6F6DFyzsjvAW4ws49RXAx7NnCjmb0awN3fXuH4hBCtRXoWonSSntAAACAASURBVMfIOZB/q/yZZ/7rJenNWSFEpyM9C9FjrHggd/c3tGMgOUxtbMKokkszSVI500XzRWlGQbJURN+xNKlp/X3pv3V6Y2q2mdwerHYwNaqce+o9WWO57b40Z2TcNie1gZH0NVg/GJhrLOM1bsa89BCkk/Q8nQYQZpGb4tZMe9KmiN63Qc1mUhPX4KG0LejsYKrd6WBfOHNCutrN6xY7S5988neSae4d35LU9u5LY+LGLP2sNzCSvp7r9gftpjP3Z9Lz6shxre8CXgc8nMVNFh5f4biEEBUgPQvRe+RcWn8fhdP1NkDfAxCiu5Gehegxcg7kB9z9mspHIoRoB9KzED1GzoH8j8zs3cC1LM5m/nBloxJCVIX0LESPkXMgfzFwNtDPDy/FOdB+4Wf6JdaMyEjTUAtblg6lLUbZuCEpzW1Ok6CmtgYtDnek6xjbka6i/vA0qunJp9+V1M5cfzCpffVoaoaZGE+T5/qPpuaVgWNpelPfWNDmcCpoUdqYEDWrdobHScfo2QOPZ3br0VYSGdHClqVBK9L1qf6i1sKzG9Pa1NZU9xPbUu3GqYzpXZHh0w8ltUZz246BI8k0kdltaixoSTySlOgfTbVcj7Q8GWk5SoCTnldDzoH8Ce7+o5WPRAjRDqRnIXqMnI+/XzSzx1Y+EiFEO5Cehegxcs7IfxK41My+Q3FPzQDX11WE6EqkZyF6jJwD+UWVj0II0S6kZyF6jCUP5Ga20d2Puft3V5qmmqGlzKZequ4jalkaERhw5oKEp6kT0n/h+HA671TQ4nB4/XhSi4xtT1yfpkFNz6VmoLu2nJjUDg2lZqC54F3nOSluYtV0pJ4Dj2craWwhDGCRwS4it2VpoGfvT1cyN5TWZjaktbGT8lqW9g2n2j1109GkdsbQYj2fPXhvMs3BIGLv9k1pSuPMQGrYm+tLdevNtHvNRa1NF7HcK/kxM3ubmT3FzB60UJvZI8zsJWb2byzz6d7MTjezz5rZHWb2VTN7ZVl/vZndY2Z7y59ntG5zhBBLsGo9S8tCdDZLnpG7+9NLYb4MON/MTgRmgG8A/wJc6u4/WGbZM8DvuPuXzWwTcLOZfbr822Xu/tbWbIIQYiWa1LO0LEQHs+w9cnf/BPCJ1SzY3fcB+8rHI2Z2B3DaapYlhGie1epZWhais2lL+oKZnQGcC9xQln7DzG41s8vLM4Nont1mdpOZ3XTgwIF2DFMIsQLSshCdR45rvSnMbCPwIeBV7n7UzN4JvIkiTepNwNuAX2ucz933AHsAdu3a5QDWDn9DZKKoOm1qLljndJqOVJtKWxzWZgJDTxSOtC5dxyNPTI1tjx5Kr65urk2k67V0vccmUvdSfTIp0TeRzlubDNKgptPtbUx+igxNUU3mmOZppZZh9XrONbHlthpuimgskU6n042tTQc6CGQQ6XlwMF3Hj2y6L6mdM/S9xcsP+uQM1tJlTU2lh4a+IJytfyzYrlDLac2jWpDsFupZLKLSI5SZ9VMI/33zWc7ufp+7z7r7HPAu4LwqxyCEaB5pWYjOZbmvn21dbkZ3f2C5v5uZAe8B7nD3ty+o7yjvuQE8F7g9f7hCiNXQjJ6lZSE6m+Uurd9MccnMgJ3AofLxFuB7wJkrLPt84IXAbWa2t6y9FrjEzM4pl30XhYtWCFEtzehZWhaig1nu62dnApjZ3wHXlI5XzOxngQtXWrC7f45iR9HIqlzwQojV04yepWUhOpscs9uPufvL55+4+yfN7E0VjmlJQhNXp9NouAnamDKYmsR8c9rGNGpZOrY9dflMBhdRa0OpoWViNk2KOzy7PqltqaftTu+eSFsfjh9Jk582pZ0VGTic/iMjgxAzaS0xw8jEdrx0jJ4Dj1UWrTaxWZQwVg9q/UEb06AF8eymoN3wCWks5cTWPO3OnJC+UIP9ae3oTKq//bObFj3fUEvdp98cHU5q0w+ky9pwOB3bwNF0HDYRmN1mopal0m6ryDmQHzSzPwD+F8UltBcA91c6KiFEVUjPQvQYOa71S4Bh4CPlz3BZE0J0H9KzED3GimfkpZv1le1uqCCEaD3SsxC9x4pn5Gb2E2b2NeBr5fMnmNnfVj4yIUTLkZ6F6D1y7pFfBvwX4BoAd/+KmT2l0lEtQVuS3VpNYypRkFwU1cJ0qJm8F8CDj2eDQ6kB5ayNabLbz2/8RlI7qZ62Obx+cCRYcWpCCgLgQizattyWr+J46Bw9r9K8Gia71dL3j8+lQogS4DxIVrQoVbAeJZalu9Ao2awW9GAO5IJHCXV96faeMJS2MX38xruT2i9sCHTawKeH0van1ILXONr9hLXgfxGZUtuRvPcQISvZzd2/31DqRv+4EALpWYheI+eM/Ptm9hOAm9kA8FvAHdUOSwhREdKzED1Gzhn5y4FXULQtvBs4p3wuhOg+pGcheowc1/pB4PltGIsQomKkZyF6jxUP5Gb2aOCdwMnu/jgzezzwc+7+5spH1ziWbjS7NRo6+oOXPKj5YJoiNbMudcLMpgFMeH/QHjEwr4wFyW53TqfJbncGLRhvfuD0pFY/lG7HwNF0vQNH85KfopaGUdtIkU8n6ZlV/ivDZLeg1XA4XVCLk90C11mU7BbU5nK1O5iOZS5YbRSOOxs4Wo/Mpolyt00tNsUdnkunufn+VMv996daHjyS/sP6RoLepkF70jDFLVfLSm9ckZxL6+8CXgNMA7j7rcDzqhyUEKIypGcheoycA/l6d7+xobbKlGQhxBojPQvRY+QcyA+a2VmUF8LM7GJg3/KzCCE6FOlZiB4j5+tnrwD2AGeb2T3Ad5BZRohuRXoWosfIca1/G7jQzDYANXdfOSoIMLPTgfcCp1Dk/+xx93eY2VbgKuAM4C7gl9w9aHYZLLODYivCdKnIqNJIpunD64ERZiC9gDK1KSkxuzU1m2xeN5HU1gdJVWf0py1LH5hN3yYHRtO0t4FD6ZgHRoLUrKngHxkZZGRsazmdpOfVtjFtKtktyL6J3mUWtRuOzJdR+mCk3f60FhlVp05Mt2PTlrGkduJgmux2Qj2tndm3eL23BN60+4+lLZMHgpal/cfS7a9F7YfDfVyU3JhpYguMjDLALSYna32bmf0l8B/AdWb2DjPblrHsGeB33P0xwJOAV5jZY4HfB65190cB15bPhRBtQHoWovfIuUf+AeAA8AvAxeXjq1aayd33ufuXy8cjFOlRpwHPBq4sJ7sSeM7xD1sIsUqkZyF6jJx75Fvd/U0Lnr/ZzI5LrGZ2BnAucAPF91f3QbFzMLOTjmdZQoimkJ6F6DFyDuSfNbPnAVeXzy8G/iV3BWa2EfgQ8Cp3P2qW1/HGzHYDuwF27txZFnPXWj1R2EQYQNFIPQqfSGven95wn1kX3GdL8x2oD6X3svrraW02aL/0takTk9pNY49IakePpiteP5mOpTYbdVHKDIdQ97MqaLueQy0Td+nLGkNmIExIEPRiUfhLRBQcE9Q8eE1mB9LaTKBdX5fqdKg/9Y8M1NLpjgU33W+aWrySTx390WSa0SPpQDYH99Lj7meZ98ObQffDVyTn3f8y4B+BqfLnA8CrzWzEzIL+dz/EzPopRP8+d/9wWb7PzHaUf98B7I/mdfc97r7L3XcNDw/nbY0QYiXarmdpWYhqWfFA7u6b3L3m7n3lT62sbXL3zUvNZ8VH9fcAd7j72xf86Rrg0vLxpcDHmtkAIUQ+0rMQvceSl9bN7OHAYXc/Uj5/GoWR5S7gb9w9uPiyiPOBFwK3mdnesvZa4E+Bq83sJcD3gF9saguEECsiPQvRuyx3j/xq4LnAETM7B/gn4E8o2h7+LfDS5Rbs7p9j6bvaTz/+oQohmkB6FqJHWe5Avs7d7y0fvwC43N3fZmY1YO8y84mF5Jj7IqNOpmFmdijoSDSQhjRsG0pDJTbWU3falKdvibHZgaTms+lYooAPC8xua2JiU6jEQ07PoSkuMlVmet2ytAx4XzpdFPAUmd361qci2jiY6vSUodTO0B8kZo00dDs7OpMa4nw6MO4GWq5NBXqJ9N1qs5u0uyLL3SNf+N+9gCLsAXe9gkJ0IdKzED3KcmfknzGzqykaKpwIfAYedKaudD9NCNFZSM9C9CjLHchfBfwysAP4SXef/zLjKcDrqh6YEKKlSM9C9ChLHsjd3Sm+Y9pYv6XSEQkhWo70LETvkpPs1jGEyUI9yuxg6sCZ2hgYZjalBpd1fWltJugEdWx2MKl9fzrtn/G98a1JzUf7k1rUna42HZlh0lLlBjjdCu44WtrNMPz/Bi62nPTF45kuSmXsS2szqdSYPiF9z28I4hH7gs5uh6dTp9yRgbR219T2Rc/vGduSTFMbS1+nenCzJUppzCZT31FnO7EyqwxJFEIIIUQnkNPG9JU5NSFE5yM9C9F75JyRXxrUXtTicQgh2oP0LESPsVxE6yXArwBnmtk1C/60Cbi/6oEJIVqH9CxE77Kc2e0LFN853Q68bUF9BLi1ykEtRX2ig4wQuW0TG2eL5uvLM+WEbR9rgWFmMHWqDNWDxKgg2W3a07H8YHxTutqJdDDB4vLJTM0Sq6bz9NzM+6WRVeqxmDdINstMW4wS2+YCs9tcf6Tn1MTWHxhVtwxMJLV19bS1aZTs1tja9L7RVMv18UDLU5kmVdERLPf1s+8C3wWe3L7hCCGqQHoWonfJMbv9vJndaWZHzOxoTt9iIURnIj0L0XvkfI/8z4BnufsdVQ9GCFE50rMQPUbOjaX7JHohegbpWYgeI+eM/CYzuwr4KPCgPcXdP1zZqJYgNGB0EjmGmygxKkiHmh0IamkHQrwvfU2mgxS3uaCV9Phc2p70nskTk9oD4+uTWm0y2I7g3xOl8VmU8pTb+lAJbc3SOXpupdktl8hUWQt0m6nT0AAXTBa1LPXB9L1slmpjJljg+GyarHgkWMkD0xsWPT80mk4T/h9CLadFi3Qb6Ntb3dpULCLnjHwzMAb8DPCs8ueZK81kZpeb2X4zu31B7fVmdo+Z7S1/nrHagQshVoX0LESPseIZubu/eJXL/j/tnXu0JFV1xn/ffTG8BHFGMj5GVNBIohCdEARJ0ChBjKIrYwSJYpRMkuVb89BoMBpMMJhoVowxo+KgS8mYKEaNMuD4GECRhwwzIwZRgskoYQR1mMd9z84f5zRTt2vfe+v27b7d1dm/tXrdqnNPVZ3TXV+fqjpf770eeB/w0aby95jZu1vcZxAEiyD0HAT9RxXX+uMkbWpciUt6kqS3zredmW0GftKGNgZB0CZCz0HQf1R5tP5B4M3AJICZbQXOWcQxXyVpa35UV56QDYKgk4Seg6DPqGJ2O8TMbtBMU0c5TFg1/gn4S5KV4i9JEaZe7lWUtBZYC7Bq1SoAhvf1kNmtYtpENRtpKkYws2EvOlS5noaqmUi8NKb3TZRNbFP7y33YM1rOwThYDjbF0Hj58xmYcNo37eSv9AxwXr3mzSLt4UJZcj17WgYY2dthA1TVaG9VjVjeueYY5fxob87+RsrHXTZU/ig87Y45ZrcfjpVTlO6bmmlondhX3u5gR8ved+3AuKPHaU/fVQ1wFbUbBtd5qXKm3yvpsWQfo6Q1pFCPC8bM7jGzaTPbT7ozOGmOuuvMbLWZrV6xYkUrhwuCoMyS6zm0HASdpcod+SuBdcDPS/oh8F/A77RyMEkrzazxpfECYPtc9YMgaDuh5yDoM6q41u8EninpUGDAzHZX2bGky4HTgeWSdgBvA06XdCLpbuAu4PdbbHcQBC0Qeg6C/mPegVzSkcBLgWOAocbcmpm9Zq7tzOxcp/jDC29iEATtIvQcBP1HlUfrXwCuB7bR5UR2g2M9bnpo0ZRhXmQpL4qSZ0kaL5vTpqbL+/MMM4NOFKl9jitncqxctsyJBjXgtM+NBjXdemS3ZoOMvHSvYYCbix7Scxc+J89U6enPw4nsZm6kOCctqnNYm3JMbFNlrU04BtQBb4cO90/MNKravvL+PeOqq1GPiNjWE1QZyJeZ2Rs63pIgCJaC0HMQ9BlVLkU/Jun3JK2UdFTj1fGWBUHQCULPQdBnVLkjnwAuAd7CgVD6BjymU40KgqBjhJ6DoM+oMpC/ATjWzO7tdGOCIOg4oecg6DOqDOTfJmVL6jqDY/NH+loyqkaNKm3nmGOGnChuThrTShMhwNR02Ryza6KcA9VLj7hrrJzmcP/ecjSoIeeMGNpXNr640aAmHVdci6kPw9i2YHpGz0OjXTBKVYys6NYbLOvKhstl+4cqRnZzmJgsV7x/vKzdXVY+xogTFe6+PTPTmA7uKbd3eG+5Hb6WJ8sVJ8pl5pl+PZ1GxLa2UeX0mga2SPoKM/MXz/lzlSAIepLQcxD0GVUG8s/kVxAE9Sf0HAR9RpXIbpctRUOCIOg8oecg6D+qRHbbxgF3a4NdwE3ARWZ2XycaFgRB+wk9B0H/UeXR+hdJ82qfyOvnACKJfz3w3I60zGFgssfNEZ4Brtk046U9dMoqG2amy/UmJ8uGlmknstu4E0Vq7/hIqWzAMcgMOdGgBscdg8ykY3abKptyzClzo3AFi6V39OyluG02QLVqKl0IFY1trnYdo+r0sLM/z2PnRGfzojJ6Oh0ZLOtq70RZu/t2z4zsNrK33JCh0XI7hhxjsSYcjXqphj0za9BRqgzkp5rZqYX1bZKuM7NTJbWUNSkIgq4Reg6CPqPK5e5hkn6lsSLpJOCwvBqXXkFQL0LPQdBnVLkjvwC4VFJD7LuBC3IaxL/uWMuCIOgEoecg6DOquNZvBJ4o6QhAZvazwr8/2bGWBUHQdkLPQdB/VHGtHw38FfAwM3u2pOOBp5rZkuciHhidKJX1uP2tjGuscVJxetkRvTShk+WKUxNlo45nYhsdKEdsGx0rlw2OlY8xMFE2yAw65iXfIFMx8pNHlWhQETFqVnpJz4OjS/8kX17KUiftqJvadMiJ7OaYUs3xyXl61oSTxnRfWafmbDw2UD7HJ52ocDY6s8xLWTroaNmLyKgpT7eeYbFaFDc3KmNotyWqzJGvBzYCD8vr3wVeN99Gki6VtFPS9kLZUZKulnRH/vvgVhodBEHLrCf0HAR9RZWBfLmZfZJ882tmU6Sfr8zHeuDMprI3AZvM7DhgU14PgmDpCD0HQZ9RZSDfK+kh5CASkk4m/eZ0TsxsM/CTpuKzgUZkqcuA51dvahAEbSD0HAR9RtU0pp8FHivpOmAFsKbF4x1tZncDmNndkh46W0VJa4G1AKtWrWrxcEEQNLHkeg4tB0FnqeJa/5akXwMeT4pPdLuZOfns2ouZrQPWAaxevTrdPXjGqV6iimmmarQyLxKU4wMZGC9XnHYiu+3ZXU6F6LF/V9lsc8jucr1hJxqUF6lLXmQ3LxqU975EitK20w09e1oGPy3m/k5HcnPMpqoSkREwz6jq1XN25xngNOVEbxwvVxz3PGFOBDhGnRSlP51ZNrynvNnwXi9lqfNd66UxnSpr2Us/HOmGO8usqpH0y5J+Dh6YR3sK8E7gbyUd1eLx7pG0Mu9/JbCzxf0EQbAAQs9B0L/Mdfn7z8AEgKRfBS4GPkqaT1vX4vE+C5yfl88H/r3F/QRBsDBCz0HQp8z1aH3QzBrmlhcB68zsU8CnJG2Zb8eSLgdOB5ZL2gG8jfTl8UlJrwD+G3jhYhofBEFlQs9B0KfMOZBLGsqP4X6dbFapsB0AZnbuLP/69QW0LwiC9hB6DoI+ZS4BXw58TdK9wChwDYCkY6nwc5VOIM+A0faDlGcb5JnYWt6/s6/pshFEnrHN6f6AE9ltem/Z9LJ/2JlFcbYd2u0YZvaWNx3aV9Eg45hh3GhQboSoiPLURnpPz2Ne6trW0pi6Gq2q20Vsa149R+MD5aCUbsRE5ESPmyy/B57JdWC0XG+4yag6sttJWbq3YspSL/1wVeNq0FFmHcjN7J2SNgErgavMHvh0BoBXL0XjgiBoD6HnIOhf5nykZmbXO2Xf7VxzgiDoFKHnIOhPOvyjzSAIgiAIOkkM5EEQBEFQY6qEaO0dPONUu3HT7TkGOCdSU6vIMXoNjTlljpllxLEpabrcuOllTtpRx2zjRX4aud8xyDhmNzeKW1WzW0WDTESI6h/URj1754WrUS896SKQk5J30AnFNuRobf/ucpmnST8qXLms2dgGMNJsdrvfaa9jOnSNxZNOZLeqERnDuNpR4o48CIIgCGpMDORBEARBUGNiIA+CIAiCGhMDeRAEQRDUmHqZ3Sac8EjtZjGR3TyTR7Oxy4uENOUYUPaV6404Udf2D3nRocpFQ/scY814uZ5ndjtol2focaJBeWa3iiYXL/VhxQ1b2y7oPuPOCViFqhr1oihWxTGxuU1xojIOjpe3HXGMbV77pstZhF0Gx5wy5+08aPfMtozsLmvUjchYNWKbWy80udTEHXkQBEEQ1JgYyIMgCIKgxsRAHgRBEAQ1JgbyIAiCIKgxXTG7SboL2A1MA1NmtrrShp6xoku0nNrUMYx4Ea6G9pWjKB10f9nsJifs06SXHtFhYLLcluG9TtmecvsGnfbJMe25pqGK0dkiils9aF3PbTQ4ari1fUFlU5wmy6awgbGyDob2lr9Wlzm3TANTTgTGqmY3x/c7NOpFYJyp3aE9jm5HnYhtE+Uyq5rG1MHVcpji2kY3XetPN7N7u3j8IAjaR+g5CLpEPFoPgiAIghrTrYHcgKsk3SxpbZfaEARBewg9B0EX6daj9VPN7EeSHgpcLek/zWxzsUL+QlgLsGrVqm60MQiCasyp59ByEHSWrgzkZvaj/HenpCuAk4DNTXXWAesAVq9enZwSrUb/6gBu2sRhJwVhsxnEMYzIiVg3sK9s3hm+v/xxyXlLvOhs5pjzvAhUQ6OOsW3Ua7MTDcoxyHgGRc80UzWNadB7zKdnV8vgaqEZP2JbtQeJ8lKWesY2z3Tn5Ql10ngOjJYNa0ODjil1f1nPntnUvEiNjjS8bQfHnKhtEzPLBlyTqmNY81KWVjQnhkl16VnyR+uSDpV0eGMZOAPYvtTtCIJg8YSeg6D7dOOO/GjgCqUr4yHgE2Z2ZRfaEQTB4gk9B0GXWfKB3MzuBE5Y6uMGQdB+Qs9B0H3i52dBEARBUGPqlca0100UXpSjZuOLEx2KsXL+QTmGmWHHqDPoRJHav6y8rQ2Wr9majTCzlWmsbMaTE9HK64c5qSrNMdKY8764UaMiGlT/UMHg6JpKy6f3LNuWzxVVjU5mjrHUa69TNuiYxwbGyyHbBkfLBjjzDHqe4c97X5zIigPjM7Xm6nbfaLnM6YOn20hj2hvEHXkQBEEQ1JgYyIMgCIKgxsRAHgRBEAQ1plZz5N58a9dw5oHMmS5qnt1yZwXHnTlop5qc+ajBZQeVygZGneszZ87dC7BTde4bJ4iNjY6Vy7ygH4uZV2sOBhLzcbXFnPO+mZazDII7f101W5fvd3ECI3lBUpz5ZTnzy+4c+bDzlezdbrkxbJw2N39nOu+5ed4Wbz68or8gAsIsPXFHHgRBEAQ1JgbyIAiCIKgxMZAHQRAEQY2JgTwIgiAIaky9zG5eMJW2H6Saia1qBiZo2tgz0XiGEcfYJy9wzEjZMOPZg1yTj2NKcc0rFQ1rrsmlohltMdsG9cQcw2Spjhf4ZMDRqBMMZVE4+jaczGFexr/RcoAVL8ATjrFN3nE9HTgmOy8ATkm7FTXvfg9WNbGFbpecuCMPgiAIghoTA3kQBEEQ1JgYyIMgCIKgxsRAHgRBEAQ1plZmt/0VzDFLRlUTV4VAUq6JxDH2yet/VdNdmFeCHqOK2a2y+bTtVDtI1Uhxi4lQt6hIaaHd/xd05Y5c0pmSbpf0PUlv6kYbgiBoD6HnIOguSz6QSxoE/hF4NnA8cK6k45e6HUEQLJ7QcxB0n27ckZ8EfM/M7jSzCeBfgLO70I4gCBZP6DkIukw3BvKHA/9TWN+Ry4IgqB+h5yDoMt0wu7mBx0qVpLXA2ry6R9LteXk5cG+H2rZUzOxDVS9Lb/lW+uFzgP7ox3JJjT48aomPPa+e+1rLVrEPvaVdj/p/Fv3RByQ1+lFZy90YyHcAjyysPwL4UXMlM1sHrGsul3STma3uXPM6T/Shd+iHfnS5D/PqObTc+/RDP/qhD9BaP7rxaP1G4DhJj5Y0ApwDfLYL7QiCYPGEnoOgyyz5HbmZTUl6FbARGAQuNbNvL3U7giBYPKHnIOg+XQkIY2ZfAL7Q4ualR3Q1JPrQO/RDP7rah0XoOd773qEf+tEPfYAW+iGzRUQNCoIgCIKgq0Ss9SAIgiCoMbUZyOsaBlLSpZJ2StpeKDtK0tWS7sh/H9zNNs6HpEdK+oqk70j6tqTX5vLa9EPSMkk3SLo19+HtufzRkr6Z+7AhG7Z6GkmDkm6R9Pm8Xsc+1E7PoeXeIfQ8k1oM5DUPA7keOLOp7E3AJjM7DtiU13uZKeCNZvYE4GTglfn9r1M/xoFnmNkJwInAmZJOBt4FvCf34afAK7rYxqq8FvhOYb1WfaixntcTWu4VQs8FajGQU+MwkGa2GfhJU/HZwGV5+TLg+UvaqAViZneb2bfy8m7SSfdwatQPS+zJq8P5ZcAzgH/L5T3dBwBJjwCeA3wor4ua9YGa6jm03DuEnmdSl4G838JAHm1md0MSFvDQLrenMpKOAX4J+CY160d+hLUF2AlcDXwf+JmZNXLG1uG8ei/wJxyIFfYQ6teHftJzrTRQpM5ahtBzkboM5JXCugadRdJhwKeA15nZ/d1uz0Ixs2kzO5EUfewk4AletaVtVXUk/Saw08xuLhY7VXu2D5k6trmvqLuWIfRcpCu/I2+BSmFda8Q9klaa2d2SVpKuKHsaScMk4X/czD6di2vXDwAz+5mkr5LmCI+UNJSvgHv9vDoVeJ6ks4BlwINIV/R16gP0l55rp4F+0jKEnqE+d+T9Fgbys8D5efl84N+72JZ5yfM2Hwa+Y2Z/V/hXbfohfEX11gAACj1JREFUaYWkI/PywcAzSfODXwHW5Go93Qcze7OZPcLMjiFp4Mtmdh416kOmn/RcGw1Af2gZQs/ezmrxAs4CvkuaB3lLt9uzgHZfDtwNTJLuRF5BmgfZBNyR/x7V7XbO04enkR7vbAW25NdZdeoH8CTgltyH7cCFufwxwA3A94B/BQ7qdlsr9ud04PN17UMd9Rxa7p1X6HnmKyK7BUEQBEGNqcuj9SAIgiAIHGIgD4IgCIIaEwN5EARBENSYGMiDIAiCoMbEQB4EQRAENSYG8haQNC1pS+F1TAv7+LNZyg9v2ve9kt6b//cyST8u/O+CXH6MpBcX9vEySe+r0Iav5gxUt0q6TtLjF9qPdiDp+cWkGZLeIemZhTauXuD+3ivpV9vUtj2zlL9K0u+24xjB0iLpIQUN/a+kHxbWS5mmcmawP6iw3yFJP3PKj2/S9G5Jr8r/u6jp+L+Ry58s6czCPi6S9LoKbdghaZukrZKulNSVUKuSXi7p5wrrH2l8v+Q2HrnA/V0h6VFtaNexOayr97+2fW8sNTGQt8aomZ1YeN3Vwj7cgdzMdhf3DfwA+HShyobC/z+Uy44BXty8r4qcZymD0GXAJVU3ktTOqIDPJ2XBAsDMLjSzL7WyI0lHASdbSnDRSS4FXtPhYwQdwMzuK+jrA6RMUw1NTTibHAXMO5DPcbzbCsdbDYwCnylUuaRw/I257MmUM61V5TQzexLpN9aVs5i1WdMvBx4YyM3sd83s9lZ2JOkEYMrMftCuxs3CPwBv7vAxOkIM5G0i3xVfI+lb+XVKLl8paXO+2t4u6TRJFwMH57KPz7HP40jJC66Z5/AXA6fl/b0+lz0sX5HfIelvKnRhM3BsPu5TJH1N0s2SNiqFbGzcHf+VpK8Br5V0dL5SvjW/Gn3+HaVcwVsk/bNS2kok7ZH0zlz3+rz9KcDzgEty/cdKWi9pTXMDJZ0h6Rv5/f1XpXjRzawBrixsc1du8zck3ZTvdDZK+n7jLkvS6fkzukLSbZI+IGmgsI8ZbQYws33AXZJOqvDeBjVB0p9knW6X9OpcfDHw+Hx+XizpQZK+nM/DrUoxs6tyBimq2o452nAwcCFwXj5mQwtPzLq8U9IrKxyrqOlnF7SzQdKhuXyHpD+XdB3wAkmPy327Ndc9Jtd7U9b0VkkX5rJj8/v0YaWc4F9UyhP+IlJq0Q25/SOSrpV0otPX8wvfFe8v6q7AeeToZspPPSRdktu3UdKvFN6Xs3K9C7KeNyo9dXxrYX9DzW0GMLPvAyslrajw3vYW3Y5oU8cXMM2BqEhX5LJDgGV5+Tjgprz8RnLkKmAQODwv76lwnAuBdxfWX0aKLLWVlObukdYUFahQ707gCFIM3x806jbt/6vA6rz8x8AGUjrArwMrcvmLgEsL9d9f2H4DKelCo29HkBIXfA4YzuXvB16alw14bl7+G+CteXk9sKaw3wfWG20ElpO+mA7N5X9KjubU1KfLGsfI63cBf5iX35Pfu8OBFaSEBY33b4wUUWmQlElpzVxtzutvIeV27vo5Ga/WXsBfAH+Ul08Cbs1aPpwU8vNJpMFwS2Gb4YKOHwrckZeHSJmr5jreR4E/KKxfBPxXPi8/BByRyy8A3ttU7xpgJB/zPmDQ2f8O4EhS8o0PAO/M9b8GHJLrvAX4s0L9NxS2v7lwvi/L78VZWcci3fxdCZyS35dJ4Im5/qeBc/LytcCJhf0+sF5o4y+SnkwM5fJ1wIudPl0HPKHwHhvwrLz+OeCLufwpHPjevQD4IfBg4FDgNtLFxaxtzusfAc7u9nm50Fddkqb0GqOWHpMVGQbel686p4HH5fIbgUuVEhV8xszc+ZlZOAd4SWH9c8DlZjae7yYvI+Wu9dhkZrsAJN0GPIqZqSMbfFzSKGnAezXweJLArpYEaWC7u1B/Q2H5GcBLIWUiAnZJeglJUDfm7Q/mQAKGCeDzeflm4Flz9L2Zk0mP36/L+x0BvuHUWwn8uKmsEcd7G3CYpTzMuyWN6cBc3Q1mdieApMtJoSz/bZ427wR+fgF9CHqb04BPWXragqTPkM6Dq5rqCXiXpKeR0k8+UtJyoDQ/PmOjdOf3HOANheJ/AN5GGpz+mjS9tXaWXXze0qP/nZJ+QroY/V+n3jW5XVuAd5F0ejzw9YJ2ri3U35Db92BguZl9DsDMxnL5GcCzSSFRAQ4jfb/tJOWV35bLbyZN81XlmcAvAzcVviu876hmTY+a2dV5eRuwy8ymJG1rOv5GM/tp7kPjs7xynjbvBB62gD70BDGQt4/XA/cAJ5CuWscAzGyzkoHiOcDHJF1iZh+db2dK80JDVkhxZ2b3Fap8kCTS2RgvLE8z+2d9npndVDjukcC3zeyps9TfO2fD05fcZWbmzTVNWr7snadNs+33ajM7d556o6Q7iSKN92I/M9+X/YU2NMcqbqzP1eZl+XhBf+ClkPR4Kenp05PzALKD8jnn8Rzgm2Z2b6PAzO554ODSB0kXj7NRVdOnmdkDFxVKo+SVZvaSWeoXNe3F7BZwkZl9eEahdOwC2uQh0tO+P5+nXrOmiz6GoqaLeobZNT1Xm2up6Zgjbx9HAHeb2X7SXXRjXvhRpEe4HyRlHXpyrj+Z79Jn41xSkoYHUJ6rzjyP9OgPYDfpUWA7uB1YIemp+ZjDkn5hlrqbgD/M9QYlPSiXrVF2yyo5fudzm1Zp//XAqfnLA0mHSHqcU+875HnBBXKSUjauAdJ0wrXzbUC6K9newrGC3mQzaZ74YCX/xdmku9vm8/MIkqanJD0LeHjF/c+n6Rdw4Hxqp6a/DvyapMfkYx6q5L+ZQb57vVfSc3O9ZZIOATYCryjMqz8iP4GYiyrt/xLw2419Kf2aYJVTr1VNnyHpyNyHs0mP6OejlpqOgbx9vB84X9L1pJOhcZV7OrBF0i3AbwF/n8vXAVs1u9ntt2kSPfCabNC4leSYflku3wpMZYPK61kE+dHdGtKjw1tJj+dOmaX6a4Gn50daNwO/YGa3AW8FrpK0lTTfvHKW7Rv8C/DHkm6R9NhZ2vVjUn8vz/u9Hv+x9n+Q3vOF8g2SqWk7ac7yigrbnEr6Mgr6ADO7gaS5G0nn1z+Z2bZ813yT0s+6LgY+Bpwi6SbghaSMYXOSLwyezky3OsDf5v1uJZ1Pf5TLvwyckDVRMn4usF/3kDK1bcia/joHpv6aOQ94Y27PtSSvzBdITwquz1r/JOnx+lx8BPiQZvlJX27XNuDtwJfy8a4Cjnaqtqrpa4FPkKYELp9vWlPSQaTH7LfMVa8XiexnQd8h6VrgN4uPF+epfzrJ8FTZfSzpl0gmodkeVwZB0AbyHfUm4GnZi1NlmwuAXzSzeX97X9jmhcDxZvb21lraPeKOPOhH3gh4j+jayXJgvrm9IAgWSTYfvoP5n+wtFpF+2VI74o48CIIgCGpM3JEHQRAEQY2JgTwIgiAIakwM5EEQBEFQY2IgD4IgCIIaEwN5EARBENSYGMiDIAiCoMb8H5B60DH1+5DvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_min = 5\n",
    "c_max = 10000\n",
    "bin_size = 40\n",
    "freq_min = 0\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "stats_filtered = se_gps_data_hour_prev_next[se_gps_data_hour_prev_next[:,5] >= freq_min]\n",
    "events = se[se_gps_data_hour_prev_next[:,5] >= freq_min]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist2d(stats_filtered[:,7], events['speed_mph'], range=[[0,40],[0,40]], bins=[bin_size,bin_size], linewidth=0,rasterized=True)\n",
    "plt.ylabel(\"Segment Speed (mph)\")\n",
    "plt.xlabel(\"Median Fast (mph)\")\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist2d(stats_filtered[:,2], events['speed_mph'], range=[[0,40],[0,40]], bins=[bin_size,bin_size], linewidth=0,rasterized=True)\n",
    "plt.ylabel(\"Segment Speed (mph)\")\n",
    "plt.xlabel(\"Fast Harmonic Mean (mph)\")\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist2d(stats_filtered[:,8], events['speed_mph'], range=[[0,40],[0,40]], bins=[bin_size,bin_size], linewidth=0,rasterized=True)\n",
    "plt.ylabel(\"Segment Speed (mph)\")\n",
    "plt.xlabel(\"Fast 75th Percentile (mph)\")\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist2d(stats_filtered[:,10], events['speed_mph'], range=[[0,40],[0,40]], bins=[bin_size,bin_size], linewidth=0,rasterized=True)\n",
    "plt.ylabel(\"Segment Speed (mph)\")\n",
    "plt.xlabel(\"Total 75th Percentile (mph)\")\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.savefig(\"GPS_seg speed vs stats.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(filtered['speed_mph'], bins=50, range=(3,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_mask(freq):\n",
    "\n",
    "    valid_mask = (se_gps_data_hour_prev_next[:,5] >= freq) & \\\n",
    "    (se['speed_mph'] != np.inf) & \\\n",
    "    (~np.isnan(se_gps_data_hour_prev_next[:,8])) & \\\n",
    "    (~np.isnan(se_gps_data_hour_prev_next[:,4])) & \\\n",
    "    (se_gps_data_hour_prev_next[:,11] != 0)\n",
    "    \n",
    "    return valid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920087\n",
      "2895912\n",
      "73.87366657933867\n"
     ]
    }
   ],
   "source": [
    "v_mask = make_valid_mask(8)\n",
    "\n",
    "print(len(v_mask))\n",
    "\n",
    "print(np.count_nonzero(v_mask))\n",
    "\n",
    "print(np.count_nonzero(v_mask)/len(v_mask)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 slow_fraction\n",
    "# 1 fast_hmean\n",
    "# 2 fast_mean\n",
    "# 3 total_mean\n",
    "# 4 clipped_hmean\n",
    "# 5 clipped_mean\n",
    "# 6 freq_total\n",
    "# 7 freq_fast\n",
    "# 8 freq_clipped\n",
    "# 9 fast_median\n",
    "# 10 fast_75th percential\n",
    "# 11 total_median\n",
    "# 12 total_75th percential\n",
    "# 13 max\n",
    "\n",
    "overlaps_dict = {}\n",
    "overlaps_dict[0] = []\n",
    "overlaps_dict[1] = [4, 5, 11, 9, 12]\n",
    "overlaps_dict[2] = [3, 10, 9]\n",
    "overlaps_dict[3] = [2, 10, 12]\n",
    "overlaps_dict[4] = [1, 5]\n",
    "overlaps_dict[5] = [1, 4]\n",
    "overlaps_dict[6] = [7, 8]\n",
    "overlaps_dict[7] = [6, 8]\n",
    "overlaps_dict[8] = [6, 7]\n",
    "overlaps_dict[9] = [1, 2, 10, 12]\n",
    "overlaps_dict[10] = [2, 9, 3]\n",
    "overlaps_dict[11] = [1, 12]\n",
    "overlaps_dict[12] = [1, 3, 9, 11]\n",
    "overlaps_dict[13] = []\n",
    "overlaps_dict[14] = []\n",
    "overlaps_dict[15] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overlap_mask(width = 17):\n",
    "    overlaps_mask = np.zeros(width)\n",
    "\n",
    "    overlaps_mask[:] = -1\n",
    "    \n",
    "    overlaps_mask[11] = 1 # 11 total_median\n",
    "    overlaps_mask[4] = 1 # 4 clipped_hmean\n",
    "    overlaps_mask[3] = 1 # 3 total_mean\n",
    "    \n",
    "    while(np.isin([-1], overlaps_mask).any()):\n",
    "        options = np.where(overlaps_mask < 0)[0]\n",
    "    #     print(options)\n",
    "        i = np.random.randint(len(options))\n",
    "#         print(i)\n",
    "        overlaps_mask[options[i]] = 1\n",
    "        overlaps_mask[overlaps_dict[options[i]]] = 0\n",
    "\n",
    "    return overlaps_mask.astype(bool)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_overlap_mask(freq, data, columns):\n",
    "\n",
    "    df_cors = pd.DataFrame(data=np.hstack((data, se[['speed_mph']].values)),\n",
    "                        columns=columns)\n",
    "\n",
    "    cors = df_cors[df_cors['freq_fast'] >= freq].corr()\n",
    "    \n",
    "    overlaps_dict = {}\n",
    "\n",
    "    abs_cor_top_75th = np.percentile(np.abs(cors.values), 75)\n",
    "\n",
    "    for col_idx, column in enumerate(cors.columns):\n",
    "\n",
    "        if column == 'true_speed':\n",
    "            continue\n",
    "\n",
    "        overlaps_dict[column] = []\n",
    "\n",
    "        for row_idx, (name, value) in enumerate(cors[column].iteritems()):\n",
    "            if np.abs(value) > abs_cor_top_75th and column != name:\n",
    "    #             print(f\"{column} -> {name}: {value}\")\n",
    "                overlaps_dict[column].append(row_idx)\n",
    "        \n",
    "    overlap_mask = np.empty(len(cors['true_speed']))\n",
    "\n",
    "    overlap_mask[:] = -1\n",
    "\n",
    "    for best in cors['true_speed'].abs().sort_values().index[::-1]:\n",
    "\n",
    "        if(best == \"true_speed\"):\n",
    "            continue\n",
    "\n",
    "        best_idx = cors.columns.get_loc(best)\n",
    "\n",
    "        if overlap_mask[best_idx] == -1:\n",
    "            overlap_mask[best_idx] = 1\n",
    "            overlap_mask[overlaps_dict[best]] = 0\n",
    "\n",
    "\n",
    "    return overlap_mask[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.807506642246715\n"
     ]
    }
   ],
   "source": [
    "train_speeds = se['speed_mph'][:int(len(se)*test_fraction)]\n",
    "\n",
    "mean_speed = np.mean(train_speeds[np.isfinite(train_speeds)])\n",
    "print(mean_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = se_gps_data_hour_prev_next[:,1:]\n",
    "\n",
    "mask = make_valid_mask(10)\n",
    "\n",
    "display(np.sum(np.isnan(data[mask]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "(baseline_array_cum, \n",
    "     actual_array_cum, \n",
    "     baseline_median_array_cum, \n",
    "     baseline_pass_count, \n",
    "     pass_fraction, \n",
    "     baseline_median_pass_count, \n",
    "     median_pass_fraction) = calc_baseline_and_actual(se[int(len(se)*test_fraction):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn(freq, dropout, loss, NN, use_linear = False):\n",
    "    \n",
    "#     valid_mask = make_valid_mask(freq)\n",
    "    \n",
    "# #     data = np.hstack((se_gps_data_hour_prev_next[:,1:], se[['real_length', \n",
    "# #                                                             'direction_degrees', \n",
    "# #                                                             \"to_centre_dist\",\n",
    "# #                                                            'rain',\n",
    "# #                                                            'arrival_hour',\n",
    "# #                                                            'arrival_day'\n",
    "# #                                                            ]].values))\n",
    "\n",
    "# #     overlaps_mask = best_overlap_mask(freq, data, ['slow_fraction', 'fast_hmean', 'fast_mean', 'total_mean',\n",
    "# #                                     'clipped_hmean','clipped_mean','freq_total',\n",
    "# #                                     'freq_fast','freq_clipped', \n",
    "# #                                    'fast_median', 'fast_75th percential',\n",
    "# #                                   'total_median', 'total_75th percential', 'max', \n",
    "# #                                  'real_length', 'direction_degrees', \"to_centre_dist\",\n",
    "# #                                                            'rain',\n",
    "# #                                                            'arrival_hour',\n",
    "# #                                                            'arrival_day','true_speed'])\n",
    "\n",
    "\n",
    "#     data = se_gps_data_hour_prev_next[:,1:]\n",
    "\n",
    "#     overlaps_mask = best_overlap_mask(freq, data, ['slow_fraction', 'fast_hmean', 'fast_mean', 'total_mean',\n",
    "#                                     'freq_total',\n",
    "#                                     'freq_fast',\n",
    "#                                    'fast_median', 'fast_75th percential',\n",
    "#                                   'total_median', 'total_75th percential', 'max','std', \n",
    "#                                     'true_speed'])\n",
    "\n",
    "    \n",
    "#     # where on the reduced (valid mask) data is the right place to cut so that when it comes back\n",
    "#     # it's exactly test_fraction from the start\n",
    "#     cut_point_valid = np.count_nonzero(valid_mask[:int(len(se)*test_fraction)])\n",
    "    \n",
    "# #     speeds_mph_simple = se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237\n",
    "    \n",
    "# #     (train_data_scaled, test_data_scaled, \n",
    "# #      train_target_scaled_baseline, test_target_scaled_baseline, \n",
    "# #      scaler_target_baseline) = prep_training_data(data[valid_mask,:][:, (overlaps_mask==1)], speeds_mph_simple[valid_mask], cut_point_valid)\n",
    "\n",
    "\n",
    "#     (train_data_scaled, test_data_scaled, \n",
    "#      train_target_scaled, test_target_scaled, \n",
    "#      scaler_target) = prep_training_data(data[valid_mask,:][:, (overlaps_mask==1)], se[valid_mask]['speed_mph'], cut_point_valid)\n",
    "\n",
    "#     print(overlaps_mask)\n",
    "    \n",
    "#     model = create_simple_model(\n",
    "#             (train_data_scaled.shape[1]),\n",
    "#             dropout, NN, use_linear)\n",
    "\n",
    "#     Path(f\"GPS_models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     callbacks_list = [\n",
    "#         keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "#         keras.callbacks.ModelCheckpoint(\n",
    "#             filepath=f\"GPS_models/freq_{freq}_mask_{overlaps_mask}_simple_[{'_'.join(list(map(str, NN)))}]_{loss}_{dropout}_{use_linear}.h5\",\n",
    "#             monitor=\"val_loss\",\n",
    "#             save_best_only=True,\n",
    "#         ),\n",
    "#     ]\n",
    "\n",
    "#     # model.compile(optimizer=\"rmsprop\", loss=\"mean_absolute_error\")\n",
    "# #     model.compile(optimizer=\"rmsprop\", loss=\"logcosh\")\n",
    "#     model.compile(optimizer=\"rmsprop\", loss=loss)\n",
    "#     model.fit(\n",
    "#         train_data_scaled,\n",
    "#         train_target_scaled,\n",
    "#         epochs=100,\n",
    "#         callbacks=callbacks_list,\n",
    "#         batch_size=256,\n",
    "#         validation_data=(test_data_scaled, test_target_scaled),\n",
    "#     )\n",
    "\n",
    "#     test_y_scaled = model.predict(test_data_scaled)\n",
    "\n",
    "#     test_y = (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]\n",
    "\n",
    "#     test_y[valid_mask[int(len(se)*test_fraction):]] = scaler_target.inverse_transform(test_y_scaled)\n",
    "    \n",
    "#     test_target_truth = se['speed_mph'][int(len(se)*test_fraction):]\n",
    "    \n",
    "#     test_target_truth[~np.isfinite(test_target_truth)] = mean_speed\n",
    "\n",
    "#     RMSE = np.sqrt(mean_squared_error(test_target_truth, test_y))\n",
    "    \n",
    "#     MAE = mean_absolute_error(test_target_truth, test_y)\n",
    "    \n",
    "#     print(f\"RMSE pred: {np.sqrt(mean_squared_error(test_target_truth, test_y))}\")\n",
    "#     print(f\"RMSE base: {np.sqrt(mean_squared_error(test_target_truth, (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]))}\")\n",
    "#     print(f\"RMSE base_median: {np.sqrt(mean_squared_error(test_target_truth, (se['real_length'] / se['median_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]))}\")\n",
    "\n",
    "#     print(f\"MAE pred: {mean_absolute_error(test_target_truth, test_y)}\")\n",
    "#     print(f\"MAE base: {mean_absolute_error(test_target_truth, (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):])}\")\n",
    "#     print(f\"MAE base_median: {mean_absolute_error(test_target_truth, (se['real_length'] / se['median_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):])}\")\n",
    "    \n",
    "#     predict_array_NN_cum, _, pass_fraction = calc_prediction_cum_journeys(se[int(len(se)*test_fraction):], test_y, baseline_array_cum, actual_array_cum)\n",
    "\n",
    "#     return overlaps_mask, pass_fraction, RMSE, MAE, test_y, predict_array_NN_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_PCA(freq, dropout, loss, NN, days, extra_features = False, use_linear = False):\n",
    "    \n",
    "    valid_mask = make_valid_mask(freq)\n",
    "    \n",
    "    if extra_features:\n",
    "        data = np.hstack((se_gps_data_hour_prev_next[:,1:], se[['real_length', \n",
    "                                                                'direction_degrees', \n",
    "                                                                \"to_centre_dist\",\n",
    "                                                               'rain',\n",
    "                                                            \"timetable_segment_duration\",\n",
    "                                                            \"std_diff_percent_segment_mean_by_segment_code_and_hour_and_day\",\n",
    "                                                            \"clock_direction_degrees\",\n",
    "                                                            \"dry\",\n",
    "                                                            \"weekend\",\n",
    "                                                               ]].values, pd.get_dummies(se[[\"arrival_hour\", \"arrival_day\"]])))\n",
    "    else: \n",
    "        data = se_gps_data_hour_prev_next[:,1:]\n",
    "\n",
    "    (train_data_scaled, test_data_scaled, \n",
    "     train_target_scaled, test_target_scaled, \n",
    "     scaler_target) = prep_training_data_days(data, se['speed_mph'], days, valid_mask)\n",
    "    \n",
    "    pca = PCA(n_components=0.95, svd_solver = 'full')\n",
    "    \n",
    "    GPS_feature_width =  se_gps_data_hour_prev_next[:,1:].shape[1]\n",
    "    \n",
    "    train_data_scaled = np.hstack((pca.fit_transform(train_data_scaled[:,:GPS_feature_width]), train_data_scaled[:,GPS_feature_width:]))\n",
    "    test_data_scaled = np.hstack((pca.transform(test_data_scaled[:,:GPS_feature_width]), test_data_scaled[:,GPS_feature_width:]))\n",
    "    \n",
    "    print(f\"Using {len(pca.explained_variance_)} PCA components\")\n",
    "    \n",
    "    model = create_simple_model(\n",
    "            (train_data_scaled.shape[1]),\n",
    "            dropout, NN, use_linear)\n",
    "\n",
    "    Path(f\"GPS_models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"GPS_models/freq_{freq}_pca_{len(pca.explained_variance_)}_simple_[{'_'.join(list(map(str, NN)))}]_{loss}_{dropout}_{use_linear}.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # model.compile(optimizer=\"rmsprop\", loss=\"mean_absolute_error\")\n",
    "#     model.compile(optimizer=\"rmsprop\", loss=\"logcosh\")\n",
    "    model.compile(optimizer=\"rmsprop\", loss=loss)\n",
    "    model.fit(\n",
    "        train_data_scaled,\n",
    "        train_target_scaled,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks_list,\n",
    "        batch_size=256,\n",
    "        validation_data=(test_data_scaled, test_target_scaled),\n",
    "    )\n",
    "\n",
    "    test_y_scaled = model.predict(test_data_scaled)\n",
    "\n",
    "    test_y = (se.loc[se['test'], 'real_length'] / se.loc[se['test'],'mean_durations_by_segment_code_and_hour_and_day'] * 2.237)\n",
    "\n",
    "    test_y[valid_mask & se['test']] = scaler_target.inverse_transform(test_y_scaled)\n",
    "    \n",
    "    test_target_truth = se.loc[se['test'], 'speed_mph']\n",
    "    \n",
    "    test_target_truth[~np.isfinite(test_target_truth)] = mean_speed\n",
    "    \n",
    "    test_y_duration = se.loc[se['test'], 'real_length'] / test_y * 2.237\n",
    "    \n",
    "    return test_y_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn_KNN(freq=10, k=5):\n",
    "    \n",
    "#     valid_mask = make_valid_mask(freq)\n",
    "    \n",
    "#     data = se_gps_data_hour_prev_next[:,1:]\n",
    "\n",
    "#     overlaps_mask = best_overlap_mask(freq, data, ['slow_fraction', 'fast_hmean', 'fast_mean', 'total_mean',\n",
    "#                                     'freq_total',\n",
    "#                                     'freq_fast','freq_clipped', \n",
    "#                                    'fast_median', 'fast_75th percential',\n",
    "#                                   'total_median', 'total_75th percential', 'max', 'std', \n",
    "#                                     'true_speed'])\n",
    "\n",
    "    \n",
    "#     # where on the reduced (valid mask) data is the right place to cut so that when it comes back\n",
    "#     # it's exactly test_fraction from the start\n",
    "#     cut_point_valid = np.count_nonzero(valid_mask[:int(len(se)*test_fraction)])\n",
    "    \n",
    "# #     speeds_mph_simple = se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237\n",
    "    \n",
    "# #     (train_data_scaled, test_data_scaled, \n",
    "# #      train_target_scaled_baseline, test_target_scaled_baseline, \n",
    "# #      scaler_target_baseline) = prep_training_data(data[valid_mask,:][:, (overlaps_mask==1)], speeds_mph_simple[valid_mask], cut_point_valid)\n",
    "\n",
    "\n",
    "#     (train_data_scaled, test_data_scaled, \n",
    "#      train_target_scaled, test_target_scaled, \n",
    "#      scaler_target) = prep_training_data(data[valid_mask,:][:, (overlaps_mask==1)], se[valid_mask]['speed_mph'], cut_point_valid)\n",
    "\n",
    "#     neigh = KNeighborsRegressor(n_neighbors=k, weights=\"distance\")\n",
    "#     neigh.fit(train_data_scaled, train_target_scaled) \n",
    "\n",
    "#     test_y_scaled = neigh.predict(test_data_scaled)\n",
    "\n",
    "#     test_y = (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]\n",
    "\n",
    "#     test_y[valid_mask[int(len(se)*test_fraction):]] = scaler_target.inverse_transform(test_y_scaled)\n",
    "    \n",
    "#     test_target_truth = se['speed_mph'][int(len(se)*test_fraction):]\n",
    "    \n",
    "#     test_target_truth[~np.isfinite(test_target_truth)] = mean_speed\n",
    "\n",
    "#     RMSE = np.sqrt(mean_squared_error(test_target_truth, test_y))\n",
    "    \n",
    "#     MAE = mean_absolute_error(test_target_truth, test_y)\n",
    "    \n",
    "#     print(f\"RMSE pred: {np.sqrt(mean_squared_error(test_target_truth, test_y))}\")\n",
    "#     print(f\"RMSE base: {np.sqrt(mean_squared_error(test_target_truth, (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]))}\")\n",
    "#     print(f\"RMSE base_median: {np.sqrt(mean_squared_error(test_target_truth, (se['real_length'] / se['median_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):]))}\")\n",
    "\n",
    "#     print(f\"MAE pred: {mean_absolute_error(test_target_truth, test_y)}\")\n",
    "#     print(f\"MAE base: {mean_absolute_error(test_target_truth, (se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):])}\")\n",
    "#     print(f\"MAE base_median: {mean_absolute_error(test_target_truth, (se['real_length'] / se['median_durations_by_segment_code_and_hour_and_day'] * 2.237)[int(len(se)*test_fraction):])}\")\n",
    "\n",
    "    \n",
    "#     predict_array_NN_cum, _, pass_fraction = calc_prediction_cum_journeys(se[int(len(se)*test_fraction):], test_y, baseline_array_cum, actual_array_cum)\n",
    "\n",
    "#     return overlaps_mask, pass_fraction, RMSE, MAE, test_y, predict_array_NN_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../pipeline/utils/stats.py:20: RuntimeWarning: invalid value encountered in less\n",
      "  self.first_20mins_mask = actual_array_cum < 20 * 60\n"
     ]
    }
   ],
   "source": [
    "stats = Stats(se[se['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, _, _, test_y, predict_array_KNN_cum = learn_KNN(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, _, _, test_y, predict_array_NN_cum = learn(10, 0.0, \"logcosh\", [64,32,12], False)\n",
    "\n",
    "# Draw real vs streight length for messages - Yes\n",
    "# Try using straight lengths for the messages instead - Bad\n",
    "# Try using a linear instead of tanh activation for the last layer - Worse\n",
    "# Try predicting the mean and then still testing against true, for various networks\n",
    "# Try to find one bus route where this works really well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_423 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_424 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 62)                7998      \n",
      "_________________________________________________________________\n",
      "dropout_425 (Dropout)        (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 32)                2016      \n",
      "_________________________________________________________________\n",
      "dropout_426 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 27,831\n",
      "Trainable params: 27,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 401328 samples, validate on 487506 samples\n",
      "Epoch 1/100\n",
      "401328/401328 [==============================] - 15s 37us/step - loss: 0.1732 - val_loss: 0.1698\n",
      "Epoch 2/100\n",
      "401328/401328 [==============================] - 10s 24us/step - loss: 0.1719 - val_loss: 0.1691\n",
      "Epoch 3/100\n",
      "401328/401328 [==============================] - 10s 26us/step - loss: 0.1715 - val_loss: 0.1687\n",
      "Epoch 4/100\n",
      "401328/401328 [==============================] - 10s 24us/step - loss: 0.1712 - val_loss: 0.1685\n",
      "Epoch 5/100\n",
      "401328/401328 [==============================] - 9s 23us/step - loss: 0.1710 - val_loss: 0.1686\n",
      "Epoch 6/100\n",
      "401328/401328 [==============================] - 9s 23us/step - loss: 0.1708 - val_loss: 0.1688\n",
      "logcosh & 35.932 & 40.621 & 18.191 & 21.095 & 20.857 & 241.694 & 153.071 & 31.657 \\\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logcosh & 35.932 & 40.621 & 18.191 & 21.095 & 20.857 & 241.694 & 153.071 & 31.657 \\\\\\\\\\n'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _, _, _, test_y, predict_array_NN_PCA_cum, wraw_prediction = learn_PCA(10, 0.3, \"logcosh\", [128,62,32,12], 20, True)\n",
    "predict = learn_PCA(8, 0, \"logcosh\", [128,62,32,12], 10, False, False)\n",
    "\n",
    "stats.single_row(predict, \"logcosh\", data_type=\"duration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../pipeline/utils/stats.py:20: RuntimeWarning: invalid value encountered in less\n",
      "  self.first_20mins_mask = actual_array_cum < 20 * 60\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_807 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_713 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_808 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_714 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_809 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_715 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_810 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 30s 446us/step - loss: 0.2027 - val_loss: 0.3185\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 10s 144us/step - loss: 0.1926 - val_loss: 0.3192\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 11s 159us/step - loss: 0.1882 - val_loss: 0.3453\n",
      "features_True_linear_False_days_1_dropout_0_freq_10_NN_32_12_12 & 53.132 & 42.429 & 22.443 & 18.884 & 31.094 & 318.353 & 203.633 & 23.765 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_716 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_812 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_717 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_813 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_718 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_814 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 26s 388us/step - loss: 0.2120 - val_loss: 0.2194\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 17s 248us/step - loss: 0.2107 - val_loss: 0.2194\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 21s 316us/step - loss: 0.2101 - val_loss: 0.2188\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 32s 482us/step - loss: 0.2094 - val_loss: 0.2183\n",
      "Epoch 5/100\n",
      "67430/67430 [==============================] - 22s 331us/step - loss: 0.2090 - val_loss: 0.2190\n",
      "Epoch 6/100\n",
      "67430/67430 [==============================] - 19s 287us/step - loss: 0.2088 - val_loss: 0.2194\n",
      "features_False_linear_False_days_1_dropout_0_freq_10_NN_32_12_12 & 35.627 & 40.494 & 18.106 & 22.065 & 20.966 & 240.812 & 153.219 & 31.295 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_815 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_719 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_816 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_720 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_817 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_721 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_818 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 28s 447us/step - loss: 0.2008 - val_loss: 0.4134\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 17s 276us/step - loss: 0.1909 - val_loss: 0.4616\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 13s 205us/step - loss: 0.1859 - val_loss: 0.4768\n",
      "features_True_linear_False_days_1_dropout_0_freq_12_NN_32_12_12 & 103.257 & 55.239 & 36.080 & 15.340 & 65.503 & 611.672 & 409.753 & 15.269 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_819 (Dense)            (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_722 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_723 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_821 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_724 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_822 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 68s 1ms/step - loss: 0.2075 - val_loss: 0.2152\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 14s 220us/step - loss: 0.2059 - val_loss: 0.2144\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 12s 188us/step - loss: 0.2054 - val_loss: 0.2137\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 10s 160us/step - loss: 0.2049 - val_loss: 0.2134\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 9s 142us/step - loss: 0.2046 - val_loss: 0.2143\n",
      "Epoch 6/100\n",
      "62237/62237 [==============================] - 8s 131us/step - loss: 0.2045 - val_loss: 0.2157\n",
      "features_False_linear_False_days_1_dropout_0_freq_12_NN_32_12_12 & 37.540 & 39.629 & 17.941 & 21.518 & 19.201 & 209.234 & 131.193 & 35.162 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_823 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_725 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_824 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_726 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_825 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_727 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_826 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 29s 137us/step - loss: 0.1608 - val_loss: 0.1560\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 21s 100us/step - loss: 0.1512 - val_loss: 0.1538\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 19s 88us/step - loss: 0.1457 - val_loss: 0.1510\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 16s 75us/step - loss: 0.1418 - val_loss: 0.1480\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 20s 96us/step - loss: 0.1387 - val_loss: 0.1424\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 20s 92us/step - loss: 0.1362 - val_loss: 0.1421\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 21s 100us/step - loss: 0.1343 - val_loss: 0.1409\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 26s 122us/step - loss: 0.1329 - val_loss: 0.1394\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 34s 159us/step - loss: 0.1316 - val_loss: 0.1424\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 25s 118us/step - loss: 0.1304 - val_loss: 0.1378\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 19s 89us/step - loss: 0.1295 - val_loss: 0.1378\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 19s 87us/step - loss: 0.1286 - val_loss: 0.1355\n",
      "Epoch 13/100\n",
      "214031/214031 [==============================] - 14s 63us/step - loss: 0.1278 - val_loss: 0.1347\n",
      "Epoch 14/100\n",
      "214031/214031 [==============================] - 12s 56us/step - loss: 0.1270 - val_loss: 0.1325\n",
      "Epoch 15/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1264 - val_loss: 0.1326\n",
      "Epoch 16/100\n",
      "214031/214031 [==============================] - 14s 66us/step - loss: 0.1258 - val_loss: 0.1348\n",
      "features_True_linear_False_days_5_dropout_0_freq_10_NN_32_12_12 & 31.275 & 38.485 & 16.504 & 26.691 & 19.757 & 227.740 & 143.914 & 33.267 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_827 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_728 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_828 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_729 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_730 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 21s 99us/step - loss: 0.1701 - val_loss: 0.1664\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 16s 73us/step - loss: 0.1688 - val_loss: 0.1667\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 19s 87us/step - loss: 0.1684 - val_loss: 0.1666\n",
      "features_False_linear_False_days_5_dropout_0_freq_10_NN_32_12_12 & 36.415 & 40.302 & 18.042 & 21.383 & 20.119 & 229.885 & 144.563 & 33.242 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_731 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_732 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_733 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 32s 160us/step - loss: 0.1589 - val_loss: 0.1543\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 11s 57us/step - loss: 0.1493 - val_loss: 0.1488\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 11s 54us/step - loss: 0.1433 - val_loss: 0.1450\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 12s 59us/step - loss: 0.1392 - val_loss: 0.1424\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 11s 58us/step - loss: 0.1366 - val_loss: 0.1413\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 12s 58us/step - loss: 0.1348 - val_loss: 0.1381\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 11s 58us/step - loss: 0.1333 - val_loss: 0.1382\n",
      "Epoch 8/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1322 - val_loss: 0.1352\n",
      "Epoch 9/100\n",
      "197977/197977 [==============================] - 12s 58us/step - loss: 0.1312 - val_loss: 0.1347\n",
      "Epoch 10/100\n",
      "197977/197977 [==============================] - 11s 55us/step - loss: 0.1303 - val_loss: 0.1342\n",
      "Epoch 11/100\n",
      "197977/197977 [==============================] - 12s 60us/step - loss: 0.1295 - val_loss: 0.1335\n",
      "Epoch 12/100\n",
      "197977/197977 [==============================] - 14s 70us/step - loss: 0.1288 - val_loss: 0.1365\n",
      "Epoch 13/100\n",
      "197977/197977 [==============================] - 14s 70us/step - loss: 0.1282 - val_loss: 0.1328\n",
      "Epoch 14/100\n",
      "197977/197977 [==============================] - 12s 60us/step - loss: 0.1277 - val_loss: 0.1325\n",
      "Epoch 15/100\n",
      "197977/197977 [==============================] - 13s 64us/step - loss: 0.1271 - val_loss: 0.1325\n",
      "Epoch 16/100\n",
      "197977/197977 [==============================] - 14s 72us/step - loss: 0.1266 - val_loss: 0.1318\n",
      "Epoch 17/100\n",
      "197977/197977 [==============================] - 14s 72us/step - loss: 0.1261 - val_loss: 0.1304\n",
      "Epoch 18/100\n",
      "197977/197977 [==============================] - 17s 83us/step - loss: 0.1257 - val_loss: 0.1306\n",
      "Epoch 19/100\n",
      "197977/197977 [==============================] - 18s 92us/step - loss: 0.1253 - val_loss: 0.1312\n",
      "features_True_linear_False_days_5_dropout_0_freq_12_NN_32_12_12 & 31.797 & 38.411 & 16.463 & 26.410 & 19.154 & 221.244 & 137.883 & 35.182 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_734 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_735 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_837 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_736 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 21s 104us/step - loss: 0.1695 - val_loss: 0.1660\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 10s 49us/step - loss: 0.1679 - val_loss: 0.1656\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 10s 49us/step - loss: 0.1673 - val_loss: 0.1660\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 9s 45us/step - loss: 0.1671 - val_loss: 0.1655\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 9s 47us/step - loss: 0.1669 - val_loss: 0.1650\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 11s 55us/step - loss: 0.1667 - val_loss: 0.1652\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1666 - val_loss: 0.1653\n",
      "features_False_linear_False_days_5_dropout_0_freq_12_NN_32_12_12 & 36.086 & 40.088 & 17.934 & 22.094 & 20.235 & 229.470 & 144.785 & 32.902 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_737 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_840 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_738 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_841 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_739 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_842 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 55s 149us/step - loss: 0.1584 - val_loss: 0.1508\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 18s 48us/step - loss: 0.1468 - val_loss: 0.1440\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 16s 43us/step - loss: 0.1417 - val_loss: 0.1411\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1380 - val_loss: 0.1387\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1352 - val_loss: 0.1332\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 18s 48us/step - loss: 0.1329 - val_loss: 0.1320\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 18s 49us/step - loss: 0.1311 - val_loss: 0.1308\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 17s 45us/step - loss: 0.1297 - val_loss: 0.1329\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 16s 44us/step - loss: 0.1285 - val_loss: 0.1281\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1275 - val_loss: 0.1267\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 23s 61us/step - loss: 0.1266 - val_loss: 0.1271\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 94s 254us/step - loss: 0.1258 - val_loss: 0.1272\n",
      "features_True_linear_False_days_10_dropout_0_freq_10_NN_32_12_12 & 32.355 & 37.322 & 16.170 & 25.824 & 17.681 & 193.120 & 119.726 & 37.950 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_843 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_740 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_844 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_741 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_845 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_742 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_846 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 27s 74us/step - loss: 0.1716 - val_loss: 0.1694\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 13s 34us/step - loss: 0.1703 - val_loss: 0.1672\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 12s 34us/step - loss: 0.1699 - val_loss: 0.1672\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 12s 33us/step - loss: 0.1696 - val_loss: 0.1670\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 12s 33us/step - loss: 0.1694 - val_loss: 0.1672\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 12s 32us/step - loss: 0.1692 - val_loss: 0.1666\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1691 - val_loss: 0.1667\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 17s 47us/step - loss: 0.1690 - val_loss: 0.1672\n",
      "features_False_linear_False_days_10_dropout_0_freq_10_NN_32_12_12 & 35.764 & 40.611 & 18.094 & 21.586 & 20.722 & 240.623 & 151.833 & 32.025 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_847 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_743 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_848 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_744 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_849 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_745 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 25s 74us/step - loss: 0.1548 - val_loss: 0.1467\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1432 - val_loss: 0.1398\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 11s 32us/step - loss: 0.1377 - val_loss: 0.1362\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 13s 37us/step - loss: 0.1343 - val_loss: 0.1334\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 12s 34us/step - loss: 0.1320 - val_loss: 0.1313\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1301 - val_loss: 0.1308\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1285 - val_loss: 0.1279\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1272 - val_loss: 0.1262\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 15s 45us/step - loss: 0.1262 - val_loss: 0.1252\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 17s 50us/step - loss: 0.1253 - val_loss: 0.1247\n",
      "Epoch 11/100\n",
      "341937/341937 [==============================] - 17s 49us/step - loss: 0.1246 - val_loss: 0.1239\n",
      "Epoch 12/100\n",
      "341937/341937 [==============================] - 17s 51us/step - loss: 0.1241 - val_loss: 0.1243\n",
      "Epoch 13/100\n",
      "341937/341937 [==============================] - 19s 55us/step - loss: 0.1235 - val_loss: 0.1232\n",
      "Epoch 14/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1230 - val_loss: 0.1226\n",
      "Epoch 15/100\n",
      "341937/341937 [==============================] - 15s 45us/step - loss: 0.1227 - val_loss: 0.1218\n",
      "Epoch 16/100\n",
      "341937/341937 [==============================] - 13s 37us/step - loss: 0.1222 - val_loss: 0.1217\n",
      "Epoch 17/100\n",
      "341937/341937 [==============================] - 12s 34us/step - loss: 0.1219 - val_loss: 0.1210\n",
      "Epoch 18/100\n",
      "341937/341937 [==============================] - 11s 34us/step - loss: 0.1216 - val_loss: 0.1214\n",
      "Epoch 19/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1213 - val_loss: 0.1204\n",
      "Epoch 20/100\n",
      "341937/341937 [==============================] - 11s 33us/step - loss: 0.1210 - val_loss: 0.1209\n",
      "Epoch 21/100\n",
      "341937/341937 [==============================] - 11s 31us/step - loss: 0.1208 - val_loss: 0.1203\n",
      "Epoch 22/100\n",
      "341937/341937 [==============================] - 11s 32us/step - loss: 0.1206 - val_loss: 0.1202\n",
      "Epoch 23/100\n",
      "341937/341937 [==============================] - 11s 32us/step - loss: 0.1204 - val_loss: 0.1194\n",
      "Epoch 24/100\n",
      "341937/341937 [==============================] - 11s 32us/step - loss: 0.1201 - val_loss: 0.1204\n",
      "Epoch 25/100\n",
      "341937/341937 [==============================] - 10s 31us/step - loss: 0.1199 - val_loss: 0.1201\n",
      "features_True_linear_False_days_10_dropout_0_freq_12_NN_32_12_12 & 31.272 & 37.214 & 15.849 & 26.843 & 17.525 & 194.641 & 119.721 & 38.496 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_746 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_852 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_747 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_748 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_854 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 43s 126us/step - loss: 0.1705 - val_loss: 0.1667\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 15s 43us/step - loss: 0.1694 - val_loss: 0.1669\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1690 - val_loss: 0.1677\n",
      "features_False_linear_False_days_10_dropout_0_freq_12_NN_32_12_12 & 35.042 & 40.689 & 18.063 & 22.508 & 21.392 & 248.712 & 158.160 & 30.503 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_855 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_749 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_750 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_751 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_858 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 34s 34us/step - loss: 0.1608 - val_loss: 0.1512\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 28s 28us/step - loss: 0.1456 - val_loss: 0.1421\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 34s 35us/step - loss: 0.1400 - val_loss: 0.1396\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 37s 37us/step - loss: 0.1364 - val_loss: 0.1351\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 32s 33us/step - loss: 0.1340 - val_loss: 0.1338\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 25s 25us/step - loss: 0.1322 - val_loss: 0.1354\n",
      "Epoch 7/100\n",
      "988463/988463 [==============================] - 22s 23us/step - loss: 0.1309 - val_loss: 0.1319\n",
      "Epoch 8/100\n",
      "988463/988463 [==============================] - 23s 23us/step - loss: 0.1299 - val_loss: 0.1315\n",
      "Epoch 9/100\n",
      "988463/988463 [==============================] - 23s 23us/step - loss: 0.1291 - val_loss: 0.1293\n",
      "Epoch 10/100\n",
      "988463/988463 [==============================] - 23s 23us/step - loss: 0.1284 - val_loss: 0.1300\n",
      "Epoch 11/100\n",
      "988463/988463 [==============================] - 22s 23us/step - loss: 0.1278 - val_loss: 0.1274\n",
      "Epoch 12/100\n",
      "988463/988463 [==============================] - 22s 22us/step - loss: 0.1274 - val_loss: 0.1300s - loss: 0.1\n",
      "Epoch 13/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1270 - val_loss: 0.1280\n",
      "features_True_linear_False_days_30_dropout_0_freq_10_NN_32_12_12 & 29.954 & 37.532 & 15.734 & 28.239 & 18.475 & 213.730 & 132.923 & 36.327 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_859 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_752 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_860 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_753 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_861 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_754 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_862 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 33s 33us/step - loss: 0.1836 - val_loss: 0.1812\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 21s 21us/step - loss: 0.1825 - val_loss: 0.1810\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 20s 20us/step - loss: 0.1821 - val_loss: 0.1810\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 25s 26us/step - loss: 0.1818 - val_loss: 0.1807\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 32s 32us/step - loss: 0.1817 - val_loss: 0.1810\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 30s 31us/step - loss: 0.1816 - val_loss: 0.1810\n",
      "features_False_linear_False_days_30_dropout_0_freq_10_NN_32_12_12 & 35.131 & 40.849 & 18.152 & 22.141 & 21.346 & 249.601 & 158.566 & 30.666 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_863 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_755 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_864 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_756 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_865 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_757 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_866 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 30s 33us/step - loss: 0.1590 - val_loss: 0.1467\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 19s 21us/step - loss: 0.1428 - val_loss: 0.1392\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 24s 26us/step - loss: 0.1369 - val_loss: 0.1341\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 30s 33us/step - loss: 0.1336 - val_loss: 0.1325\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 29s 31us/step - loss: 0.1318 - val_loss: 0.1310\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 29s 31us/step - loss: 0.1305 - val_loss: 0.1355\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 21s 23us/step - loss: 0.1295 - val_loss: 0.1326\n",
      "features_True_linear_False_days_30_dropout_0_freq_12_NN_32_12_12 & 30.292 & 38.146 & 16.055 & 28.067 & 19.305 & 226.139 & 141.316 & 34.464 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_867 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_758 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_868 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_759 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_869 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_760 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_870 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 28s 31us/step - loss: 0.1828 - val_loss: 0.1808\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 29s 32us/step - loss: 0.1818 - val_loss: 0.1809\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 29s 32us/step - loss: 0.1815 - val_loss: 0.1804\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 28s 31us/step - loss: 0.1811 - val_loss: 0.1806\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 25s 27us/step - loss: 0.1809 - val_loss: 0.1797\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 20s 22us/step - loss: 0.1807 - val_loss: 0.1806\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 19s 21us/step - loss: 0.1806 - val_loss: 0.1797\n",
      "features_False_linear_False_days_30_dropout_0_freq_12_NN_32_12_12 & 35.932 & 40.131 & 17.946 & 22.190 & 20.186 & 229.104 & 144.341 & 33.006 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_761 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_762 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_873 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_763 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 68s 42us/step - loss: 0.1620 - val_loss: 0.1529\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 45s 28us/step - loss: 0.1434 - val_loss: 0.1459\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 32s 20us/step - loss: 0.1371 - val_loss: 0.1403\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 31s 19us/step - loss: 0.1344 - val_loss: 0.1380\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 31s 19us/step - loss: 0.1329 - val_loss: 0.1387\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 33s 20us/step - loss: 0.1317 - val_loss: 0.1354\n",
      "Epoch 7/100\n",
      "1625518/1625518 [==============================] - 48s 30us/step - loss: 0.1310 - val_loss: 0.1345\n",
      "Epoch 8/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1304 - val_loss: 0.1347\n",
      "Epoch 9/100\n",
      "1625518/1625518 [==============================] - 31s 19us/step - loss: 0.1299 - val_loss: 0.1341\n",
      "Epoch 10/100\n",
      "1625518/1625518 [==============================] - 32s 20us/step - loss: 0.1295 - val_loss: 0.1347\n",
      "Epoch 11/100\n",
      "1625518/1625518 [==============================] - 31s 19us/step - loss: 0.1293 - val_loss: 0.1331\n",
      "Epoch 12/100\n",
      "1625518/1625518 [==============================] - 31s 19us/step - loss: 0.1290 - val_loss: 0.1331\n",
      "Epoch 13/100\n",
      "1625518/1625518 [==============================] - 42s 26us/step - loss: 0.1287 - val_loss: 0.1330\n",
      "Epoch 14/100\n",
      "1625518/1625518 [==============================] - 49s 30us/step - loss: 0.1285 - val_loss: 0.1345\n",
      "Epoch 15/100\n",
      "1625518/1625518 [==============================] - 41s 25us/step - loss: 0.1282 - val_loss: 0.1333\n",
      "features_True_linear_False_days_50_dropout_0_freq_10_NN_32_12_12 & 30.165 & 37.649 & 15.723 & 28.110 & 18.380 & 217.156 & 133.292 & 37.135 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_875 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_764 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_876 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_765 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_877 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_766 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_878 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 55s 34us/step - loss: 0.1908 - val_loss: 0.1922\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 45s 28us/step - loss: 0.1895 - val_loss: 0.1920\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 34s 21us/step - loss: 0.1891 - val_loss: 0.1919\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 32s 20us/step - loss: 0.1888 - val_loss: 0.1909\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 33s 21us/step - loss: 0.1886 - val_loss: 0.1921\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 32s 19us/step - loss: 0.1885 - val_loss: 0.1910\n",
      "features_False_linear_False_days_50_dropout_0_freq_10_NN_32_12_12 & 35.616 & 40.611 & 18.095 & 21.605 & 20.775 & 241.032 & 152.179 & 31.865 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_879 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_767 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_768 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_769 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_882 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1601 - val_loss: 0.1500\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 46s 31us/step - loss: 0.1409 - val_loss: 0.1428\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 40s 27us/step - loss: 0.1358 - val_loss: 0.1385\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 30s 20us/step - loss: 0.1330 - val_loss: 0.1379\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 30s 20us/step - loss: 0.1315 - val_loss: 0.1365\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 29s 20us/step - loss: 0.1305 - val_loss: 0.1358\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 29s 19us/step - loss: 0.1299 - val_loss: 0.1349\n",
      "Epoch 8/100\n",
      "1499014/1499014 [==============================] - 40s 27us/step - loss: 0.1294 - val_loss: 0.1336\n",
      "Epoch 9/100\n",
      "1499014/1499014 [==============================] - 46s 31us/step - loss: 0.1290 - val_loss: 0.1340\n",
      "Epoch 10/100\n",
      "1499014/1499014 [==============================] - 38s 26us/step - loss: 0.1286 - val_loss: 0.1333\n",
      "Epoch 11/100\n",
      "1499014/1499014 [==============================] - 30s 20us/step - loss: 0.1283 - val_loss: 0.1374\n",
      "Epoch 12/100\n",
      "1499014/1499014 [==============================] - 29s 19us/step - loss: 0.1280 - val_loss: 0.1357\n",
      "features_True_linear_False_days_50_dropout_0_freq_12_NN_32_12_12 & 30.451 & 37.984 & 15.857 & 28.197 & 18.709 & 219.815 & 135.647 & 36.430 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_770 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_771 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_885 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_772 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_886 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 58s 39us/step - loss: 0.1911 - val_loss: 0.1934\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 30s 20us/step - loss: 0.1898 - val_loss: 0.1922\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 29s 20us/step - loss: 0.1893 - val_loss: 0.1919\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 29s 19us/step - loss: 0.1891 - val_loss: 0.1923\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 39s 26us/step - loss: 0.1888 - val_loss: 0.1921\n",
      "features_False_linear_False_days_50_dropout_0_freq_12_NN_32_12_12 & 35.326 & 40.451 & 18.007 & 22.363 & 20.843 & 240.587 & 152.205 & 31.628 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_887 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_773 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_888 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_774 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_889 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_775 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_890 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 56s 25us/step - loss: 0.1589 - val_loss: 0.1533\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 63s 29us/step - loss: 0.1405 - val_loss: 0.1428\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1357 - val_loss: 0.1414\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 44s 20us/step - loss: 0.1336 - val_loss: 0.1413\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 44s 20us/step - loss: 0.1323 - val_loss: 0.1388\n",
      "Epoch 6/100\n",
      "2219791/2219791 [==============================] - 42s 19us/step - loss: 0.1313 - val_loss: 0.1407\n",
      "Epoch 7/100\n",
      "2219791/2219791 [==============================] - 58s 26us/step - loss: 0.1307 - val_loss: 0.1390\n",
      "features_True_linear_False_days_70_dropout_0_freq_10_NN_32_12_12 & 31.563 & 36.962 & 15.753 & 26.552 & 17.123 & 189.807 & 115.760 & 39.554 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_891 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_776 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_892 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_777 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_893 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_778 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_894 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 56s 25us/step - loss: 0.1942 - val_loss: 0.1965\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 64s 29us/step - loss: 0.1928 - val_loss: 0.1973\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 54s 24us/step - loss: 0.1923 - val_loss: 0.1955\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 44s 20us/step - loss: 0.1919 - val_loss: 0.1961\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 42s 19us/step - loss: 0.1917 - val_loss: 0.1957\n",
      "features_False_linear_False_days_70_dropout_0_freq_10_NN_32_12_12 & 35.327 & 40.698 & 18.109 & 21.988 & 21.089 & 245.815 & 155.715 & 31.230 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_895 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_779 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_896 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_780 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_897 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_781 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_898 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 52s 26us/step - loss: 0.1601 - val_loss: 0.1536\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 40s 19us/step - loss: 0.1426 - val_loss: 0.1463\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 58s 28us/step - loss: 0.1368 - val_loss: 0.1408\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 59s 29us/step - loss: 0.1339 - val_loss: 0.1390\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 42s 20us/step - loss: 0.1324 - val_loss: 0.1408\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1315 - val_loss: 0.1370\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1307 - val_loss: 0.1382\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 45s 22us/step - loss: 0.1302 - val_loss: 0.1361\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 60s 29us/step - loss: 0.1298 - val_loss: 0.1360\n",
      "Epoch 10/100\n",
      "2049015/2049015 [==============================] - 49s 24us/step - loss: 0.1294 - val_loss: 0.1352\n",
      "Epoch 11/100\n",
      "2049015/2049015 [==============================] - 40s 19us/step - loss: 0.1291 - val_loss: 0.1348\n",
      "Epoch 12/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1288 - val_loss: 0.1348\n",
      "Epoch 13/100\n",
      "2049015/2049015 [==============================] - 40s 19us/step - loss: 0.1284 - val_loss: 0.1346\n",
      "Epoch 14/100\n",
      "2049015/2049015 [==============================] - 60s 29us/step - loss: 0.1282 - val_loss: 0.1342\n",
      "Epoch 15/100\n",
      "2049015/2049015 [==============================] - 53s 26us/step - loss: 0.1280 - val_loss: 0.1334\n",
      "Epoch 16/100\n",
      "2049015/2049015 [==============================] - 40s 20us/step - loss: 0.1279 - val_loss: 0.1343\n",
      "Epoch 17/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1277 - val_loss: 0.1339\n",
      "features_True_linear_False_days_70_dropout_0_freq_12_NN_32_12_12 & 31.038 & 36.892 & 15.567 & 27.359 & 17.307 & 194.716 & 118.754 & 39.325 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_899 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_782 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_900 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_783 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_901 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_784 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_902 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 52s 25us/step - loss: 0.1937 - val_loss: 0.1962\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1924 - val_loss: 0.1962\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 52s 25us/step - loss: 0.1919 - val_loss: 0.1956\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 58s 28us/step - loss: 0.1915 - val_loss: 0.1955\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 45s 22us/step - loss: 0.1912 - val_loss: 0.1949\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 39s 19us/step - loss: 0.1910 - val_loss: 0.1952\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 38s 19us/step - loss: 0.1908 - val_loss: 0.1946\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 42s 20us/step - loss: 0.1907 - val_loss: 0.1951\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 58s 29us/step - loss: 0.1905 - val_loss: 0.1958\n",
      "features_False_linear_False_days_70_dropout_0_freq_12_NN_32_12_12 & 35.228 & 40.688 & 18.054 & 22.267 & 21.101 & 245.762 & 155.415 & 31.256 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_903 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_785 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_904 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_786 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_905 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_787 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_906 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 19s 279us/step - loss: 0.2218 - val_loss: 0.2925\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 6s 96us/step - loss: 0.2084 - val_loss: 0.2726\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 7s 97us/step - loss: 0.2047 - val_loss: 0.2452\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 7s 99us/step - loss: 0.2025 - val_loss: 0.2670\n",
      "Epoch 5/100\n",
      "67430/67430 [==============================] - 6s 93us/step - loss: 0.2003 - val_loss: 0.2724\n",
      "features_True_linear_False_days_1_dropout_0.2_freq_10_NN_32_12_12 & 49.013 & 42.234 & 21.268 & 19.484 & 27.317 & 285.350 & 176.189 & 28.372 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_907 (Dense)            (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_788 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_789 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_909 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_790 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_910 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 30s 446us/step - loss: 0.2195 - val_loss: 0.2197\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 7s 107us/step - loss: 0.2143 - val_loss: 0.2197\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 7s 103us/step - loss: 0.2133 - val_loss: 0.2195\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 7s 99us/step - loss: 0.2130 - val_loss: 0.2198\n",
      "Epoch 5/100\n",
      "67430/67430 [==============================] - 6s 96us/step - loss: 0.2126 - val_loss: 0.2201\n",
      "features_False_linear_False_days_1_dropout_0.2_freq_10_NN_32_12_12 & 35.953 & 40.796 & 18.197 & 21.168 & 21.037 & 245.113 & 154.939 & 31.439 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_791 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_912 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_792 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_793 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 16s 257us/step - loss: 0.2161 - val_loss: 0.3103\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 11s 179us/step - loss: 0.2045 - val_loss: 0.2780\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 11s 171us/step - loss: 0.2010 - val_loss: 0.2740\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 11s 170us/step - loss: 0.1985 - val_loss: 0.2650\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 10s 163us/step - loss: 0.1961 - val_loss: 0.2618\n",
      "Epoch 6/100\n",
      "62237/62237 [==============================] - 9s 148us/step - loss: 0.1942 - val_loss: 0.2550\n",
      "Epoch 7/100\n",
      "62237/62237 [==============================] - 9s 151us/step - loss: 0.1923 - val_loss: 0.2981\n",
      "Epoch 8/100\n",
      "62237/62237 [==============================] - 9s 147us/step - loss: 0.1912 - val_loss: 0.3018\n",
      "features_True_linear_False_days_1_dropout_0.2_freq_12_NN_32_12_12 & 42.845 & 41.792 & 20.382 & 21.082 & 26.822 & 289.386 & 184.502 & 24.252 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_794 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_795 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_796 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 18s 288us/step - loss: 0.2170 - val_loss: 0.2160\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 6s 97us/step - loss: 0.2115 - val_loss: 0.2155\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 6s 98us/step - loss: 0.2099 - val_loss: 0.2153\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 6s 97us/step - loss: 0.2094 - val_loss: 0.2154\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 6s 93us/step - loss: 0.2090 - val_loss: 0.2158\n",
      "features_False_linear_False_days_1_dropout_0.2_freq_12_NN_32_12_12 & 36.437 & 40.363 & 18.038 & 21.380 & 20.238 & 230.845 & 145.053 & 33.040 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_797 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_798 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_799 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 38s 177us/step - loss: 0.1703 - val_loss: 0.1592\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 11s 51us/step - loss: 0.1620 - val_loss: 0.1568\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 10s 49us/step - loss: 0.1593 - val_loss: 0.1559\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 11s 50us/step - loss: 0.1571 - val_loss: 0.1548\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1552 - val_loss: 0.1526\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1536 - val_loss: 0.1506\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1523 - val_loss: 0.1501\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1512 - val_loss: 0.1478\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 9s 44us/step - loss: 0.1502 - val_loss: 0.1474\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1489 - val_loss: 0.1446\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 9s 44us/step - loss: 0.1481 - val_loss: 0.1450\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 9s 42us/step - loss: 0.1474 - val_loss: 0.1468\n",
      "features_True_linear_False_days_5_dropout_0.2_freq_10_NN_32_12_12 & 34.351 & 39.242 & 17.265 & 21.844 & 19.329 & 220.804 & 137.532 & 34.476 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_800 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_924 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_801 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_802 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 26s 124us/step - loss: 0.1742 - val_loss: 0.1695\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1715 - val_loss: 0.1683\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 10s 46us/step - loss: 0.1709 - val_loss: 0.1686\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 9s 44us/step - loss: 0.1704 - val_loss: 0.1679\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 10s 45us/step - loss: 0.1702 - val_loss: 0.1684\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 9s 42us/step - loss: 0.1699 - val_loss: 0.1679\n",
      "features_False_linear_False_days_5_dropout_0.2_freq_10_NN_32_12_12 & 36.476 & 40.573 & 18.144 & 20.824 & 20.412 & 235.894 & 148.047 & 32.759 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_927 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_803 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_928 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_804 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_929 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_805 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_930 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 41s 206us/step - loss: 0.1700 - val_loss: 0.1595\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 13s 68us/step - loss: 0.1613 - val_loss: 0.1543\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 11s 56us/step - loss: 0.1575 - val_loss: 0.1525\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 14s 71us/step - loss: 0.1551 - val_loss: 0.1496\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 14s 72us/step - loss: 0.1530 - val_loss: 0.1481\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 14s 70us/step - loss: 0.1513 - val_loss: 0.1473\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 12s 61us/step - loss: 0.1498 - val_loss: 0.1454\n",
      "Epoch 8/100\n",
      "197977/197977 [==============================] - 11s 56us/step - loss: 0.1483 - val_loss: 0.1449\n",
      "Epoch 9/100\n",
      "197977/197977 [==============================] - 12s 59us/step - loss: 0.1471 - val_loss: 0.1428\n",
      "Epoch 10/100\n",
      "197977/197977 [==============================] - 11s 54us/step - loss: 0.1458 - val_loss: 0.1424\n",
      "Epoch 11/100\n",
      "197977/197977 [==============================] - 12s 59us/step - loss: 0.1456 - val_loss: 0.1419\n",
      "Epoch 12/100\n",
      "197977/197977 [==============================] - 13s 64us/step - loss: 0.1450 - val_loss: 0.1416\n",
      "Epoch 13/100\n",
      "197977/197977 [==============================] - 13s 65us/step - loss: 0.1446 - val_loss: 0.1415\n",
      "Epoch 14/100\n",
      "197977/197977 [==============================] - 17s 87us/step - loss: 0.1438 - val_loss: 0.1401\n",
      "Epoch 15/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1434 - val_loss: 0.1399\n",
      "Epoch 16/100\n",
      "197977/197977 [==============================] - 14s 71us/step - loss: 0.1429 - val_loss: 0.1402\n",
      "Epoch 17/100\n",
      "197977/197977 [==============================] - 14s 72us/step - loss: 0.1427 - val_loss: 0.1391\n",
      "Epoch 18/100\n",
      "197977/197977 [==============================] - 14s 70us/step - loss: 0.1425 - val_loss: 0.1391\n",
      "Epoch 19/100\n",
      "197977/197977 [==============================] - 11s 54us/step - loss: 0.1422 - val_loss: 0.1394\n",
      "features_True_linear_False_days_5_dropout_0.2_freq_12_NN_32_12_12 & 33.194 & 39.413 & 17.074 & 23.892 & 19.793 & 230.250 & 143.791 & 33.769 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_931 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_806 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_932 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_807 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_933 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_808 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 21s 108us/step - loss: 0.1742 - val_loss: 0.1681\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 10s 51us/step - loss: 0.1709 - val_loss: 0.1670\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1702 - val_loss: 0.1672\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 10s 51us/step - loss: 0.1699 - val_loss: 0.1680\n",
      "features_False_linear_False_days_5_dropout_0.2_freq_12_NN_32_12_12 & 35.479 & 41.006 & 18.197 & 21.708 & 21.414 & 250.632 & 158.626 & 30.777 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_809 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_810 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_937 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_811 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_938 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 25s 68us/step - loss: 0.1690 - val_loss: 0.1590\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1604 - val_loss: 0.1543\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1566 - val_loss: 0.1500\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1537 - val_loss: 0.1468\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1516 - val_loss: 0.1439\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1500 - val_loss: 0.1449\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1487 - val_loss: 0.1410\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1480 - val_loss: 0.1404\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 15s 42us/step - loss: 0.1471 - val_loss: 0.1394\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1466 - val_loss: 0.1393\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1459 - val_loss: 0.1405\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1456 - val_loss: 0.1388\n",
      "Epoch 13/100\n",
      "370240/370240 [==============================] - 16s 43us/step - loss: 0.1453 - val_loss: 0.1383\n",
      "Epoch 14/100\n",
      "370240/370240 [==============================] - 15s 41us/step - loss: 0.1451 - val_loss: 0.1379\n",
      "Epoch 15/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1448 - val_loss: 0.1384\n",
      "Epoch 16/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1446 - val_loss: 0.1389\n",
      "features_True_linear_False_days_10_dropout_0.2_freq_10_NN_32_12_12 & 31.702 & 39.600 & 16.988 & 24.734 & 20.918 & 248.191 & 157.378 & 31.107 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_939 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_812 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_940 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_813 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_941 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_814 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_942 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 25s 68us/step - loss: 0.1747 - val_loss: 0.1700\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1726 - val_loss: 0.1688\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1721 - val_loss: 0.1688\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1717 - val_loss: 0.1686\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1715 - val_loss: 0.1693\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1714 - val_loss: 0.1685\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1713 - val_loss: 0.1686\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1711 - val_loss: 0.1688\n",
      "features_False_linear_False_days_10_dropout_0.2_freq_10_NN_32_12_12 & 35.449 & 41.079 & 18.240 & 21.315 & 21.502 & 253.231 & 160.465 & 30.582 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_943 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_815 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_944 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_816 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_945 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_817 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_946 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 25s 72us/step - loss: 0.1678 - val_loss: 0.1564\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1594 - val_loss: 0.1523\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1559 - val_loss: 0.1495\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1535 - val_loss: 0.1473\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1516 - val_loss: 0.1452\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1498 - val_loss: 0.1430\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1484 - val_loss: 0.1413\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1475 - val_loss: 0.1404\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1463 - val_loss: 0.1389\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1455 - val_loss: 0.1392\n",
      "Epoch 11/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1448 - val_loss: 0.1380\n",
      "Epoch 12/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1443 - val_loss: 0.1376\n",
      "Epoch 13/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1438 - val_loss: 0.1364\n",
      "Epoch 14/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1435 - val_loss: 0.1368\n",
      "Epoch 15/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1431 - val_loss: 0.1360\n",
      "Epoch 16/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1430 - val_loss: 0.1355\n",
      "Epoch 17/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1426 - val_loss: 0.1364\n",
      "Epoch 18/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1421 - val_loss: 0.1355\n",
      "Epoch 19/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1422 - val_loss: 0.1348\n",
      "Epoch 20/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1422 - val_loss: 0.1351\n",
      "Epoch 21/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1418 - val_loss: 0.1360\n",
      "features_True_linear_False_days_10_dropout_0.2_freq_12_NN_32_12_12 & 32.340 & 39.317 & 16.899 & 24.408 & 20.060 & 235.323 & 147.458 & 33.164 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_947 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_818 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_948 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_819 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_949 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_820 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_950 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 24s 71us/step - loss: 0.1745 - val_loss: 0.1694\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1716 - val_loss: 0.1687\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1710 - val_loss: 0.1680\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1706 - val_loss: 0.1680\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1705 - val_loss: 0.1675\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1702 - val_loss: 0.1670\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1701 - val_loss: 0.1668\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1700 - val_loss: 0.1672\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1698 - val_loss: 0.1668\n",
      "features_False_linear_False_days_10_dropout_0.2_freq_12_NN_32_12_12 & 35.883 & 40.471 & 18.011 & 21.701 & 20.505 & 236.387 & 148.772 & 32.493 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_951 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_821 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_952 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_822 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_953 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_823 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_954 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1752 - val_loss: 0.1626\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1637 - val_loss: 0.1558\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1584 - val_loss: 0.1522\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1555 - val_loss: 0.1491\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1542 - val_loss: 0.1472\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1530 - val_loss: 0.1471\n",
      "Epoch 7/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1522 - val_loss: 0.1462\n",
      "Epoch 8/100\n",
      "988463/988463 [==============================] - 29s 30us/step - loss: 0.1514 - val_loss: 0.1452\n",
      "Epoch 9/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1510 - val_loss: 0.1447\n",
      "Epoch 10/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1507 - val_loss: 0.1441\n",
      "Epoch 11/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1504 - val_loss: 0.1444\n",
      "Epoch 12/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1502 - val_loss: 0.1435\n",
      "Epoch 13/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1500 - val_loss: 0.1437\n",
      "Epoch 14/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1498 - val_loss: 0.1427\n",
      "Epoch 15/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1498 - val_loss: 0.1437\n",
      "Epoch 16/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1495 - val_loss: 0.1431\n",
      "features_True_linear_False_days_30_dropout_0.2_freq_10_NN_32_12_12 & 31.834 & 39.274 & 16.785 & 24.298 & 19.769 & 233.436 & 145.848 & 33.793 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_955 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_824 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_956 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_825 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_957 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_826 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_958 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 38s 38us/step - loss: 0.1862 - val_loss: 0.1839\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 28s 28us/step - loss: 0.1844 - val_loss: 0.1829\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 30s 30us/step - loss: 0.1839 - val_loss: 0.1818\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 31s 32us/step - loss: 0.1836 - val_loss: 0.1817\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 31s 32us/step - loss: 0.1834 - val_loss: 0.1823\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 29s 30us/step - loss: 0.1832 - val_loss: 0.1821\n",
      "features_False_linear_False_days_30_dropout_0.2_freq_10_NN_32_12_12 & 35.749 & 40.932 & 18.209 & 21.249 & 21.054 & 246.468 & 155.461 & 31.488 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_959 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_827 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_960 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_828 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_961 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_829 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_962 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 40s 44us/step - loss: 0.1742 - val_loss: 0.1633\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 28s 30us/step - loss: 0.1631 - val_loss: 0.1564\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1587 - val_loss: 0.1517\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1561 - val_loss: 0.1500\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1546 - val_loss: 0.1489\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1535 - val_loss: 0.1477\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1526 - val_loss: 0.1472\n",
      "Epoch 8/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1520 - val_loss: 0.1466\n",
      "Epoch 9/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1516 - val_loss: 0.1465\n",
      "Epoch 10/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1514 - val_loss: 0.1461\n",
      "Epoch 11/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1510 - val_loss: 0.1453\n",
      "Epoch 12/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1507 - val_loss: 0.1450\n",
      "Epoch 13/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1506 - val_loss: 0.1458\n",
      "Epoch 14/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1504 - val_loss: 0.1458\n",
      "features_True_linear_False_days_30_dropout_0.2_freq_12_NN_32_12_12 & 32.708 & 39.184 & 16.859 & 23.966 & 19.556 & 227.901 & 141.868 & 34.265 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_963 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_830 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_964 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_831 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_965 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_832 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_966 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 38s 41us/step - loss: 0.1860 - val_loss: 0.1823\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1838 - val_loss: 0.1815\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1833 - val_loss: 0.1817\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1830 - val_loss: 0.1816\n",
      "features_False_linear_False_days_30_dropout_0.2_freq_12_NN_32_12_12 & 36.445 & 40.230 & 17.989 & 21.469 & 19.979 & 227.119 & 142.329 & 33.566 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_967 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_833 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_968 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_834 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_969 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_835 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_970 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 56s 35us/step - loss: 0.1772 - val_loss: 0.1675\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 45s 27us/step - loss: 0.1644 - val_loss: 0.1606\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1608 - val_loss: 0.1569\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1592 - val_loss: 0.1554\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1581 - val_loss: 0.1565\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1573 - val_loss: 0.1553\n",
      "Epoch 7/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1565 - val_loss: 0.1543\n",
      "Epoch 8/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1561 - val_loss: 0.1530\n",
      "Epoch 9/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1556 - val_loss: 0.1515\n",
      "Epoch 10/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1552 - val_loss: 0.1523\n",
      "Epoch 11/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1549 - val_loss: 0.1521\n",
      "features_True_linear_False_days_50_dropout_0.2_freq_10_NN_32_12_12 & 32.955 & 38.654 & 16.679 & 23.516 & 18.512 & 211.762 & 130.600 & 36.430 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_971 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_836 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_972 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_837 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_973 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_838 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_974 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 56s 35us/step - loss: 0.1932 - val_loss: 0.1943\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1914 - val_loss: 0.1942\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1910 - val_loss: 0.1929\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1908 - val_loss: 0.1927\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1907 - val_loss: 0.1935\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1906 - val_loss: 0.1931\n",
      "features_False_linear_False_days_50_dropout_0.2_freq_10_NN_32_12_12 & 35.642 & 40.930 & 18.209 & 21.323 & 21.151 & 247.986 & 156.604 & 31.278 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_975 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_839 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_976 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_840 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_977 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_841 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_978 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 53s 35us/step - loss: 0.1790 - val_loss: 0.1679\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 42s 28us/step - loss: 0.1647 - val_loss: 0.1591\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 41s 28us/step - loss: 0.1597 - val_loss: 0.1565\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1573 - val_loss: 0.1531\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1559 - val_loss: 0.1514\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 41s 28us/step - loss: 0.1549 - val_loss: 0.1523\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1542 - val_loss: 0.1512\n",
      "Epoch 8/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1536 - val_loss: 0.1499\n",
      "Epoch 9/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1533 - val_loss: 0.1498\n",
      "Epoch 10/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1530 - val_loss: 0.1500\n",
      "Epoch 11/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1528 - val_loss: 0.1499\n",
      "features_True_linear_False_days_50_dropout_0.2_freq_12_NN_32_12_12 & 32.148 & 38.766 & 16.576 & 24.697 & 19.197 & 223.324 & 138.517 & 35.013 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_979 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_842 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_980 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_843 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_981 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_844 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_982 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 52s 35us/step - loss: 0.1936 - val_loss: 0.1948\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1918 - val_loss: 0.1946\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1913 - val_loss: 0.1940\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1910 - val_loss: 0.1944\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1909 - val_loss: 0.1932\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1908 - val_loss: 0.1936\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1907 - val_loss: 0.1935\n",
      "features_False_linear_False_days_50_dropout_0.2_freq_12_NN_32_12_12 & 35.675 & 40.719 & 18.100 & 21.674 & 20.865 & 242.451 & 152.680 & 31.857 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_983 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_845 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_984 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_846 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_985 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_847 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_986 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 74s 33us/step - loss: 0.1787 - val_loss: 0.1697\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1654 - val_loss: 0.1643\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1617 - val_loss: 0.1650\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1597 - val_loss: 0.1648\n",
      "features_True_linear_False_days_70_dropout_0.2_freq_10_NN_32_12_12 & 31.178 & 40.576 & 17.362 & 25.418 & 22.449 & 270.268 & 173.036 & 28.477 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_987 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_848 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_988 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_849 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_989 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_850 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_990 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 71s 32us/step - loss: 0.1965 - val_loss: 0.1992\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 59s 26us/step - loss: 0.1949 - val_loss: 0.1988\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1944 - val_loss: 0.1983\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 59s 26us/step - loss: 0.1942 - val_loss: 0.1977\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1940 - val_loss: 0.1969\n",
      "Epoch 6/100\n",
      "2219791/2219791 [==============================] - 59s 26us/step - loss: 0.1939 - val_loss: 0.1982\n",
      "Epoch 7/100\n",
      "2219791/2219791 [==============================] - 59s 26us/step - loss: 0.1938 - val_loss: 0.1985\n",
      "features_False_linear_False_days_70_dropout_0.2_freq_10_NN_32_12_12 & 36.198 & 40.743 & 18.188 & 20.985 & 20.719 & 241.212 & 151.536 & 32.188 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_991 (Dense)            (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_851 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_992 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_852 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_993 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_853 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_994 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 69s 34us/step - loss: 0.1780 - val_loss: 0.1687\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1647 - val_loss: 0.1610\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1605 - val_loss: 0.1585\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1588 - val_loss: 0.1575\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1578 - val_loss: 0.1581\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1571 - val_loss: 0.1568\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 54s 27us/step - loss: 0.1566 - val_loss: 0.1566\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1561 - val_loss: 0.1552\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1557 - val_loss: 0.1544\n",
      "Epoch 10/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1554 - val_loss: 0.1542\n",
      "Epoch 11/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1553 - val_loss: 0.1555\n",
      "Epoch 12/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1550 - val_loss: 0.1546\n",
      "features_True_linear_False_days_70_dropout_0.2_freq_12_NN_32_12_12 & 31.634 & 39.291 & 16.739 & 25.173 & 20.174 & 238.159 & 149.261 & 32.964 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_995 (Dense)            (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_854 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_996 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_855 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_997 (Dense)            (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_856 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_998 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 67s 33us/step - loss: 0.1959 - val_loss: 0.1980\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 54s 27us/step - loss: 0.1943 - val_loss: 0.1974\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 54s 27us/step - loss: 0.1940 - val_loss: 0.1977\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1938 - val_loss: 0.1976\n",
      "features_False_linear_False_days_70_dropout_0.2_freq_12_NN_32_12_12 & 36.016 & 40.598 & 18.072 & 21.552 & 20.529 & 237.531 & 149.103 & 32.551 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_999 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_857 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1000 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_858 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1001 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_859 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1002 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 21s 305us/step - loss: 0.2499 - val_loss: 0.2848\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 9s 129us/step - loss: 0.2251 - val_loss: 0.2534\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 9s 128us/step - loss: 0.2185 - val_loss: 0.2366\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 9s 128us/step - loss: 0.2149 - val_loss: 0.2322\n",
      "Epoch 5/100\n",
      "67430/67430 [==============================] - 9s 128us/step - loss: 0.2126 - val_loss: 0.2284\n",
      "Epoch 6/100\n",
      "67430/67430 [==============================] - 9s 128us/step - loss: 0.2110 - val_loss: 0.2371\n",
      "Epoch 7/100\n",
      "67430/67430 [==============================] - 9s 127us/step - loss: 0.2092 - val_loss: 0.2284\n",
      "features_True_linear_False_days_1_dropout_0.5_freq_10_NN_32_12_12 & 37.474 & 40.807 & 18.443 & 19.882 & 20.417 & 232.863 & 145.347 & 32.721 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1003 (Dense)           (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_860 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1004 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_861 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1005 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_862 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1006 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 20s 301us/step - loss: 0.2360 - val_loss: 0.2231\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 9s 127us/step - loss: 0.2238 - val_loss: 0.2238\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 9s 128us/step - loss: 0.2211 - val_loss: 0.2255\n",
      "features_False_linear_False_days_1_dropout_0.5_freq_10_NN_32_12_12 & 36.371 & 41.090 & 18.390 & 20.487 & 21.327 & 249.140 & 157.257 & 30.972 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1007 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_863 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1008 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_864 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1009 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_865 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1010 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 20s 321us/step - loss: 0.2401 - val_loss: 0.2334\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 8s 129us/step - loss: 0.2226 - val_loss: 0.2398\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 8s 130us/step - loss: 0.2155 - val_loss: 0.2370\n",
      "features_True_linear_False_days_1_dropout_0.5_freq_12_NN_32_12_12 & 36.729 & 41.485 & 18.859 & 21.661 & 23.316 & 267.879 & 170.206 & 28.310 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1011 (Dense)           (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dropout_866 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1012 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_867 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1013 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_868 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1014 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,813\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 20s 318us/step - loss: 0.2347 - val_loss: 0.2209\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 8s 130us/step - loss: 0.2214 - val_loss: 0.2209\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 8s 130us/step - loss: 0.2179 - val_loss: 0.2212\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 8s 128us/step - loss: 0.2165 - val_loss: 0.2190\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 8s 129us/step - loss: 0.2151 - val_loss: 0.2184\n",
      "Epoch 6/100\n",
      "62237/62237 [==============================] - 8s 127us/step - loss: 0.2139 - val_loss: 0.2183\n",
      "Epoch 7/100\n",
      "62237/62237 [==============================] - 8s 127us/step - loss: 0.2130 - val_loss: 0.2177\n",
      "Epoch 8/100\n",
      "62237/62237 [==============================] - 8s 126us/step - loss: 0.2127 - val_loss: 0.2181\n",
      "Epoch 9/100\n",
      "62237/62237 [==============================] - 8s 125us/step - loss: 0.2125 - val_loss: 0.2173\n",
      "Epoch 10/100\n",
      "62237/62237 [==============================] - 8s 126us/step - loss: 0.2117 - val_loss: 0.2168\n",
      "Epoch 11/100\n",
      "62237/62237 [==============================] - 8s 126us/step - loss: 0.2115 - val_loss: 0.2159\n",
      "Epoch 12/100\n",
      "62237/62237 [==============================] - 8s 126us/step - loss: 0.2114 - val_loss: 0.2164\n",
      "Epoch 13/100\n",
      "62237/62237 [==============================] - 8s 127us/step - loss: 0.2111 - val_loss: 0.2169\n",
      "features_False_linear_False_days_1_dropout_0.5_freq_12_NN_32_12_12 & 35.517 & 41.064 & 18.224 & 21.732 & 21.433 & 250.943 & 158.812 & 30.773 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1015 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_869 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1016 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_870 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1017 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_871 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1018 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 24s 114us/step - loss: 0.1845 - val_loss: 0.1723\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1714 - val_loss: 0.1661\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1676 - val_loss: 0.1656\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1651 - val_loss: 0.1603\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1628 - val_loss: 0.1601\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1615 - val_loss: 0.1587\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1603 - val_loss: 0.1583\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 12s 57us/step - loss: 0.1595 - val_loss: 0.1573\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1591 - val_loss: 0.1566\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1585 - val_loss: 0.1551\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 12s 57us/step - loss: 0.1585 - val_loss: 0.1551\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1578 - val_loss: 0.1550\n",
      "Epoch 13/100\n",
      "214031/214031 [==============================] - 12s 57us/step - loss: 0.1576 - val_loss: 0.1554\n",
      "Epoch 14/100\n",
      "214031/214031 [==============================] - 12s 58us/step - loss: 0.1577 - val_loss: 0.1553\n",
      "features_True_linear_False_days_5_dropout_0.5_freq_10_NN_32_12_12 & 35.054 & 39.914 & 17.693 & 21.344 & 19.742 & 227.127 & 141.758 & 33.903 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1019 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_872 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1020 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_873 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1021 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_874 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1022 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 23s 106us/step - loss: 0.1839 - val_loss: 0.1736\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 11s 52us/step - loss: 0.1752 - val_loss: 0.1759\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 11s 50us/step - loss: 0.1739 - val_loss: 0.1701\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 11s 53us/step - loss: 0.1732 - val_loss: 0.1700\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 11s 52us/step - loss: 0.1726 - val_loss: 0.1698\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 11s 52us/step - loss: 0.1722 - val_loss: 0.1695\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 11s 51us/step - loss: 0.1722 - val_loss: 0.1685\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 11s 53us/step - loss: 0.1719 - val_loss: 0.1689\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 11s 51us/step - loss: 0.1718 - val_loss: 0.1681\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 11s 52us/step - loss: 0.1718 - val_loss: 0.1672\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 11s 52us/step - loss: 0.1714 - val_loss: 0.1686\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 11s 50us/step - loss: 0.1716 - val_loss: 0.1680\n",
      "features_False_linear_False_days_5_dropout_0.5_freq_10_NN_32_12_12 & 35.946 & 40.913 & 18.212 & 21.132 & 20.958 & 244.921 & 154.431 & 31.712 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1023 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_875 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1024 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_876 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1025 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_877 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1026 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 22s 111us/step - loss: 0.1835 - val_loss: 0.1688\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1711 - val_loss: 0.1643\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1675 - val_loss: 0.1611\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 11s 53us/step - loss: 0.1650 - val_loss: 0.1596\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1632 - val_loss: 0.1578\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1615 - val_loss: 0.1584\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1602 - val_loss: 0.1573\n",
      "Epoch 8/100\n",
      "197977/197977 [==============================] - 10s 52us/step - loss: 0.1591 - val_loss: 0.1558\n",
      "Epoch 9/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1583 - val_loss: 0.1560\n",
      "Epoch 10/100\n",
      "197977/197977 [==============================] - 11s 57us/step - loss: 0.1576 - val_loss: 0.1548: 0\n",
      "Epoch 11/100\n",
      "197977/197977 [==============================] - 10s 52us/step - loss: 0.1573 - val_loss: 0.1542\n",
      "Epoch 12/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1571 - val_loss: 0.1531\n",
      "Epoch 13/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1567 - val_loss: 0.1534\n",
      "Epoch 14/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1563 - val_loss: 0.1527\n",
      "Epoch 15/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1560 - val_loss: 0.1529\n",
      "Epoch 16/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1559 - val_loss: 0.1523\n",
      "Epoch 17/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1559 - val_loss: 0.1524\n",
      "Epoch 18/100\n",
      "197977/197977 [==============================] - 10s 51us/step - loss: 0.1557 - val_loss: 0.1525\n",
      "features_True_linear_False_days_5_dropout_0.5_freq_12_NN_32_12_12 & 34.673 & 39.705 & 17.526 & 22.307 & 19.738 & 226.013 & 141.427 & 33.810 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1027 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_878 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1028 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_879 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1029 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_880 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1030 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 21s 107us/step - loss: 0.1830 - val_loss: 0.1712\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1749 - val_loss: 0.1706\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 10s 53us/step - loss: 0.1731 - val_loss: 0.1706\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1723 - val_loss: 0.1692\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 10s 52us/step - loss: 0.1719 - val_loss: 0.1696\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 10s 50us/step - loss: 0.1717 - val_loss: 0.1700\n",
      "features_False_linear_False_days_5_dropout_0.5_freq_12_NN_32_12_12 & 36.315 & 40.815 & 18.205 & 21.156 & 20.718 & 240.021 & 150.677 & 32.256 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1031 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_881 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1032 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_882 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1033 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_883 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1034 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 26s 70us/step - loss: 0.1840 - val_loss: 0.1704\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1700 - val_loss: 0.1633\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1654 - val_loss: 0.1628\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1626 - val_loss: 0.1601\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1612 - val_loss: 0.1588\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1604 - val_loss: 0.1569\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1595 - val_loss: 0.1568\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1593 - val_loss: 0.1572\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1591 - val_loss: 0.1554\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1587 - val_loss: 0.1549\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1585 - val_loss: 0.1544\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1584 - val_loss: 0.1551\n",
      "Epoch 13/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1583 - val_loss: 0.1544\n",
      "features_True_linear_False_days_10_dropout_0.5_freq_10_NN_32_12_12 & 34.860 & 39.800 & 17.592 & 21.470 & 19.537 & 224.854 & 140.003 & 34.249 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1035 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_884 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1036 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_885 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1037 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_886 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1038 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 26s 71us/step - loss: 0.1836 - val_loss: 0.1752\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1764 - val_loss: 0.1735\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 15s 40us/step - loss: 0.1749 - val_loss: 0.1710\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 15s 39us/step - loss: 0.1745 - val_loss: 0.1716\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 14s 39us/step - loss: 0.1741 - val_loss: 0.1712\n",
      "features_False_linear_False_days_10_dropout_0.5_freq_10_NN_32_12_12 & 36.584 & 40.809 & 18.241 & 20.708 & 20.540 & 238.304 & 149.409 & 32.621 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1039 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_887 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1040 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_888 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1041 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_889 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1042 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 26s 77us/step - loss: 0.1780 - val_loss: 0.1677\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1673 - val_loss: 0.1625\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1636 - val_loss: 0.1583\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1613 - val_loss: 0.1556\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1600 - val_loss: 0.1551\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1593 - val_loss: 0.1546\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1586 - val_loss: 0.1532\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1583 - val_loss: 0.1533\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1579 - val_loss: 0.1526\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1574 - val_loss: 0.1525\n",
      "Epoch 11/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1574 - val_loss: 0.1526\n",
      "Epoch 12/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1573 - val_loss: 0.1528\n",
      "features_True_linear_False_days_10_dropout_0.5_freq_12_NN_32_12_12 & 33.952 & 40.199 & 17.607 & 22.533 & 20.648 & 241.701 & 151.905 & 32.004 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1043 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_890 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1044 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_891 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1045 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_892 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1046 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 25s 73us/step - loss: 0.1806 - val_loss: 0.1733\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1751 - val_loss: 0.1712\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 14s 41us/step - loss: 0.1738 - val_loss: 0.1698\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1732 - val_loss: 0.1691\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1728 - val_loss: 0.1688\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1725 - val_loss: 0.1693\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1723 - val_loss: 0.1684\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1723 - val_loss: 0.1683\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 14s 40us/step - loss: 0.1721 - val_loss: 0.1686\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 13s 39us/step - loss: 0.1721 - val_loss: 0.1683\n",
      "features_False_linear_False_days_10_dropout_0.5_freq_12_NN_32_12_12 & 35.617 & 40.877 & 18.144 & 21.840 & 21.072 & 245.781 & 155.141 & 31.474 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1047 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_893 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1048 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_894 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1049 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_895 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1050 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1879 - val_loss: 0.1774\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 30s 30us/step - loss: 0.1761 - val_loss: 0.1724\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1735 - val_loss: 0.1726\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 29s 30us/step - loss: 0.1722 - val_loss: 0.1682\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 29s 30us/step - loss: 0.1716 - val_loss: 0.1698\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 29s 30us/step - loss: 0.1711 - val_loss: 0.1692\n",
      "features_True_linear_False_days_30_dropout_0.5_freq_10_NN_32_12_12 & 32.942 & 41.243 & 17.976 & 23.665 & 22.554 & 270.297 & 172.848 & 28.414 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1051 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_896 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1052 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_897 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1053 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_898 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1054 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1905 - val_loss: 0.1852\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1868 - val_loss: 0.1842\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1860 - val_loss: 0.1836\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1856 - val_loss: 0.1834\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1855 - val_loss: 0.1828\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1853 - val_loss: 0.1827\n",
      "Epoch 7/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1853 - val_loss: 0.1837\n",
      "Epoch 8/100\n",
      "988463/988463 [==============================] - 29s 29us/step - loss: 0.1852 - val_loss: 0.1837\n",
      "features_False_linear_False_days_30_dropout_0.5_freq_10_NN_32_12_12 & 35.232 & 41.319 & 18.341 & 21.499 & 21.919 & 259.131 & 164.775 & 29.779 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1055 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_899 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1056 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_900 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1057 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_901 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1058 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 39s 43us/step - loss: 0.1849 - val_loss: 0.1715\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1738 - val_loss: 0.1660\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 28s 30us/step - loss: 0.1706 - val_loss: 0.1634\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1693 - val_loss: 0.1626\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 28s 31us/step - loss: 0.1684 - val_loss: 0.1622\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1680 - val_loss: 0.1607\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1678 - val_loss: 0.1607\n",
      "Epoch 8/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1676 - val_loss: 0.1610\n",
      "Epoch 9/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1674 - val_loss: 0.1610\n",
      "features_True_linear_False_days_30_dropout_0.5_freq_12_NN_32_12_12 & 33.409 & 40.048 & 17.453 & 23.699 & 20.604 & 241.020 & 151.841 & 32.049 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1059 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_902 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1060 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_903 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1061 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_904 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1062 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 38s 42us/step - loss: 0.1901 - val_loss: 0.1836\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1859 - val_loss: 0.1828\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1853 - val_loss: 0.1826\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1850 - val_loss: 0.1831\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1848 - val_loss: 0.1824\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1847 - val_loss: 0.1819\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 27s 30us/step - loss: 0.1846 - val_loss: 0.1825\n",
      "Epoch 8/100\n",
      "911990/911990 [==============================] - 27s 29us/step - loss: 0.1846 - val_loss: 0.1825\n",
      "features_False_linear_False_days_30_dropout_0.5_freq_12_NN_32_12_12 & 35.600 & 40.863 & 18.145 & 21.763 & 21.064 & 245.199 & 154.833 & 31.456 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1063 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_905 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1064 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_906 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1065 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_907 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1066 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 57s 35us/step - loss: 0.1886 - val_loss: 0.1828\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1780 - val_loss: 0.1775\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 45s 28us/step - loss: 0.1765 - val_loss: 0.1781\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 45s 27us/step - loss: 0.1758 - val_loss: 0.1785\n",
      "features_True_linear_False_days_50_dropout_0.5_freq_10_NN_32_12_12 & 33.263 & 40.614 & 17.749 & 22.733 & 21.674 & 257.461 & 163.652 & 29.906 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1067 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_908 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1068 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_909 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1069 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_910 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1070 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 56s 35us/step - loss: 0.1969 - val_loss: 0.1958\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1938 - val_loss: 0.1951\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 45s 28us/step - loss: 0.1934 - val_loss: 0.1949\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1932 - val_loss: 0.1951\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1930 - val_loss: 0.1948\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1930 - val_loss: 0.1944\n",
      "Epoch 7/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1930 - val_loss: 0.1942\n",
      "Epoch 8/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1929 - val_loss: 0.1946\n",
      "Epoch 9/100\n",
      "1625518/1625518 [==============================] - 44s 27us/step - loss: 0.1928 - val_loss: 0.1949\n",
      "features_False_linear_False_days_50_dropout_0.5_freq_10_NN_32_12_12 & 36.013 & 40.955 & 18.251 & 21.100 & 20.978 & 245.414 & 154.620 & 31.690 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1071 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_911 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1072 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_912 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1073 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_913 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1074 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 56s 37us/step - loss: 0.1905 - val_loss: 0.1857\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 42s 28us/step - loss: 0.1792 - val_loss: 0.1825\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 41s 28us/step - loss: 0.1772 - val_loss: 0.1787\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 42s 28us/step - loss: 0.1763 - val_loss: 0.1780\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 42s 28us/step - loss: 0.1754 - val_loss: 0.1786\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1750 - val_loss: 0.1757\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 41s 28us/step - loss: 0.1749 - val_loss: 0.1768\n",
      "Epoch 8/100\n",
      "1499014/1499014 [==============================] - 42s 28us/step - loss: 0.1745 - val_loss: 0.1743\n",
      "Epoch 9/100\n",
      "1499014/1499014 [==============================] - 49s 33us/step - loss: 0.1744 - val_loss: 0.1755\n",
      "Epoch 10/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1743 - val_loss: 0.1773\n",
      "features_True_linear_False_days_50_dropout_0.5_freq_12_NN_32_12_12 & 32.890 & 40.811 & 17.770 & 24.200 & 22.058 & 261.766 & 166.790 & 29.331 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1075 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_914 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1076 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_915 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1077 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_916 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1078 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 53s 36us/step - loss: 0.1974 - val_loss: 0.1963\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1941 - val_loss: 0.1957\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1937 - val_loss: 0.1965\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 41s 27us/step - loss: 0.1934 - val_loss: 0.1974\n",
      "features_False_linear_False_days_50_dropout_0.5_freq_12_NN_32_12_12 & 35.809 & 41.003 & 18.246 & 21.361 & 21.230 & 247.852 & 156.335 & 31.217 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1079 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_917 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1080 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_918 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1081 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_919 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1082 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 74s 34us/step - loss: 0.1892 - val_loss: 0.1835\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1802 - val_loss: 0.1800\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1790 - val_loss: 0.1814\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1779 - val_loss: 0.1789\n",
      "Epoch 6/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1775 - val_loss: 0.1789\n",
      "Epoch 7/100\n",
      "2219791/2219791 [==============================] - 66s 30us/step - loss: 0.1773 - val_loss: 0.1766\n",
      "Epoch 8/100\n",
      "2219791/2219791 [==============================] - 61s 27us/step - loss: 0.1771 - val_loss: 0.1789\n",
      "Epoch 9/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1770 - val_loss: 0.1793\n",
      "features_True_linear_False_days_70_dropout_0.5_freq_10_NN_32_12_12 & 35.068 & 39.751 & 17.597 & 21.324 & 19.464 & 223.112 & 138.485 & 34.390 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1083 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_920 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1084 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_921 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1085 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_922 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1086 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 72s 32us/step - loss: 0.1995 - val_loss: 0.2007\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1971 - val_loss: 0.1999\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1967 - val_loss: 0.1992\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 60s 27us/step - loss: 0.1966 - val_loss: 0.1995\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1964 - val_loss: 0.1991\n",
      "Epoch 6/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1964 - val_loss: 0.1993\n",
      "Epoch 7/100\n",
      "2219791/2219791 [==============================] - 59s 27us/step - loss: 0.1963 - val_loss: 0.2000\n",
      "features_False_linear_False_days_70_dropout_0.5_freq_10_NN_32_12_12 & 36.227 & 40.938 & 18.257 & 20.919 & 20.788 & 242.703 & 152.499 & 32.129 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1087 (Dense)           (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dropout_923 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1088 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_924 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1089 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_925 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1090 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,197\n",
      "Trainable params: 2,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 68s 33us/step - loss: 0.1882 - val_loss: 0.1854\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1792 - val_loss: 0.1790\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1777 - val_loss: 0.1767\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1769 - val_loss: 0.1749\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1764 - val_loss: 0.1736\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1762 - val_loss: 0.1739\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1759 - val_loss: 0.1721\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1758 - val_loss: 0.1725\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1757 - val_loss: 0.1727\n",
      "features_True_linear_False_days_70_dropout_0.5_freq_12_NN_32_12_12 & 33.932 & 39.586 & 17.311 & 22.965 & 19.510 & 223.649 & 139.623 & 34.266 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1091 (Dense)           (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dropout_926 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1092 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_927 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1093 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_928 (Dropout)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1094 (Dense)           (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,845\n",
      "Trainable params: 1,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 73s 35us/step - loss: 0.1994 - val_loss: 0.2000\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 57s 28us/step - loss: 0.1967 - val_loss: 0.1996\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1962 - val_loss: 0.1988\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1961 - val_loss: 0.1991\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 55s 27us/step - loss: 0.1960 - val_loss: 0.1986\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1959 - val_loss: 0.2000\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1959 - val_loss: 0.1984\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1958 - val_loss: 0.1987\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 56s 27us/step - loss: 0.1958 - val_loss: 0.1984\n",
      "features_False_linear_False_days_70_dropout_0.5_freq_12_NN_32_12_12 & 36.217 & 40.567 & 18.079 & 21.556 & 20.366 & 234.624 & 147.160 & 32.915 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1095 (Dense)           (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dropout_929 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1096 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_930 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1097 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_931 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1098 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_932 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1099 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,433\n",
      "Trainable params: 29,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 23s 335us/step - loss: 0.1931 - val_loss: 0.3545\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 10s 151us/step - loss: 0.1779 - val_loss: 0.3617\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 10s 144us/step - loss: 0.1701 - val_loss: 0.4683\n",
      "features_True_linear_False_days_1_dropout_0_freq_10_NN_128_64_32_12 & 100.252 & 51.079 & 33.779 & 14.008 & 59.341 & 512.474 & 354.557 & 13.260 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1100 (Dense)           (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dropout_933 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1101 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_934 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1102 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_935 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1103 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_936 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1104 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,025\n",
      "Trainable params: 28,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 22s 329us/step - loss: 0.2119 - val_loss: 0.2193\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 10s 150us/step - loss: 0.2105 - val_loss: 0.2200\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 10s 143us/step - loss: 0.2099 - val_loss: 0.2188\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 10s 148us/step - loss: 0.2093 - val_loss: 0.2186\n",
      "Epoch 5/100\n",
      "67430/67430 [==============================] - 10s 149us/step - loss: 0.2086 - val_loss: 0.2187\n",
      "Epoch 6/100\n",
      "67430/67430 [==============================] - 10s 148us/step - loss: 0.2083 - val_loss: 0.2184\n",
      "Epoch 7/100\n",
      "67430/67430 [==============================] - 10s 150us/step - loss: 0.2080 - val_loss: 0.2198\n",
      "Epoch 8/100\n",
      "67430/67430 [==============================] - 10s 144us/step - loss: 0.2077 - val_loss: 0.2188\n",
      "features_False_linear_False_days_1_dropout_0_freq_10_NN_128_64_32_12 & 35.159 & 40.711 & 18.143 & 22.182 & 21.498 & 250.217 & 159.662 & 30.158 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1105 (Dense)           (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dropout_937 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1106 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_938 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1107 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_939 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1108 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_940 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1109 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,433\n",
      "Trainable params: 29,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 22s 352us/step - loss: 0.1886 - val_loss: 0.2887\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 10s 154us/step - loss: 0.1725 - val_loss: 0.3273\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 9s 147us/step - loss: 0.1642 - val_loss: 0.3882\n",
      "features_True_linear_False_days_1_dropout_0_freq_12_NN_128_64_32_12 & 38.663 & 43.929 & 21.015 & 20.434 & 28.664 & 333.187 & 213.355 & 22.775 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1110 (Dense)           (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dropout_941 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1111 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_942 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1112 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_943 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1113 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_944 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1114 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,025\n",
      "Trainable params: 28,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 22s 351us/step - loss: 0.2077 - val_loss: 0.2148\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 9s 151us/step - loss: 0.2060 - val_loss: 0.2151\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 9s 144us/step - loss: 0.2054 - val_loss: 0.2177\n",
      "features_False_linear_False_days_1_dropout_0_freq_12_NN_128_64_32_12 & 35.390 & 40.533 & 18.082 & 22.670 & 21.259 & 244.736 & 156.016 & 30.610 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1115 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_945 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1116 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_946 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1117 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_947 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1118 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_948 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1119 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 27s 126us/step - loss: 0.1495 - val_loss: 0.1433\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 15s 69us/step - loss: 0.1350 - val_loss: 0.1373\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 15s 68us/step - loss: 0.1289 - val_loss: 0.1329\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 15s 68us/step - loss: 0.1250 - val_loss: 0.1330\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1224 - val_loss: 0.1304\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 15s 68us/step - loss: 0.1204 - val_loss: 0.1289\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 15s 69us/step - loss: 0.1188 - val_loss: 0.1296\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1176 - val_loss: 0.1256\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 14s 68us/step - loss: 0.1167 - val_loss: 0.1290\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 14s 66us/step - loss: 0.1158 - val_loss: 0.1244\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 14s 68us/step - loss: 0.1151 - val_loss: 0.1261\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1144 - val_loss: 0.1251\n",
      "features_True_linear_False_days_5_dropout_0_freq_10_NN_128_64_32_12 & 32.959 & 36.837 & 16.035 & 25.535 & 17.042 & 179.884 & 111.002 & 39.327 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1120 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_949 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1121 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_950 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1122 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_951 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1123 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_952 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1124 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 27s 126us/step - loss: 0.1698 - val_loss: 0.1663\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1685 - val_loss: 0.1710\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 14s 65us/step - loss: 0.1679 - val_loss: 0.1660\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1675 - val_loss: 0.1703\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 14s 67us/step - loss: 0.1672 - val_loss: 0.1662\n",
      "features_False_linear_False_days_5_dropout_0_freq_10_NN_128_64_32_12 & 35.828 & 40.290 & 18.055 & 22.137 & 20.693 & 236.613 & 150.139 & 31.889 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1125 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_953 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1126 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_954 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1127 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_955 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1128 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_956 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1129 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 27s 135us/step - loss: 0.1484 - val_loss: 0.1407\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 14s 68us/step - loss: 0.1339 - val_loss: 0.1359\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1281 - val_loss: 0.1348\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1245 - val_loss: 0.1283\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1217 - val_loss: 0.1272\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1196 - val_loss: 0.1255\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1182 - val_loss: 0.1242\n",
      "Epoch 8/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1169 - val_loss: 0.1246\n",
      "Epoch 9/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1159 - val_loss: 0.1258\n",
      "features_True_linear_False_days_5_dropout_0_freq_12_NN_128_64_32_12 & 32.005 & 37.688 & 16.190 & 26.496 & 18.414 & 210.230 & 129.613 & 36.922 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1130 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_957 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1131 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_958 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1132 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_959 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1133 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_960 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1134 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 26s 131us/step - loss: 0.1689 - val_loss: 0.1677\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1675 - val_loss: 0.1658\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1668 - val_loss: 0.1652\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 14s 68us/step - loss: 0.1665 - val_loss: 0.1653\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 13s 67us/step - loss: 0.1663 - val_loss: 0.1647\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 14s 69us/step - loss: 0.1660 - val_loss: 0.1651\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 13s 67us/step - loss: 0.1658 - val_loss: 0.1651\n",
      "features_False_linear_False_days_5_dropout_0_freq_12_NN_128_64_32_12 & 35.567 & 40.329 & 18.000 & 22.069 & 20.791 & 238.901 & 151.185 & 31.715 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1135 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_961 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1136 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_962 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1137 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_963 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1138 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_964 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1139 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 32s 86us/step - loss: 0.1459 - val_loss: 0.1367\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1313 - val_loss: 0.1314\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 20s 53us/step - loss: 0.1254 - val_loss: 0.1305\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1220 - val_loss: 0.1224\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1198 - val_loss: 0.1233\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1183 - val_loss: 0.1206\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1171 - val_loss: 0.1196\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1162 - val_loss: 0.1196\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1156 - val_loss: 0.1186\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1150 - val_loss: 0.1189\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1144 - val_loss: 0.1180\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1139 - val_loss: 0.1179\n",
      "Epoch 13/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1135 - val_loss: 0.1173\n",
      "Epoch 14/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1131 - val_loss: 0.1179\n",
      "Epoch 15/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1127 - val_loss: 0.1181\n",
      "features_True_linear_False_days_10_dropout_0_freq_10_NN_128_64_32_12 & 31.792 & 36.485 & 15.684 & 26.283 & 16.696 & 174.654 & 108.082 & 39.920 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1140 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_965 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1141 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_966 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1142 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_967 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1143 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_968 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1144 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 32s 86us/step - loss: 0.1713 - val_loss: 0.1690\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1700 - val_loss: 0.1678\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 19s 52us/step - loss: 0.1695 - val_loss: 0.1671\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1691 - val_loss: 0.1679\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1689 - val_loss: 0.1666\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1686 - val_loss: 0.1665\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1685 - val_loss: 0.1667\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1683 - val_loss: 0.1664\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1682 - val_loss: 0.1666\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 19s 50us/step - loss: 0.1681 - val_loss: 0.1658\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 19s 51us/step - loss: 0.1679 - val_loss: 0.1669\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 19s 50us/step - loss: 0.1678 - val_loss: 0.1659\n",
      "features_False_linear_False_days_10_dropout_0_freq_10_NN_128_64_32_12 & 36.000 & 40.173 & 17.995 & 21.717 & 20.189 & 230.292 & 145.056 & 33.044 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1145 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_969 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1146 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_970 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1147 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_971 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1148 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_972 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1149 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 31s 92us/step - loss: 0.1451 - val_loss: 0.1409\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 18s 53us/step - loss: 0.1299 - val_loss: 0.1266\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 18s 53us/step - loss: 0.1241 - val_loss: 0.1251\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 18s 53us/step - loss: 0.1209 - val_loss: 0.1214\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1188 - val_loss: 0.1212\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1173 - val_loss: 0.1193\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 18s 53us/step - loss: 0.1162 - val_loss: 0.1181\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1153 - val_loss: 0.1174\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 18s 54us/step - loss: 0.1147 - val_loss: 0.1175\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1141 - val_loss: 0.1168\n",
      "Epoch 11/100\n",
      "341937/341937 [==============================] - 18s 53us/step - loss: 0.1136 - val_loss: 0.1165\n",
      "Epoch 12/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1131 - val_loss: 0.1176\n",
      "Epoch 13/100\n",
      "341937/341937 [==============================] - 18s 51us/step - loss: 0.1128 - val_loss: 0.1165\n",
      "Epoch 14/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1123 - val_loss: 0.1168\n",
      "Epoch 15/100\n",
      "341937/341937 [==============================] - 18s 52us/step - loss: 0.1120 - val_loss: 0.1170\n",
      "features_True_linear_False_days_10_dropout_0_freq_12_NN_128_64_32_12 & 31.217 & 36.879 & 15.645 & 27.237 & 17.278 & 189.786 & 117.112 & 39.005 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1150 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_973 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1151 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_974 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1152 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_975 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1153 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_976 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1154 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 31s 92us/step - loss: 0.1702 - val_loss: 0.1675\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 20s 58us/step - loss: 0.1689 - val_loss: 0.1667\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 19s 57us/step - loss: 0.1685 - val_loss: 0.1662\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 19s 55us/step - loss: 0.1681 - val_loss: 0.1656\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 20s 58us/step - loss: 0.1678 - val_loss: 0.1656\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 19s 55us/step - loss: 0.1675 - val_loss: 0.1655\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 19s 56us/step - loss: 0.1673 - val_loss: 0.1651\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 20s 59us/step - loss: 0.1671 - val_loss: 0.1655\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 20s 57us/step - loss: 0.1669 - val_loss: 0.1651\n",
      "features_False_linear_False_days_10_dropout_0_freq_12_NN_128_64_32_12 & 35.659 & 40.245 & 17.950 & 22.058 & 20.537 & 235.700 & 148.687 & 32.307 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1155 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_977 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1156 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_978 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1157 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_979 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1158 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_980 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1159 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 54s 55us/step - loss: 0.1455 - val_loss: 0.1375\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1290 - val_loss: 0.1278\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1252 - val_loss: 0.1267\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1233 - val_loss: 0.1252\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1222 - val_loss: 0.1238\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1214 - val_loss: 0.1240\n",
      "Epoch 7/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1208 - val_loss: 0.1232\n",
      "Epoch 8/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1203 - val_loss: 0.1226\n",
      "Epoch 9/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1199 - val_loss: 0.1218\n",
      "Epoch 10/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1195 - val_loss: 0.1226\n",
      "Epoch 11/100\n",
      "988463/988463 [==============================] - 41s 42us/step - loss: 0.1192 - val_loss: 0.1213\n",
      "Epoch 12/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1190 - val_loss: 0.1219\n",
      "Epoch 13/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1188 - val_loss: 0.1210\n",
      "Epoch 14/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1185 - val_loss: 0.1215\n",
      "Epoch 15/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1183 - val_loss: 0.1208\n",
      "Epoch 16/100\n",
      "988463/988463 [==============================] - 42s 42us/step - loss: 0.1181 - val_loss: 0.1212\n",
      "Epoch 17/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1180 - val_loss: 0.1200\n",
      "Epoch 18/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1179 - val_loss: 0.1207\n",
      "Epoch 19/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1177 - val_loss: 0.1201\n",
      "features_True_linear_False_days_30_dropout_0_freq_10_NN_128_64_32_12 & 29.865 & 36.563 & 15.263 & 28.853 & 17.142 & 194.782 & 119.470 & 39.649 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1160 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_981 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1161 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_982 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1162 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_983 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1163 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_984 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1164 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 988463 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "988463/988463 [==============================] - 54s 54us/step - loss: 0.1833 - val_loss: 0.1813\n",
      "Epoch 2/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1821 - val_loss: 0.1807\n",
      "Epoch 3/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1817 - val_loss: 0.1807\n",
      "Epoch 4/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1814 - val_loss: 0.1800\n",
      "Epoch 5/100\n",
      "988463/988463 [==============================] - 40s 40us/step - loss: 0.1812 - val_loss: 0.1800\n",
      "Epoch 6/100\n",
      "988463/988463 [==============================] - 39s 40us/step - loss: 0.1810 - val_loss: 0.1806\n",
      "Epoch 7/100\n",
      "988463/988463 [==============================] - 41s 41us/step - loss: 0.1808 - val_loss: 0.1799\n",
      "Epoch 8/100\n",
      "988463/988463 [==============================] - 42s 42us/step - loss: 0.1807 - val_loss: 0.1797\n",
      "Epoch 9/100\n",
      "988463/988463 [==============================] - 39s 40us/step - loss: 0.1806 - val_loss: 0.1797\n",
      "Epoch 10/100\n",
      "988463/988463 [==============================] - 40s 41us/step - loss: 0.1805 - val_loss: 0.1801\n",
      "features_False_linear_False_days_30_dropout_0_freq_10_NN_128_64_32_12 & 35.608 & 40.701 & 18.136 & 21.504 & 20.943 & 244.656 & 154.341 & 31.618 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1165 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_985 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1166 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_986 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1167 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_987 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1168 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_988 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1169 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 51s 56us/step - loss: 0.1462 - val_loss: 0.1345\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 37s 41us/step - loss: 0.1298 - val_loss: 0.1296\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 38s 41us/step - loss: 0.1255 - val_loss: 0.1265\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 44s 48us/step - loss: 0.1235 - val_loss: 0.1245\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 40s 43us/step - loss: 0.1223 - val_loss: 0.1241\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 39s 42us/step - loss: 0.1214 - val_loss: 0.1239\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 39s 43us/step - loss: 0.1208 - val_loss: 0.1227\n",
      "Epoch 8/100\n",
      "911990/911990 [==============================] - 38s 42us/step - loss: 0.1203 - val_loss: 0.1227\n",
      "Epoch 9/100\n",
      "911990/911990 [==============================] - 38s 41us/step - loss: 0.1198 - val_loss: 0.1222\n",
      "Epoch 10/100\n",
      "911990/911990 [==============================] - 38s 42us/step - loss: 0.1195 - val_loss: 0.1216\n",
      "Epoch 11/100\n",
      "911990/911990 [==============================] - 38s 42us/step - loss: 0.1192 - val_loss: 0.1222\n",
      "Epoch 12/100\n",
      "911990/911990 [==============================] - 38s 41us/step - loss: 0.1190 - val_loss: 0.1210\n",
      "Epoch 13/100\n",
      "911990/911990 [==============================] - 37s 41us/step - loss: 0.1187 - val_loss: 0.1221\n",
      "Epoch 14/100\n",
      "911990/911990 [==============================] - 37s 41us/step - loss: 0.1184 - val_loss: 0.1217\n",
      "features_True_linear_False_days_30_dropout_0_freq_12_NN_128_64_32_12 & 30.233 & 36.698 & 15.371 & 28.650 & 17.403 & 195.780 & 120.688 & 38.802 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1170 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_989 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1171 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_990 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1172 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_991 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1173 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_992 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1174 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 911990 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "911990/911990 [==============================] - 49s 53us/step - loss: 0.1826 - val_loss: 0.1812\n",
      "Epoch 2/100\n",
      "911990/911990 [==============================] - 35s 39us/step - loss: 0.1814 - val_loss: 0.1802\n",
      "Epoch 3/100\n",
      "911990/911990 [==============================] - 36s 39us/step - loss: 0.1809 - val_loss: 0.1816\n",
      "Epoch 4/100\n",
      "911990/911990 [==============================] - 35s 38us/step - loss: 0.1805 - val_loss: 0.1799\n",
      "Epoch 5/100\n",
      "911990/911990 [==============================] - 35s 38us/step - loss: 0.1802 - val_loss: 0.1795\n",
      "Epoch 6/100\n",
      "911990/911990 [==============================] - 36s 39us/step - loss: 0.1800 - val_loss: 0.1790\n",
      "Epoch 7/100\n",
      "911990/911990 [==============================] - 35s 38us/step - loss: 0.1799 - val_loss: 0.1793\n",
      "Epoch 8/100\n",
      "911990/911990 [==============================] - 35s 38us/step - loss: 0.1797 - val_loss: 0.1791\n",
      "features_False_linear_False_days_30_dropout_0_freq_12_NN_128_64_32_12 & 35.635 & 40.349 & 17.973 & 22.005 & 20.430 & 234.353 & 147.612 & 32.568 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1175 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_993 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1176 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_994 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1177 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_995 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1178 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_996 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1179 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 72s 44us/step - loss: 0.1449 - val_loss: 0.1395\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 59s 36us/step - loss: 0.1300 - val_loss: 0.1326\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1270 - val_loss: 0.1313\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1256 - val_loss: 0.1297\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1247 - val_loss: 0.1305\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1240 - val_loss: 0.1297\n",
      "features_True_linear_False_days_50_dropout_0_freq_10_NN_128_64_32_12 & 29.868 & 36.991 & 15.416 & 28.534 & 17.629 & 203.868 & 125.011 & 38.543 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1180 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_997 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1181 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_998 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1182 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_999 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1183 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1000 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1184 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1625518 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "1625518/1625518 [==============================] - 71s 44us/step - loss: 0.1905 - val_loss: 0.1923\n",
      "Epoch 2/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1891 - val_loss: 0.1916\n",
      "Epoch 3/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1886 - val_loss: 0.1906\n",
      "Epoch 4/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1883 - val_loss: 0.1906\n",
      "Epoch 5/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1881 - val_loss: 0.1911\n",
      "Epoch 6/100\n",
      "1625518/1625518 [==============================] - 58s 36us/step - loss: 0.1879 - val_loss: 0.1910\n",
      "features_False_linear_False_days_50_dropout_0_freq_10_NN_128_64_32_12 & 35.513 & 40.592 & 18.087 & 21.938 & 20.763 & 241.007 & 152.171 & 31.936 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1185 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1001 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1186 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1002 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1187 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1003 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1188 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1004 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1189 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 68s 46us/step - loss: 0.1446 - val_loss: 0.1371\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 56s 37us/step - loss: 0.1297 - val_loss: 0.1339\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 55s 36us/step - loss: 0.1269 - val_loss: 0.1310\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1255 - val_loss: 0.1307\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1246 - val_loss: 0.1303\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1240 - val_loss: 0.1301\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1235 - val_loss: 0.1290\n",
      "Epoch 8/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1232 - val_loss: 0.1290\n",
      "Epoch 9/100\n",
      "1499014/1499014 [==============================] - 55s 36us/step - loss: 0.1228 - val_loss: 0.1286\n",
      "Epoch 10/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1226 - val_loss: 0.1287\n",
      "Epoch 11/100\n",
      "1499014/1499014 [==============================] - 55s 37us/step - loss: 0.1223 - val_loss: 0.1297\n",
      "features_True_linear_False_days_50_dropout_0_freq_12_NN_128_64_32_12 & 29.767 & 37.180 & 15.475 & 29.079 & 18.081 & 209.396 & 129.488 & 37.469 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1190 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1005 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1191 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1006 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1192 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1007 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1193 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1008 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1194 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1499014 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "1499014/1499014 [==============================] - 68s 45us/step - loss: 0.1906 - val_loss: 0.1930\n",
      "Epoch 2/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1892 - val_loss: 0.1919\n",
      "Epoch 3/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1886 - val_loss: 0.1915\n",
      "Epoch 4/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1882 - val_loss: 0.1919\n",
      "Epoch 5/100\n",
      "1499014/1499014 [==============================] - 53s 36us/step - loss: 0.1880 - val_loss: 0.1910\n",
      "Epoch 6/100\n",
      "1499014/1499014 [==============================] - 53s 36us/step - loss: 0.1878 - val_loss: 0.1914\n",
      "Epoch 7/100\n",
      "1499014/1499014 [==============================] - 54s 36us/step - loss: 0.1876 - val_loss: 0.1911\n",
      "features_False_linear_False_days_50_dropout_0_freq_12_NN_128_64_32_12 & 35.393 & 40.425 & 17.980 & 22.385 & 20.680 & 237.796 & 150.245 & 32.002 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1195 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1009 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1196 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1010 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1197 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1011 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1198 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1012 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1199 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 92s 42us/step - loss: 0.1429 - val_loss: 0.1403\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 78s 35us/step - loss: 0.1296 - val_loss: 0.1393\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 77s 35us/step - loss: 0.1272 - val_loss: 0.1326\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 84s 38us/step - loss: 0.1261 - val_loss: 0.1328\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 83s 38us/step - loss: 0.1253 - val_loss: 0.1334\n",
      "features_True_linear_False_days_70_dropout_0_freq_10_NN_128_64_32_12 & 30.935 & 36.527 & 15.426 & 27.514 & 16.870 & 185.998 & 113.583 & 40.076 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1200 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1013 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1201 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1014 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1202 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1015 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1203 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1016 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1204 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2219791 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "2219791/2219791 [==============================] - 90s 41us/step - loss: 0.1936 - val_loss: 0.1970\n",
      "Epoch 2/100\n",
      "2219791/2219791 [==============================] - 77s 35us/step - loss: 0.1921 - val_loss: 0.1965\n",
      "Epoch 3/100\n",
      "2219791/2219791 [==============================] - 78s 35us/step - loss: 0.1916 - val_loss: 0.1975\n",
      "Epoch 4/100\n",
      "2219791/2219791 [==============================] - 77s 35us/step - loss: 0.1913 - val_loss: 0.1962\n",
      "Epoch 5/100\n",
      "2219791/2219791 [==============================] - 79s 36us/step - loss: 0.1911 - val_loss: 0.1949\n",
      "Epoch 6/100\n",
      "2219791/2219791 [==============================] - 77s 35us/step - loss: 0.1909 - val_loss: 0.1952\n",
      "Epoch 7/100\n",
      "2219791/2219791 [==============================] - 77s 35us/step - loss: 0.1908 - val_loss: 0.1955\n",
      "features_False_linear_False_days_70_dropout_0_freq_10_NN_128_64_32_12 & 35.068 & 40.679 & 18.094 & 22.332 & 21.408 & 250.375 & 159.191 & 30.493 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1205 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1017 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1206 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1018 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1207 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1019 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1208 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1020 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1209 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 86s 42us/step - loss: 0.1425 - val_loss: 0.1381\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 73s 35us/step - loss: 0.1295 - val_loss: 0.1343\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 73s 35us/step - loss: 0.1272 - val_loss: 0.1335\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1260 - val_loss: 0.1322\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 73s 35us/step - loss: 0.1252 - val_loss: 0.1322\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1247 - val_loss: 0.1307\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1243 - val_loss: 0.1312\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1239 - val_loss: 0.1320\n",
      "features_True_linear_False_days_70_dropout_0_freq_12_NN_128_64_32_12 & 29.736 & 37.144 & 15.433 & 29.141 & 17.950 & 207.519 & 128.066 & 37.790 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1210 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1021 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1211 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1022 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1212 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1023 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1213 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1024 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1214 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2049015 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "2049015/2049015 [==============================] - 85s 42us/step - loss: 0.1930 - val_loss: 0.1956\n",
      "Epoch 2/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1915 - val_loss: 0.1953\n",
      "Epoch 3/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1909 - val_loss: 0.1947\n",
      "Epoch 4/100\n",
      "2049015/2049015 [==============================] - 73s 35us/step - loss: 0.1906 - val_loss: 0.1948\n",
      "Epoch 5/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1904 - val_loss: 0.1947\n",
      "Epoch 6/100\n",
      "2049015/2049015 [==============================] - 74s 36us/step - loss: 0.1903 - val_loss: 0.1946\n",
      "Epoch 7/100\n",
      "2049015/2049015 [==============================] - 75s 36us/step - loss: 0.1901 - val_loss: 0.1943\n",
      "Epoch 8/100\n",
      "2049015/2049015 [==============================] - 73s 36us/step - loss: 0.1900 - val_loss: 0.1955\n",
      "Epoch 9/100\n",
      "2049015/2049015 [==============================] - 72s 35us/step - loss: 0.1899 - val_loss: 0.1944\n",
      "features_False_linear_False_days_70_dropout_0_freq_12_NN_128_64_32_12 & 35.596 & 40.396 & 17.955 & 22.121 & 20.494 & 236.325 & 148.702 & 32.501 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1215 (Dense)           (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dropout_1025 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1216 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1026 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1217 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1027 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1218 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1028 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1219 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,433\n",
      "Trainable params: 29,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 25s 376us/step - loss: 0.2086 - val_loss: 0.2224\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 12s 179us/step - loss: 0.1977 - val_loss: 0.2294\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 12s 174us/step - loss: 0.1921 - val_loss: 0.2509\n",
      "features_True_linear_False_days_1_dropout_0.2_freq_10_NN_128_64_32_12 & 34.071 & 42.192 & 18.929 & 22.418 & 25.151 & 296.765 & 193.473 & 24.388 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1220 (Dense)           (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dropout_1029 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1221 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1030 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1222 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1031 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1223 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1032 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1224 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,025\n",
      "Trainable params: 28,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 67430 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "67430/67430 [==============================] - 25s 377us/step - loss: 0.2150 - val_loss: 0.2194\n",
      "Epoch 2/100\n",
      "67430/67430 [==============================] - 12s 180us/step - loss: 0.2129 - val_loss: 0.2188\n",
      "Epoch 3/100\n",
      "67430/67430 [==============================] - 12s 174us/step - loss: 0.2122 - val_loss: 0.2203\n",
      "Epoch 4/100\n",
      "67430/67430 [==============================] - 11s 170us/step - loss: 0.2117 - val_loss: 0.2193\n",
      "features_False_linear_False_days_1_dropout_0.2_freq_10_NN_128_64_32_12 & 35.220 & 41.047 & 18.230 & 21.873 & 21.711 & 255.405 & 162.595 & 30.017 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1225 (Dense)           (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dropout_1033 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1226 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1034 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1227 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1035 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1228 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1036 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1229 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,433\n",
      "Trainable params: 29,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 25s 406us/step - loss: 0.2056 - val_loss: 0.3071\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 11s 185us/step - loss: 0.1939 - val_loss: 0.2385\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 11s 180us/step - loss: 0.1881 - val_loss: 0.2258\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 11s 179us/step - loss: 0.1834 - val_loss: 0.2752\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 11s 172us/step - loss: 0.1793 - val_loss: 0.2718\n",
      "features_True_linear_False_days_1_dropout_0.2_freq_12_NN_128_64_32_12 & 47.378 & 40.338 & 19.956 & 18.687 & 22.164 & 215.409 & 131.644 & 32.383 \\\\\n",
      "Using 5 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1230 (Dense)           (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dropout_1037 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1231 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1038 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1232 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1039 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1233 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1040 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1234 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,025\n",
      "Trainable params: 28,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62237 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "62237/62237 [==============================] - 24s 392us/step - loss: 0.2116 - val_loss: 0.2158\n",
      "Epoch 2/100\n",
      "62237/62237 [==============================] - 11s 178us/step - loss: 0.2089 - val_loss: 0.2146\n",
      "Epoch 3/100\n",
      "62237/62237 [==============================] - 11s 179us/step - loss: 0.2085 - val_loss: 0.2164\n",
      "Epoch 4/100\n",
      "62237/62237 [==============================] - 11s 173us/step - loss: 0.2078 - val_loss: 0.2142\n",
      "Epoch 5/100\n",
      "62237/62237 [==============================] - 11s 181us/step - loss: 0.2073 - val_loss: 0.2145\n",
      "Epoch 6/100\n",
      "62237/62237 [==============================] - 11s 172us/step - loss: 0.2068 - val_loss: 0.2155\n",
      "features_False_linear_False_days_1_dropout_0.2_freq_12_NN_128_64_32_12 & 36.484 & 40.378 & 18.051 & 21.393 & 20.235 & 231.781 & 145.316 & 33.108 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1235 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1041 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1236 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1042 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1237 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1043 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1238 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1044 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1239 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 32s 147us/step - loss: 0.1626 - val_loss: 0.1517\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1524 - val_loss: 0.1469\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 18s 83us/step - loss: 0.1459 - val_loss: 0.1418\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 18s 83us/step - loss: 0.1417 - val_loss: 0.1352\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1384 - val_loss: 0.1341\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 21s 100us/step - loss: 0.1364 - val_loss: 0.1347\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 21s 98us/step - loss: 0.1346 - val_loss: 0.1304\n",
      "Epoch 8/100\n",
      "214031/214031 [==============================] - 18s 83us/step - loss: 0.1330 - val_loss: 0.1313\n",
      "Epoch 9/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1318 - val_loss: 0.1285\n",
      "Epoch 10/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1306 - val_loss: 0.1310\n",
      "Epoch 11/100\n",
      "214031/214031 [==============================] - 17s 82us/step - loss: 0.1298 - val_loss: 0.1266\n",
      "Epoch 12/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1294 - val_loss: 0.1263\n",
      "Epoch 13/100\n",
      "214031/214031 [==============================] - 18s 83us/step - loss: 0.1285 - val_loss: 0.1267\n",
      "Epoch 14/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1280 - val_loss: 0.1241\n",
      "Epoch 15/100\n",
      "214031/214031 [==============================] - 18s 82us/step - loss: 0.1272 - val_loss: 0.1248\n",
      "Epoch 16/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1270 - val_loss: 0.1229\n",
      "Epoch 17/100\n",
      "214031/214031 [==============================] - 18s 83us/step - loss: 0.1266 - val_loss: 0.1236\n",
      "Epoch 18/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1259 - val_loss: 0.1252\n",
      "features_True_linear_False_days_5_dropout_0.2_freq_10_NN_128_64_32_12 & 30.352 & 38.975 & 16.411 & 27.012 & 20.247 & 241.605 & 152.179 & 32.645 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1240 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1045 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1241 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1046 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1242 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1047 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1243 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1048 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1244 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214031 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "214031/214031 [==============================] - 31s 146us/step - loss: 0.1720 - val_loss: 0.1687\n",
      "Epoch 2/100\n",
      "214031/214031 [==============================] - 17s 82us/step - loss: 0.1705 - val_loss: 0.1672\n",
      "Epoch 3/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1697 - val_loss: 0.1680\n",
      "Epoch 4/100\n",
      "214031/214031 [==============================] - 17s 80us/step - loss: 0.1691 - val_loss: 0.1663\n",
      "Epoch 5/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1688 - val_loss: 0.1662\n",
      "Epoch 6/100\n",
      "214031/214031 [==============================] - 17s 81us/step - loss: 0.1686 - val_loss: 0.1668\n",
      "Epoch 7/100\n",
      "214031/214031 [==============================] - 17s 80us/step - loss: 0.1685 - val_loss: 0.1665\n",
      "features_False_linear_False_days_5_dropout_0.2_freq_10_NN_128_64_32_12 & 36.334 & 40.369 & 18.081 & 20.967 & 20.358 & 233.969 & 147.121 & 32.785 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1245 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1049 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1246 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1050 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1247 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1051 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1248 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1052 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1249 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 30s 152us/step - loss: 0.1609 - val_loss: 0.1509\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 17s 84us/step - loss: 0.1501 - val_loss: 0.1440\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 17s 84us/step - loss: 0.1440 - val_loss: 0.1385\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 17s 84us/step - loss: 0.1401 - val_loss: 0.1366\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1372 - val_loss: 0.1339\n",
      "Epoch 6/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1353 - val_loss: 0.1319\n",
      "Epoch 7/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1337 - val_loss: 0.1303\n",
      "Epoch 8/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1322 - val_loss: 0.1298\n",
      "Epoch 9/100\n",
      "197977/197977 [==============================] - 17s 83us/step - loss: 0.1310 - val_loss: 0.1283\n",
      "Epoch 10/100\n",
      "197977/197977 [==============================] - 17s 84us/step - loss: 0.1298 - val_loss: 0.1272\n",
      "Epoch 11/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1293 - val_loss: 0.1263\n",
      "Epoch 12/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1285 - val_loss: 0.1260\n",
      "Epoch 13/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1279 - val_loss: 0.1255\n",
      "Epoch 14/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1271 - val_loss: 0.1247\n",
      "Epoch 15/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1269 - val_loss: 0.1246\n",
      "Epoch 16/100\n",
      "197977/197977 [==============================] - 17s 86us/step - loss: 0.1262 - val_loss: 0.1242\n",
      "Epoch 17/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1258 - val_loss: 0.1238\n",
      "Epoch 18/100\n",
      "197977/197977 [==============================] - 16s 83us/step - loss: 0.1254 - val_loss: 0.1228\n",
      "Epoch 19/100\n",
      "197977/197977 [==============================] - 16s 83us/step - loss: 0.1251 - val_loss: 0.1239\n",
      "Epoch 20/100\n",
      "197977/197977 [==============================] - 16s 81us/step - loss: 0.1247 - val_loss: 0.1234\n",
      "features_True_linear_False_days_5_dropout_0.2_freq_12_NN_128_64_32_12 & 32.373 & 37.519 & 16.046 & 25.287 & 17.701 & 197.864 & 121.460 & 38.248 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1250 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1053 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1251 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1054 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1252 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1055 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1253 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1056 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1254 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 197977 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "197977/197977 [==============================] - 30s 152us/step - loss: 0.1711 - val_loss: 0.1671\n",
      "Epoch 2/100\n",
      "197977/197977 [==============================] - 16s 83us/step - loss: 0.1694 - val_loss: 0.1661\n",
      "Epoch 3/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1689 - val_loss: 0.1660\n",
      "Epoch 4/100\n",
      "197977/197977 [==============================] - 16s 82us/step - loss: 0.1684 - val_loss: 0.1664\n",
      "Epoch 5/100\n",
      "197977/197977 [==============================] - 16s 81us/step - loss: 0.1680 - val_loss: 0.1666\n",
      "features_False_linear_False_days_5_dropout_0.2_freq_12_NN_128_64_32_12 & 35.886 & 40.703 & 18.100 & 21.558 & 20.727 & 240.482 & 151.239 & 32.155 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1255 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1057 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1256 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1058 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1257 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1059 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1258 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1060 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1259 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 38s 102us/step - loss: 0.1599 - val_loss: 0.1464\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1476 - val_loss: 0.1385\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1418 - val_loss: 0.1336\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1380 - val_loss: 0.1298\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1353 - val_loss: 0.1289\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1334 - val_loss: 0.1262\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1319 - val_loss: 0.1252\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1306 - val_loss: 0.1244\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1297 - val_loss: 0.1232\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1289 - val_loss: 0.1218\n",
      "Epoch 11/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1282 - val_loss: 0.1223\n",
      "Epoch 12/100\n",
      "370240/370240 [==============================] - 23s 63us/step - loss: 0.1275 - val_loss: 0.1215\n",
      "Epoch 13/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1272 - val_loss: 0.1210\n",
      "Epoch 14/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1267 - val_loss: 0.1207\n",
      "Epoch 15/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1263 - val_loss: 0.1216\n",
      "Epoch 16/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1260 - val_loss: 0.1195\n",
      "Epoch 17/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1255 - val_loss: 0.1205\n",
      "Epoch 18/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1254 - val_loss: 0.1206\n",
      "features_True_linear_False_days_10_dropout_0.2_freq_10_NN_128_64_32_12 & 30.611 & 38.239 & 16.044 & 26.102 & 18.874 & 222.736 & 138.018 & 35.664 \\\\\n",
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1260 (Dense)           (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1061 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1261 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1062 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1262 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1063 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1263 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1064 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1264 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 28,153\n",
      "Trainable params: 28,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 370240 samples, validate on 448424 samples\n",
      "Epoch 1/100\n",
      "370240/370240 [==============================] - 38s 102us/step - loss: 0.1732 - val_loss: 0.1684\n",
      "Epoch 2/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1717 - val_loss: 0.1683\n",
      "Epoch 3/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1710 - val_loss: 0.1673\n",
      "Epoch 4/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1706 - val_loss: 0.1675\n",
      "Epoch 5/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1704 - val_loss: 0.1671\n",
      "Epoch 6/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1701 - val_loss: 0.1672\n",
      "Epoch 7/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1699 - val_loss: 0.1670\n",
      "Epoch 8/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1697 - val_loss: 0.1667\n",
      "Epoch 9/100\n",
      "370240/370240 [==============================] - 24s 65us/step - loss: 0.1697 - val_loss: 0.1670\n",
      "Epoch 10/100\n",
      "370240/370240 [==============================] - 24s 64us/step - loss: 0.1696 - val_loss: 0.1677\n",
      "features_False_linear_False_days_10_dropout_0.2_freq_10_NN_128_64_32_12 & 35.874 & 40.798 & 18.161 & 21.105 & 20.880 & 243.870 & 153.596 & 31.822 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/tommelamed/anaconda3/envs/busses/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 PCA components\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1265 (Dense)           (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_1065 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1266 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1066 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1267 (Dense)           (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1067 (Dropout)       (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1268 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1068 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1269 (Dense)           (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 29,561\n",
      "Trainable params: 29,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 341937 samples, validate on 413400 samples\n",
      "Epoch 1/100\n",
      "341937/341937 [==============================] - 42s 123us/step - loss: 0.1602 - val_loss: 0.1472\n",
      "Epoch 2/100\n",
      "341937/341937 [==============================] - 26s 76us/step - loss: 0.1476 - val_loss: 0.1376\n",
      "Epoch 3/100\n",
      "341937/341937 [==============================] - 26s 76us/step - loss: 0.1409 - val_loss: 0.1324\n",
      "Epoch 4/100\n",
      "341937/341937 [==============================] - 25s 74us/step - loss: 0.1369 - val_loss: 0.1287\n",
      "Epoch 5/100\n",
      "341937/341937 [==============================] - 27s 78us/step - loss: 0.1344 - val_loss: 0.1261\n",
      "Epoch 6/100\n",
      "341937/341937 [==============================] - 25s 73us/step - loss: 0.1324 - val_loss: 0.1247\n",
      "Epoch 7/100\n",
      "341937/341937 [==============================] - 24s 69us/step - loss: 0.1309 - val_loss: 0.1234\n",
      "Epoch 8/100\n",
      "341937/341937 [==============================] - 26s 75us/step - loss: 0.1296 - val_loss: 0.1223\n",
      "Epoch 9/100\n",
      "341937/341937 [==============================] - 24s 71us/step - loss: 0.1287 - val_loss: 0.1218\n",
      "Epoch 10/100\n",
      "341937/341937 [==============================] - 26s 77us/step - loss: 0.1280 - val_loss: 0.1219\n",
      "Epoch 11/100\n",
      "341937/341937 [==============================] - 26s 75us/step - loss: 0.1271 - val_loss: 0.1201\n",
      "Epoch 12/100\n",
      "341937/341937 [==============================] - 27s 78us/step - loss: 0.1266 - val_loss: 0.1197\n",
      "Epoch 13/100\n",
      "341937/341937 [==============================] - 24s 71us/step - loss: 0.1261 - val_loss: 0.1195\n",
      "Epoch 14/100\n",
      "341937/341937 [==============================] - 25s 74us/step - loss: 0.1257 - val_loss: 0.1192\n",
      "Epoch 15/100\n",
      "341248/341937 [============================>.] - ETA: 0s - loss: 0.1253"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-334-aad559c1f749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mextra_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#                             f.write(f\"{freq},{dropout},{loss},{'_'.join(list(map(str,overlaps_mask)))},{'_'.join(list(map(str,NN)))},{use_linear},{pass_fraction},{RMSE},{MAE}\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#                             f.flush()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-328-1c7857094906>\u001b[0m in \u001b[0;36mlearn_PCA\u001b[0;34m(freq, dropout, loss, NN, days, extra_features, use_linear)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/busses/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/busses/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/busses/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/busses/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/busses/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stats = Stats(se[se['test']])\n",
    "\n",
    "with open(\"GPS_fixed_true_dist_PCA_learning_curve_valid_freq.csv\", \"a+\") as f: \n",
    "#     f.write(stats.full_stats(tests=[], names=[], data_type=\"duration\"))\n",
    "#     f.flush()\n",
    "    for runs in range(5):\n",
    "        for NN in [[32,12,12],[128,64,32,12]]: # [64,32,12], [128,64,32,32,12]]:\n",
    "            for dropout in [0,0.2,0.5]:\n",
    "                for days in [1,5,10,30,50,70]:\n",
    "                    for loss in ['logcosh']: # , 'mean_absolute_error', 'mean_squared_error']:\n",
    "                        for freq in [10, 12]:\n",
    "                            for use_linear in [False]:\n",
    "                                for extra_features in [True, False]:\n",
    "                    \n",
    "                                    prediction = learn_PCA(freq, dropout, loss, NN, days, extra_features, use_linear)\n",
    "        #                             f.write(f\"{freq},{dropout},{loss},{'_'.join(list(map(str,overlaps_mask)))},{'_'.join(list(map(str,NN)))},{use_linear},{pass_fraction},{RMSE},{MAE}\\n\")\n",
    "        #                             f.flush()\n",
    "                                    f.write(\n",
    "                                        stats.single_row(\n",
    "                                            prediction,\n",
    "                                            f\"features_{extra_features}_linear_{use_linear}_days_{days}_dropout_{dropout}_freq_{freq}_NN_{'_'.join(list(map(str,NN)))}\",\n",
    "                                            data_type=\"duration\",\n",
    "                                        )\n",
    "                                    )\n",
    "                                    f.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.clip(wraw_prediction, 0, 50), bins=100, range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(se['speed_mph'], bins=100, range=(0,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(test_y, bins=100, label=\"pred\", density=True, range=(-10,100));\n",
    "# plt.hist(se['speed_mph'][int(len(se)*test_fraction):], bins=100, label=\"truth\", alpha=0.5, density=True, range=(-10,100));\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeds_mph_simple = se['real_length'] / se['mean_durations_by_segment_code_and_hour_and_day'] * 2.237\n",
    "\n",
    "# se_min = se[['speed_mph', 'publicName', 'to_centre_dist', 'real_length', 'mean_durations_by_segment_code_and_hour_and_day']][int(len(se)*test_fraction):].copy()\n",
    "\n",
    "# se_min['baseline_speed'] = se_min['real_length'] / se_min['mean_durations_by_segment_code_and_hour_and_day'] * 2.237\n",
    "\n",
    "# se_min['test_y'] = test_y\n",
    "\n",
    "# routes = []\n",
    "# pred_MSE = []\n",
    "# pred_RMSE = []\n",
    "# base_MSE = []\n",
    "# base_RMSE = []\n",
    "# freq = []\n",
    "# mean_dist = []\n",
    "\n",
    "# for route_name, route in se_min.groupby('publicName'):\n",
    "    \n",
    "#     if route_name in schools:\n",
    "#         continue\n",
    "        \n",
    "#     routes.append(route_name)\n",
    "#     pred_MSE.append(mean_absolute_error(route['speed_mph'], route['test_y']))\n",
    "#     pred_RMSE.append(np.sqrt(mean_squared_error(route['speed_mph'], route['test_y'])))\n",
    "#     base_MSE.append(mean_absolute_error(route['speed_mph'], route['baseline_speed']))\n",
    "#     base_RMSE.append(np.sqrt(mean_squared_error(route['speed_mph'], route['baseline_speed'])))\n",
    "#     freq.append(len(route))\n",
    "    \n",
    "# results = pd.DataFrame(index=routes)\n",
    "# results['pred_MSE'] = pred_MSE\n",
    "# results['base_MSE'] = base_MSE\n",
    "# results['pred_RMSE'] = pred_RMSE\n",
    "# results['base_RMSE'] = base_RMSE\n",
    "# results['freq'] = freq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "busses",
   "language": "python",
   "name": "busses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
